# -*- coding: utf-8 -*-
"""1000_1s_ORIGINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HDbq-JbKmG10qCnD6OZrkNWykh-bIO55

<center>

UNIVERSIDADE FEDERAL DO RIO DE JANEIRO - UFRJ

DISSERTAÇÃO DE MESTRADO EM ENGENHARIA ELÉTRICA \

PROCESSAMENTO DE SINAIS DE ÁUDIO
</center>

REPOSITÓRIO DESTE TRABALHO:

https://github.com/albuca09/Blind-room-parameter-estimation-from-Room-Impulse-Responses-Using-Deep-Neural-Networks

ALUNO: LUIS PAULO A. GUEDES


ORIENTADORA: PROF. MARIANE \\

ORIENTADOR: PROF. JULIO

Convolucao original - PROCURAR SABER O QUE ESTA DIFERENTE
"""

from google.colab import drive
drive.mount('/content/drive')

"""# GERANDO AS CONFIGURAÇÕES DE COEFICIENTES DE ABSORÇÃO

ALTERANDO OS COEFICIENTES DE ABS.
"""

pip install ace_tools

import pandas as pd
import matplotlib.pyplot as plt

# Caminho do arquivo
file_path = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff.xls'

# Carregar o arquivo Excel, usando a linha 20 (índice 19) como cabeçalho
df = pd.read_excel(file_path, sheet_name='selection_table', header=19)

# Remover espaços extras dos nomes das colunas e converter tudo para string
df.columns = df.columns.astype(str).str.strip()


# Definir as colunas desejadas
columns_to_keep = ['description', '125', '250', '500', '1000', '2000', '4000', 'reference']

# Verificar quais colunas realmente existem no DataFrame
existing_columns = [col for col in columns_to_keep if col in df.columns]

# Filtrar apenas as colunas existentes
df_filtered = df[existing_columns]

df_filtered.head()

pip install deep_translator

from deep_translator import GoogleTranslator
import pandas as pd

# Definir os caminhos dos arquivos
file_path = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff.xls'
output_path = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt.csv'

# Carregar o arquivo Excel (linha 20 contém os cabeçalhos)
df = pd.read_excel(file_path, sheet_name='selection_table', header=19)

# Remover espaços extras dos nomes das colunas e converter para string
df.columns = df.columns.astype(str).str.strip()

# Verificar se a coluna "description" existe no DataFrame
if 'description' in df.columns:
    # Traduzir os valores da coluna "description" do inglês para o português
    df['description'] = df['description'].astype(str).apply(lambda x: GoogleTranslator(source='auto', target='pt').translate(x) if pd.notna(x) else x)

    # Salvar o DataFrame traduzido no formato CSV
    df.to_csv(output_path, index=False, encoding='utf-8')

    print(f"Arquivo salvo com sucesso em: {output_path}")
else:
    print("A coluna 'description' não foi encontrada no DataFrame.")

import pandas as pd

# Defina o caminho do arquivo CSV
caminho_csv = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt.csv'

# Crie o dataframe lendo o arquivo CSV
df = pd.read_csv(caminho_csv)

# Exiba as 5 primeiras linhas do dataframe para verificação
print(df.head())

df.head()

# Defina as colunas que você deseja filtrar
colunas_desejadas = ['description', '125', '250', '500', '1000', '2000', '4000', 'reference']

# Crie um novo DataFrame apenas com as colunas desejadas
df_filtrado = df[colunas_desejadas]

# Exiba as primeiras linhas do DataFrame filtrado para verificação
print(df_filtrado.head())

"""SELECIONAR AS LINHAS"""

df_filtrado.head(20)

df_filtrado.info()

"""RETIRANDO VALORES FALTANTES"""

# Remover linhas com valores faltantes no DataFrame filtrado
df_filtrado = df_filtrado.dropna()

# Exibir as primeiras linhas para verificar o resultado
print(df_filtrado.head())

# Remover linhas duplicadas do DataFrame filtrado
df_filtrado = df_filtrado.drop_duplicates()

# Exibir as primeiras linhas para verificar o resultado
print(df_filtrado.head())

"""GERANDO .csv"""

# Defina o novo caminho e nome para o arquivo CSV filtrado
novo_caminho_csv = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_filtered.csv'

# Salve o DataFrame filtrado em um novo arquivo CSV sem o índice
df_filtrado.to_csv(novo_caminho_csv, index=False)

print("Novo CSV salvo em:", novo_caminho_csv)

"""COEFICIENTES DE ABS PARA PISO"""

import pandas as pd

# Ler o CSV filtrado
novo_caminho_csv = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_filtered.csv'
df_filtrado = pd.read_csv(novo_caminho_csv)

# Filtrar as linhas onde a coluna 'description' contém a palavra ou parte da palavra "piso" (ignora maiúsculas/minúsculas)
df_floor = df_filtrado[df_filtrado['description'].str.contains("piso", case=False, na=False)]

# Exibir as primeiras linhas do DataFrame filtrado para verificação
print(df_floor.head())

df_floor.info()

df_floor.head(30)

"""COEFICIENTES DE ABS PARA PAREDES"""

import pandas as pd

# Ler o CSV filtrado
novo_caminho_csv = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_filtered.csv'
df_filtrado = pd.read_csv(novo_caminho_csv)

# Filtrar as linhas onde a coluna 'description' contém "parede" ou "concreto" (ignora maiúsculas/minúsculas)
df_wall = df_filtrado[df_filtrado['description'].str.contains('parede|concreto', case=False, na=False)]

# Exibir as primeiras linhas do DataFrame filtrado para verificação
print(df_wall.head())

df_wall.info()

"""COEFICIENTES DE ABS PARA TETO"""

import pandas as pd

# Ler o CSV filtrado
novo_caminho_csv = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_filtered.csv'
df_filtrado = pd.read_csv(novo_caminho_csv)

# Filtrar as linhas onde a coluna 'description' contém "teto" ou "gesso" (ignora maiúsculas/minúsculas)
df_ceiling = df_filtrado[df_filtrado['description'].str.contains('teto|gesso', case=False, na=False)]

# Exibir as primeiras linhas do DataFrame resultante para verificação
print(df_ceiling.head())

df_ceiling.info()

"""CRIANDO .csv SEPARADOS"""

import pandas as pd

# Ler o CSV filtrado
novo_caminho_csv = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_filtered.csv'
df_filtrado = pd.read_csv(novo_caminho_csv)

# Filtrar as linhas da coluna 'description' para cada categoria
df_floor = df_filtrado[df_filtrado['description'].str.contains('piso', case=False, na=False)]
df_wall = df_filtrado[df_filtrado['description'].str.contains('parede|concreto', case=False, na=False)]
df_ceiling = df_filtrado[df_filtrado['description'].str.contains('teto|gesso', case=False, na=False)]

# Definir os caminhos para salvar cada CSV separado
caminho_df_floor = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_floor.csv'
caminho_df_wall = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_wall.csv'
caminho_df_ceiling = '/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_ceiling.csv'

# Salvar cada DataFrame em seu respectivo arquivo CSV sem o índice
df_floor.to_csv(caminho_df_floor, index=False)
df_wall.to_csv(caminho_df_wall, index=False)
df_ceiling.to_csv(caminho_df_ceiling, index=False)

print("CSV para df_floor salvo em:", caminho_df_floor)
print("CSV para df_wall salvo em:", caminho_df_wall)
print("CSV para df_ceiling salvo em:", caminho_df_ceiling)

import pandas as pd
import numpy as np
import plotly.graph_objects as go

# Defina as colunas de frequência que você quer plotar
freq_cols = ['125', '250', '500', '1000', '2000', '4000']

# Antes de plotar, substitua ' - ' por NaN e remova linhas com NaN
def preparar_df(df):
    # Substitui ' - ' por NaN
    df[freq_cols] = df[freq_cols].replace(' - ', np.nan)
    # Converte tudo para float
    for col in freq_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    # Remove linhas que tenham NaN nas colunas de frequência
    df = df.dropna(subset=freq_cols)
    return df

def plot_absorption_coefficients(df, title):
    """
    Plota todas as curvas de absorção para cada linha do DataFrame
    (uma curva por linha), com linhas em cinza.
    """
    fig = go.Figure()

    # Para cada linha do DataFrame, cria uma curva
    for index, row in df.iterrows():
        # Extrai os valores numéricos das colunas de frequência
        y_values = [row[col] for col in freq_cols]

        fig.add_trace(go.Scatter(
            x=freq_cols,                 # Frequências (Hz)
            y=y_values,                  # Coeficientes
            mode='lines+markers',
            line=dict(color='gray'),     # Todas as linhas em cinza
            showlegend=False             # Sem legenda para cada linha
        ))

    # Ajusta o layout do gráfico
    fig.update_layout(
        title=title,
        xaxis_title='Frequência (Hz)',
        yaxis_title='Coeficiente de Absorção'
    )

    fig.show()

# Exemplo: se você já tem df_floor, df_wall, df_ceiling, prepare cada um
df_floor = preparar_df(df_floor)
df_wall = preparar_df(df_wall)
df_ceiling = preparar_df(df_ceiling)

# Agora, gere um gráfico para cada DataFrame
plot_absorption_coefficients(df_floor,   "Coeficientes de Absorção - Piso")
plot_absorption_coefficients(df_wall,    "Coeficientes de Absorção - Parede/Concreto")
plot_absorption_coefficients(df_ceiling, "Coeficientes de Absorção - Teto/Gesso")

"""# LIMITANDO VALORES DE COEFICIENTES DE ABSORÇÃO"""

import pandas as pd
import numpy as np
import plotly.graph_objects as go

# Colunas de frequência que serão avaliadas
freq_cols = ['125', '250', '500', '1000', '2000', '4000']

def preparar_df(df):
    """
    Prepara o DataFrame substituindo ' - ' por NaN,
    convertendo as colunas de frequência para float,
    removendo linhas com NaN e removendo linhas com coeficientes maiores que 1.
    """
    # Substituir ' - ' por NaN nas colunas de frequência
    df[freq_cols] = df[freq_cols].replace(' - ', np.nan)

    # Converter as colunas de frequência para float
    for col in freq_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    # Remover linhas com valores NaN em qualquer uma das colunas de frequência
    df = df.dropna(subset=freq_cols)

    # Remover linhas em que qualquer coeficiente seja maior que 1
    df = df[df[freq_cols].le(1).all(axis=1)]

    return df

# Exemplo: Preparando cada DataFrame
df_floor = preparar_df(df_floor)
df_wall = preparar_df(df_wall)
df_ceiling = preparar_df(df_ceiling)

# Função para plotar os coeficientes de absorção para cada registro do DataFrame
def plot_absorption_coefficients(df, title):
    """
    Plota todas as curvas de absorção para cada linha (registro) do DataFrame.
    Cada registro gera uma curva, com:
      - Eixo x: frequências (Hz)
      - Eixo y: coeficientes de absorção
    Todas as curvas serão plotadas na cor cinza.
    """
    fig = go.Figure()

    # Para cada registro, extrai os coeficientes e plota a curva
    for index, row in df.iterrows():
        y_values = [row[col] for col in freq_cols]
        fig.add_trace(go.Scatter(
            x=freq_cols,               # Frequências (Hz)
            y=y_values,                # Coeficientes
            mode='lines+markers',
            line=dict(color='gray'),   # Todas as linhas em cinza
            showlegend=False           # Sem legenda para cada linha
        ))

    # Configuração do layout do gráfico
    fig.update_layout(
        title=title,
        xaxis_title='Frequência (Hz)',
        yaxis_title='Coeficiente de Absorção'
    )

    fig.show()

# Gerando os gráficos para cada DataFrame
plot_absorption_coefficients(df_floor,   "Coeficientes de Absorção - Piso")
plot_absorption_coefficients(df_wall,    "Coeficientes de Absorção - Parede/Concreto")
plot_absorption_coefficients(df_ceiling, "Coeficientes de Absorção - Teto/Gesso")

# Após preparar cada DataFrame (df_floor, df_wall, df_ceiling) com a função preparar_df:

# Salvar os DataFrames modificados sobrescrevendo os arquivos com os mesmos nomes
df_floor.to_csv('/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_floor.csv', index=False)
df_wall.to_csv('/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_wall.csv', index=False)
df_ceiling.to_csv('/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_ceiling.csv', index=False)



print("Arquivos CSV atualizados com sucesso!")

"""Um coeficiente de absorção maior que um pode ser devido ao procedimento de medição; o material tem bordas que fornecem área de absorção adicional, mas as bordas não estão incluídas na área de superfície usada para calcular o coeficiente.

O texto abaixo explica um pouco: https://www.customaudiodirect.co.uk/measuring-sound-absorption
"""

# Contabilizando as entradas de cada DataFrame
num_floor = df_floor.shape[0]
num_wall = df_wall.shape[0]
num_ceiling = df_ceiling.shape[0]

print("Número de entradas no df_floor:", num_floor)
print("Número de entradas no df_wall:", num_wall)
print("Número de entradas no df_ceiling:", num_ceiling)

import pandas as pd
import plotly.graph_objects as go

# Lista de arquivos e seus rótulos
files = {
    "floor": "/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_floor.csv",
    "wall": "/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_wall.csv",
    "ceiling": "/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_ceiling.csv"
}



# Frequências especificadas (convertidas para string)
frequencies = ["125", "250", "500", "1000", "2000", "4000"]

# Criar uma figura para cada arquivo
for label, file_path in files.items():
    # Carregar o arquivo CSV
    df = pd.read_csv(file_path)

    # Converter os nomes das colunas para strings
    df.columns = df.columns.astype(str)

    # Criar a figura
    fig = go.Figure()

    # Adicionar os boxplots para cada frequência
    for freq in frequencies:
        if freq in df.columns:
            fig.add_trace(go.Box(
                y=df[freq].dropna(),  # Remove valores nulos para o boxplot
                name=f'{freq} Hz',
                marker_color='indianred'  # Cor dos pontos do boxplot
            ))
        else:
            print(f"A coluna '{freq}' não foi encontrada no DataFrame para {label}.")

    # Configuração do layout do gráfico
    fig.update_layout(
        title=f"Distribuição dos Coeficientes de Absorção ({label.capitalize()})",
        xaxis_title="Frequência (Hz)",
        yaxis_title="Coeficiente de Absorção",
        template="plotly_white"
    )

    # Exibir o gráfico
    fig.show()

"""Agora, os coeficientes de absorção para paredes, teto e chão são obtidos a partir dos respectivos arquivos CSV. Em cada caso, é sorteada (aleatoriamente) uma linha do CSV e os valores para as frequências (125, 250, 500, 1000, 2000, 4000) são atribuídos para os lados correspondentes:

1. Paredes (L_1 a L_4): São lidos os valores do CSV /content/drive/MyDrive/COEFF_ABS/abstab_wf_pt_filtered_wall.csv.

2. Teto (L_5): São lidos os valores do CSV /content/drive/MyDrive/COEFF_ABS/abstab_wf_pt_filtered_ceiling.csv.

3. Chão (L_6): São lidos os valores do CSV /content/drive/MyDrive/COEFF_ABS/abstab_wf_pt_filtered_floor.csv.

# GERANDO AS CONFIGURAÇÕES DAS SALAS

COMANDO ABAIXO É O ANTIGO. NÃO EXECUTAR.
"""

import random
import pandas as pd

class util_room:
    def height_width_length(self):
        # Intervalo das dimensões da sala: Comprimento (3-12), Largura (3-12), Altura (2.5-4.5)
        values = [round(random.uniform(3, 12), 1), round(random.uniform(3, 12), 1), round(random.uniform(2.5, 4.5), 1)]
        return values

    def get_absorption_coeff(self, room_id):
        # Frequências em Hz
        frequencies = [125, 250, 500, 1000, 2000, 4000]

        # Carregar os CSVs com os coeficientes para cada superfície
        df_wall = pd.read_csv('/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_wall.csv')
        df_ceiling = pd.read_csv('/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_ceiling.csv')
        df_floor = pd.read_csv('/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_floor.csv')


        absorption_data = {}

        # Selecionar aleatoriamente uma linha para paredes (L_1 a L_4)
        random_wall = df_wall.sample(n=1).iloc[0]
        # Selecionar aleatoriamente uma linha para teto (L_5)
        random_ceiling = df_ceiling.sample(n=1).iloc[0]
        # Selecionar aleatoriamente uma linha para floor (L_6)
        random_floor = df_floor.sample(n=1).iloc[0]

        # Gerar coeficientes de absorção para paredes (lados 1 a 4)
        for side in range(1, 5):
            for freq in frequencies:
                key = f"{room_id}/Coeficiente_Absorcao_F_{freq}_L_{side}"
                # Converte o valor para float, caso esteja como string
                value = float(random_wall[str(freq)])
                absorption_data[key] = value

        # Gerar coeficientes de absorção para o teto (lado 5)
        side = 5
        for freq in frequencies:
            key = f"{room_id}/Coeficiente_Absorcao_F_{freq}_L_{side}"
            value = float(random_ceiling[str(freq)])
            absorption_data[key] = value

        # Gerar coeficientes de absorção para o chão (lado 6)
        side = 6
        for freq in frequencies:
            key = f"{room_id}/Coeficiente_Absorcao_F_{freq}_L_{side}"
            value = float(random_floor[str(freq)])
            absorption_data[key] = value

        return absorption_data

    def get_diffusion_coeff(self, room_id):
        """
        Gera coeficientes de difusão para os lados de uma sala.
        Para cada lado (1 a 6) e para cada frequência (125, 250, 500, 1000, 2000, 4000),
        gera um coeficiente (mesmo valor para todos) aleatório entre 0.2 e 1.
        """
        frequencies = [125, 250, 500, 1000, 2000, 4000]
        diffusion_data = {}
        coeff = round(random.uniform(0.2, 1), 2)

        for side in range(1, 7):  # Considera 4 paredes, teto e chão
            for freq in frequencies:
                key = f"{room_id}/Coeficiente_Difusao_F_{freq}_L_{side}"
                diffusion_data[key] = coeff

        return diffusion_data

"""NOVO COMANDO USANDO A RELACAO CORRETA ENTRE COEFF DE ABSORÇÃO E DE REFLEXÃO"""

import random
import math
import pandas as pd

class util_room:
    def __init__(self):
        # Cache para garantir que usamos os mesmos α de absorção
        self._absorption_cache = {}   # {room_id: {chave: α}}

    # ------------------------------------------------------------------ #
    # 1. Dimensões da sala
    # ------------------------------------------------------------------ #
    def height_width_length(self):
        """
        Gera (comprimento, largura, altura) dentro dos intervalos especificados
        e com uma casa decimal.
        """
        dims = [
            round(random.uniform(3, 12), 1),   # comprimento
            round(random.uniform(3, 12), 1),   # largura
            round(random.uniform(2.5, 4.5), 1) # altura
        ]
        return dims

    # ------------------------------------------------------------------ #
    # 2. Coeficientes de absorção α (cacheados)
    # ------------------------------------------------------------------ #
    def get_absorption_coeff(self, room_id):
        """
        Gera e devolve um dicionário com α para cada lado e frequência.
        O resultado é salvo em cache para ser reutilizado no cálculo de |R|.
        """
        frequencies = [125, 250, 500, 1000, 2000, 4000]

        df_wall    = pd.read_csv('/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_wall.csv')
        df_ceiling = pd.read_csv('/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_ceiling.csv')
        df_floor   = pd.read_csv('/content/drive/MyDrive/Dissertação - Mestrado/tabcoeff_pt_floor.csv')

        absorption_data = {}

        # Amostras aleatórias
        random_wall    = df_wall.sample(n=1).iloc[0]
        random_ceiling = df_ceiling.sample(n=1).iloc[0]
        random_floor   = df_floor.sample(n=1).iloc[0]

        # Paredes (lados 1‑4)
        for side in range(1, 5):
            for f in frequencies:
                key   = f"{room_id}/Coeficiente_Absorcao_F_{f}_L_{side}"
                value = float(random_wall[str(f)])
                absorption_data[key] = value

        # Teto (lado 5)
        side = 5
        for f in frequencies:
            key   = f"{room_id}/Coeficiente_Absorcao_F_{f}_L_{side}"
            value = float(random_ceiling[str(f)])
            absorption_data[key] = value

        # Piso (lado 6)
        side = 6
        for f in frequencies:
            key   = f"{room_id}/Coeficiente_Absorcao_F_{f}_L_{side}"
            value = float(random_floor[str(f)])
            absorption_data[key] = value

        # Salvar em cache
        self._absorption_cache[room_id] = absorption_data
        return absorption_data

    # ------------------------------------------------------------------ #
    # 3. “Coeficientes de difusão” baseados na relação α = 1 − |R|²
    # ------------------------------------------------------------------ #
    def get_diffusion_coeff(self, room_id):
        """
        Para cada lado (1‑6) e frequência (125–4000 Hz):
            α = coef. de absorção (já calculado)
            |R| = sqrt(max(0, 1 − α))
        Retorna dicionário com as chaves
            '{room_id}/Coeficiente_Difusao_F_{f}_L_{side}' : |R|
        lidas como coeficientes de “difusão” conforme solicitado.
        """
        # Verifica se os α já foram gerados
        if room_id not in self._absorption_cache:
            raise ValueError(
                f"Coeficientes de absorção para o room_id '{room_id}' "
                f"ainda não foram calculados. Execute get_absorption_coeff() primeiro."
            )

        frequencies    = [125, 250, 500, 1000, 2000, 4000]
        absorption_map = self._absorption_cache[room_id]

        diffusion_data = {}
        for side in range(1, 7):
            for f in frequencies:
                key_alpha = f"{room_id}/Coeficiente_Absorcao_F_{f}_L_{side}"
                alpha     = absorption_map[key_alpha]

                # |R| = sqrt(1 - α)   (proteção contra erro numérico)
                R_mag = math.sqrt(max(0.0, 1.0 - alpha))

                key_diff = f"{room_id}/Coeficiente_Difusao_F_{f}_L_{side}"
                diffusion_data[key_diff] = R_mag

        return diffusion_data

"""# GERANDO AS CONFIGURAÇÕES DOS RECEPTORES"""

import numpy as np
import random
import plotly.graph_objects as go

class util_receiver():
    def __init__(self):
        self.dic_receiver = {}

    def mic_definition_array(self, barycenter):
        """
        Define a posição dos microfones no array, garantindo que fiquem no plano XY.
        """
        distance_bw_mics = 0.180
        distance_wrt_bc = distance_bw_mics / 2

        # Os microfones são simétricos em relação ao baricentro no eixo X
        mic_1 = np.array([barycenter[0] + distance_wrt_bc, barycenter[1], barycenter[2]])
        mic_2 = np.array([barycenter[0] - distance_wrt_bc, barycenter[1], barycenter[2]])

        return mic_1, mic_2

    def define_perpendicular_direction(self, mic_pos_1, mic_pos_2):
        """
        Calcula um vetor de direção estritamente perpendicular à linha que une os microfones,
        mas permitindo que ele aponte em qualquer direção em um plano perpendicular ao plano horizontal.
        """
        # Vetor base entre os microfones
        base_vector = mic_pos_2 - mic_pos_1
        base_vector[2] = 0  # Garante que está no plano XY

        # Normaliza o vetor base
        base_vector /= np.linalg.norm(base_vector)

        # Gera um ângulo aleatório para definir a rotação em torno do eixo perpendicular
        theta = random.uniform(0, 2 * np.pi)  # Ângulo em radianos

        # Vetor ortonormal inicial (vetor vertical no plano XY)
        ortonormal_vector = np.array([-base_vector[1], base_vector[0], 0])
        ortonormal_vector /= np.linalg.norm(ortonormal_vector)

        # Aplicando rotação para gerar um vetor perpendicular aleatório
        direction_vector = np.array([
            ortonormal_vector[0] * np.cos(theta),
            ortonormal_vector[1] * np.cos(theta),
            np.sin(theta)  # Direção na componente Z
        ])

        return direction_vector

    def generate_receivers_rooms(self, room_dimension, different_no_receivers, safety_distance):
        """
        Gera a posição dos receptores e microfones na sala com vetores de direção ortogonais.
        """
        mic_pos_1_arr = []  # Posição do microfone 1
        mic_pos_2_arr = []  # Posição do microfone 2
        baricenters = []    # Baricentros calculados
        directions = []     # Vetores de direção dos receptores

        for _ in range(different_no_receivers):
            # Define um baricentro aleatório dentro da sala
            barycenter = np.array([
                round(random.uniform(0.3, (room_dimension[0] - safety_distance)), 3),
                round(random.uniform(0.3, (room_dimension[1] - safety_distance)), 3),
                round(random.uniform(1.0, 1.5), 3)  # Coordenada Z fixa no plano horizontal
            ])

            # Calcula as posições dos microfones
            mic_pos_1, mic_pos_2 = self.mic_definition_array(barycenter)
            mic_pos_1_arr.append(mic_pos_1)
            mic_pos_2_arr.append(mic_pos_2)

            # Calcula o baricentro como ponto médio entre os dois microfones
            midpoint = (mic_pos_1 + mic_pos_2) / 2
            baricenters.append(midpoint)

            # Calcula o vetor de direção perpendicular
            direction_vector = self.define_perpendicular_direction(mic_pos_1, mic_pos_2)
            directions.append(direction_vector)

        return np.array(mic_pos_1_arr), np.array(mic_pos_2_arr), np.array(baricenters), np.array(directions)

    def plot_receivers(self, mic_pos_1_arr, mic_pos_2_arr, baricenters, directions):
        """
        Plota os receptores, microfones e vetores direcionais usando Plotly.
        """
        fig = go.Figure()

        for i, (mic_1, mic_2, bc, direction) in enumerate(zip(mic_pos_1_arr, mic_pos_2_arr, baricenters, directions)):
            # Linha conectando os microfones
            fig.add_trace(go.Scatter3d(
                x=[mic_1[0], mic_2[0]],
                y=[mic_1[1], mic_2[1]],
                z=[mic_1[2], mic_2[2]],
                mode='lines',
                line=dict(color='black', width=4),
                name=f"Segmento Microfones {i+1}"
            ))

            # Microfones
            fig.add_trace(go.Scatter3d(
                x=[mic_1[0], mic_2[0]],
                y=[mic_1[1], mic_2[1]],
                z=[mic_1[2], mic_2[2]],
                mode='markers',
                marker=dict(size=6, color=['red', 'green']),
                name=f"Microfones {i+1}"
            ))

            # Baricentro
            fig.add_trace(go.Scatter3d(
                x=[bc[0]], y=[bc[1]], z=[bc[2]],
                mode='markers',
                marker=dict(size=8, color='orange'),
                name=f"Baricentro {i+1}"
            ))

            # Vetor de direção
            fig.add_trace(go.Scatter3d(
                x=[bc[0], bc[0] + 0.05 * direction[0]],  # Ajuste no tamanho do vetor
                y=[bc[1], bc[1] + 0.05 * direction[1]],
                z=[bc[2], bc[2] + 0.05 * direction[2]],
                mode='lines',
                line=dict(color='purple', width=4, dash='dash'),
                name=f"Vetor Direção {i+1}"
            ))

        # Configurações do layout
        fig.update_layout(
            scene=dict(
                xaxis=dict(title='X'),
                yaxis=dict(title='Y'),
                zaxis=dict(title='Z'),
                aspectmode='data'
            ),
            title="Visualização dos Receptores e Vetores de Direção",
            showlegend=True
        )

        fig.show()

"""# GERANDO AS CONFIGURAÇÕES DAS FONTES

Geração de Fontes Reais (generate_source_room):

Em cada iteração do laço, independentemente do índice, a fonte é definida com a descrição "omni" e o vetor de direção é fixado como [0, 0, 0].
Geração de Fontes de Ruído (generate_noise_source_room):

Para cada fonte de ruído (anteriormente marcadas como "homni"), a descrição é alterada para "omni".
Além disso, os vetores de direção são configurados como [0, 0, 0], indicando uma fonte sem orientação preferencial.
Observação sobre o Método _generate_perpendicular_direction:

Como todas as fontes agora são omni, esse método não é mais utilizado, mas foi mantido no código para referência.
Com essas alterações, todas as fontes geradas (normais e de ruído) terão a descrição "omni", conforme solicitado.
"""

import numpy as np
import random
import plotly.graph_objects as go
from scipy.spatial import distance
from tabulate import tabulate

class util_source:
    def __init__(self):
        # A lista de descrições não será mais usada, pois todas serão "omni"
        self.descriptions = ["omni"]

    def generate_source_room(self, room_dimension, num_sources, safety_distance, barycenter):
        """
        Gera fontes reais na sala, garantindo que todas as fontes sejam omni.

        Parâmetros:
        -----------
        room_dimension : list ou array
            [Comprimento (X), Largura (Y), Altura (Z)] da sala.
        num_sources : int
            Número total de fontes a serem geradas.
        safety_distance : float
            Distância de segurança para não colar as fontes nas paredes.
        barycenter : np.ndarray (shape: [num_sources, 3])
            Baricentro (ou posição de referência) para cada fonte.

        Retorna:
        --------
        sources      : (num_sources, 3) coordenadas X, Y, Z de cada fonte
        ypr_sources  : (num_sources, 3) yaw, pitch, roll de cada fonte
        descriptions : lista com as descrições de cada fonte (todas "omni")
        directions   : (num_sources, 3) vetor de direção para cada fonte (omnidirecional: [0,0,0])
        """
        sources = np.empty((num_sources, 3))
        ypr_sources = np.empty((num_sources, 3))
        descriptions = []
        directions = np.empty((num_sources, 3))

        x_max = room_dimension[0] - safety_distance
        y_max = room_dimension[1] - safety_distance
        z_max = room_dimension[2] - safety_distance

        for i in range(num_sources):
            tmp_coords = self._generate_safe_coordinates(barycenter[i], x_max, y_max, z_max)
            sources[i, :] = tmp_coords

            yaw = random.randint(-180, 180)
            ypr_sources[i, :] = [yaw, 0, 0]

            # Todas as fontes serão "omni"
            descriptions.append("omni")
            directions[i, :] = np.array([0, 0, 0])  # Sem direção preferencial

        return sources, ypr_sources, descriptions, directions

    def generate_noise_source_room(self, room_dimension, num_noise_sources, safety_distance):
        """
        Geração de fontes de ruído com posições e direções fixas/aleatórias.
        Agora, todas as fontes de ruído serão "omni".

        Parâmetros:
        -----------
        room_dimension : [Comprimento(X), Largura(Y), Altura(Z)]
        num_noise_sources : int
            Quantidade de fontes de ruído a gerar (1..5)
        safety_distance : float
            Distância de segurança para não colar as fontes nas paredes

        Retorna:
        --------
        sources     : (num_noise_sources, 3) coordenadas X, Y, Z
        ypr_sources : (num_noise_sources, 3) yaw, pitch, roll
        descriptions: lista de strings ("omni" para cada ruído)
        directions  : (num_noise_sources, 3) vetor de direção (omnidirecional: [0,0,0])
        """
        sources = np.empty((num_noise_sources, 3))
        ypr_sources = np.empty((num_noise_sources, 3))
        descriptions = [None] * num_noise_sources
        directions = np.empty((num_noise_sources, 3))

        x_center = room_dimension[0] / 2
        y_center = room_dimension[1] / 2
        z_top = room_dimension[2]

        # Ruído 1: 30 cm abaixo do teto, fixo no centro da sala
        if num_noise_sources >= 1:
            sources[0, :] = [x_center, y_center, z_top - 0.3]
            directions[0, :] = [0, 0, 0]  # omni
            descriptions[0] = "omni"
            ypr_sources[0, :] = [0, 0, 0]

        # Ruído 2: 30~50 cm abaixo do teto
        if num_noise_sources >= 2:
            sources[1, :] = np.array([
                round(random.uniform(safety_distance, room_dimension[0] - safety_distance), 3),
                round(random.uniform(safety_distance, room_dimension[1] - safety_distance), 3),
                round(random.uniform(z_top - 0.5, z_top - 0.3), 3)
            ])
            directions[1, :] = [0, 0, 0]  # omni
            descriptions[1] = "omni"
            ypr_sources[1, :] = [0, 0, 0]

        # Ruído 3: 20~40 cm da lateral esquerda
        if num_noise_sources >= 3:
            sources[2, :] = np.array([
                round(random.uniform(0.3, room_dimension[0] - 0.3), 3),
                round(random.uniform(safety_distance + 0.2, safety_distance + 0.4), 3),
                round(random.uniform(0.3, z_top - 0.3), 3)
            ])
            directions[2, :] = [0, 0, 0]  # omni
            descriptions[2] = "omni"
            ypr_sources[2, :] = [0, 0, 0]

        # Ruído 4: 20~40 cm da lateral direita
        if num_noise_sources >= 4:
            sources[3, :] = np.array([
                round(random.uniform(0.3, room_dimension[0] - 0.3), 3),
                round(random.uniform(room_dimension[1] - (safety_distance + 0.4),
                                     room_dimension[1] - (safety_distance + 0.2)), 3),
                round(random.uniform(0.3, z_top - 0.3), 3)
            ])
            directions[3, :] = [0, 0, 0]  # omni
            descriptions[3] = "omni"
            ypr_sources[3, :] = [0, 0, 0]

        # Ruído 5: 30~50 cm acima do chão
        if num_noise_sources >= 5:
            sources[4, :] = np.array([
                round(random.uniform(safety_distance, room_dimension[0] - safety_distance), 3),
                round(random.uniform(safety_distance, room_dimension[1] - safety_distance), 3),
                round(random.uniform(0.3, 0.5), 3)
            ])
            directions[4, :] = [0, 0, 0]  # omni
            descriptions[4] = "omni"
            ypr_sources[4, :] = [0, 0, 0]

        return sources, ypr_sources, descriptions, directions

    def _generate_safe_coordinates(self, barycenter, x_max, y_max, z_max, min_distance=0.3):
        """
        Gera coordenadas aleatórias [x, y, z] dentro [0.3, x_max], [0.3, y_max], [0.3, z_max],
        garantindo que a distância euclidiana até 'barycenter' seja >= min_distance.
        """
        while True:
            tmp_coords = np.array([
                round(random.uniform(0.3, x_max), 3),
                round(random.uniform(0.3, y_max), 3),
                round(random.uniform(0.3, z_max), 3)
            ])
            if distance.euclidean(tmp_coords, barycenter) >= min_distance:
                return tmp_coords

    def _generate_perpendicular_direction(self, source_pos, barycenter):
        """
        Método original para gerar direção perpendicular.
        Agora, como todas as fontes serão omni, este método não será utilizado.
        """
        base_vector = source_pos - barycenter
        base_vector[2] = 0
        base_vector /= np.linalg.norm(base_vector)
        theta = random.uniform(0, 2*np.pi)
        ortonormal_vector = np.array([-base_vector[1], base_vector[0], 0])
        ortonormal_vector /= np.linalg.norm(ortonormal_vector)
        direction_vector = np.array([
            ortonormal_vector[0] * np.cos(theta),
            ortonormal_vector[1] * np.cos(theta),
            np.sin(theta)
        ])
        return direction_vector

"""# COMPILANDO AS INFORMAÇÕES"""

import yaml
import json
import os
from tqdm import tqdm

class conf_files:
    def __init__(self, number_of_rooms, name_of_the_dataset):
        self.number_rooms = number_of_rooms
        self.receiver_file = util_receiver()
        self.source_file = util_source()
        self.util_room = util_room()

        # Criar diretório se não existir
        self.save_dir = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas"
        os.makedirs(self.save_dir, exist_ok=True)

        self.params_file()
        self.room_file()

    def params_file(self):
        dict_file = {'simulation_params': {
            'fs': 48000,
            'responseduration': 1.25,
            'bandsperoctave': 1,
            'referencefrequency': 125,
            'airabsorption': True,
            'distanceattenuation': True,
            'subsampleaccuracy': False,
            'highpasscutoff': 0,
            'verbose': True,
            'simulatespecular': True,
            'reflectionorder': [10, 10, 10],
            'simulatediffuse': True,
            'numberofrays': 2000,
            'diffusetimestep': 0.01,
            'rayenergyfloordB': -80.0,
            'uncorrelatednoise': True
        }}

        # Salvar YAML e JSON
        with open(f'{self.save_dir}/conf_sim_params.yml', 'w') as file:
            yaml.dump(dict_file, file)
        with open(f'{self.save_dir}/conf_sim_params.json', 'w') as file:
            json.dump(dict_file, file, indent=4)

    def room_file(self):
        dict_file = {}
        dict_file_receiver = {}
        dict_file_source = {}
        dict_file_noise_source = {}

        # Parâmetros da sala
        humidity = 0.42
        temperature = 20.0
        reference_freq = 125
        no_of_receiver_per_room = 5
        no_of_source_per_room = 5  # Número de fontes de áudio por sala
        no_of_noise_source_per_room = 5  # Número de fontes de ruído por sala
        safety_distance = 0.7

        for x in tqdm(range(self.number_rooms)):
            room_id = f'room_{x}'
            return_dimension = self.util_room.height_width_length()
            dict_file[room_id] = {'surface': {}}
            dict_file[room_id]['dimension'] = return_dimension
            dict_file[room_id]['humidity'] = humidity
            dict_file[room_id]['temperature'] = temperature
            dict_file[room_id]['surface']['frequency'] = [reference_freq * pow(2, a) for a in range(6)]
            dict_file[room_id]['surface']['absorption'] = self.util_room.get_absorption_coeff(room_id)
            dict_file[room_id]['surface']['diffusion'] = self.util_room.get_diffusion_coeff(room_id)

            # Geração de receptores
            li_rec_1, li_rec_2, li_bc, li_directions = self.receiver_file.generate_receivers_rooms(
                return_dimension, no_of_receiver_per_room, safety_distance
            )

            # Geração de fontes de áudio
            li_sc, li_sc_ypr, li_sc_ds, li_sc_directions = self.source_file.generate_source_room(
                return_dimension, no_of_source_per_room, safety_distance, li_bc
            )

            # Geração de fontes de ruído (corrigido para remover li_bc)
            li_nsc, li_nsc_ypr, li_nsc_ds, li_nsc_directions = self.source_file.generate_noise_source_room(
                return_dimension, no_of_noise_source_per_room, safety_distance
            )

            # Garantir ao menos uma fonte omnidirecional
            if "omni" not in li_sc_ds:
                li_sc_ds[0] = "omni"

            # Armazenar dados no dicionário
            dict_file_receiver[room_id] = {
                'barycenter': li_bc.tolist(),
                'mic_pos_1': li_rec_1.tolist(),
                'mic_pos_2': li_rec_2.tolist(),
                'direction': li_directions.tolist()
            }

            dict_file_source[room_id] = {
                'source_pos': li_sc.tolist(),
                'source_ypr': li_sc_ypr.tolist(),
                'source_description': li_sc_ds,
                'source_direction': li_sc_directions.tolist()
            }

            dict_file_noise_source[room_id] = {
                'source_pos': li_nsc.tolist(),
                'source_ypr': li_nsc_ypr.tolist(),
                'source_description': li_nsc_ds,
                'source_direction': li_nsc_directions.tolist()
            }

        # Salvar arquivos YAML
        with open(f'{self.save_dir}/conf_room_setup_2.yml', 'w') as file:
            yaml.dump(dict_file, file)
        with open(f'{self.save_dir}/conf_receivers_2.yml', 'w') as file_1:
            yaml.dump(dict_file_receiver, file_1)
        with open(f'{self.save_dir}/conf_source_2.yml', 'w') as file_2:
            yaml.dump(dict_file_source, file_2)
        with open(f'{self.save_dir}/conf_noise_source_2.yml', 'w') as file_3:
            yaml.dump(dict_file_noise_source, file_3)

        # Salvar arquivos JSON
        with open(f'{self.save_dir}/conf_room_setup_2.json', 'w') as file:
            json.dump(dict_file, file, indent=4)
        with open(f'{self.save_dir}/conf_receivers_2.json', 'w') as file_1:
            json.dump(dict_file_receiver, file_1, indent=4)
        with open(f'{self.save_dir}/conf_source_2.json', 'w') as file_2:
            json.dump(dict_file_source, file_2, indent=4)
        with open(f'{self.save_dir}/conf_noise_source_2.json', 'w') as file_3:
            json.dump(dict_file_noise_source, file_3, indent=4)

conf_files(1000, "test")

"""# GERANDO SALA EM 3D"""

import plotly.graph_objects as go
import json

# Função para carregar dados do arquivo JSON
def load_room_data(json_file, room_key):
    with open(json_file, 'r') as file:
        data = json.load(file)
    return data.get(room_key, None)

# Função para visualizar a sala em 3D com superfícies identificadas e arestas
def plot_3d_room_with_labels_and_edges(room_data, room_key=None):
    if room_data is None:
        print(f"Erro: Sala '{room_key}' não encontrada no arquivo JSON.")
        return

    dimensions = room_data['dimension']
    x_len, y_len, z_len = dimensions

    # Definir os vértices da sala
    vertices = [
        (0, 0, 0), (x_len, 0, 0), (x_len, y_len, 0), (0, y_len, 0),  # Base inferior
        (0, 0, z_len), (x_len, 0, z_len), (x_len, y_len, z_len), (0, y_len, z_len)  # Topo
    ]

    # Definir as arestas conectando os vértices
    edges = [
        (0, 1), (1, 2), (2, 3), (3, 0),  # Base inferior
        (4, 5), (5, 6), (6, 7), (7, 4),  # Topo
        (0, 4), (1, 5), (2, 6), (3, 7)   # Conexões verticais
    ]

    # Definir as superfícies e suas cores
    surfaces = {
        'L_1 (Frente)': {'x': [0, 0, 0, 0], 'y': [0, y_len, y_len, 0], 'z': [0, 0, z_len, z_len], 'color': 'yellow'},
        'L_2 (Trás)': {'x': [x_len, x_len, x_len, x_len], 'y': [0, y_len, y_len, 0], 'z': [0, 0, z_len, z_len], 'color': 'blue'},
        'L_3 (Esquerda)': {'x': [0, x_len, x_len, 0], 'y': [0, 0, 0, 0], 'z': [0, 0, z_len, z_len], 'color': 'red'},
        'L_4 (Direita)': {'x': [0, x_len, x_len, 0], 'y': [y_len, y_len, y_len, y_len], 'z': [0, 0, z_len, z_len], 'color': 'green'},
        'L_5 (Teto)': {'x': [0, x_len, x_len, 0], 'y': [0, 0, y_len, y_len], 'z': [z_len, z_len, z_len, z_len], 'color': 'orange'},
        'L_6 (Chão)': {'x': [0, x_len, x_len, 0], 'y': [0, 0, y_len, y_len], 'z': [0, 0, 0, 0], 'color': 'cyan'}
    }

    # Criar o layout 3D com Plotly
    fig = go.Figure()

    # Adicionar as superfícies coloridas com identificação
    for surface_name, surface_data in surfaces.items():
        fig.add_trace(go.Mesh3d(
            x=surface_data['x'],
            y=surface_data['y'],
            z=surface_data['z'],
            color=surface_data['color'],
            opacity=0.6,
            name=surface_name
        ))

        # Calcular o ponto central da superfície para o rótulo
        center_x = sum(surface_data['x']) / len(surface_data['x'])
        center_y = sum(surface_data['y']) / len(surface_data['y'])
        center_z = sum(surface_data['z']) / len(surface_data['z'])

        fig.add_trace(go.Scatter3d(
            x=[center_x],
            y=[center_y],
            z=[center_z],
            mode='text',
            text=surface_name.split()[0],
            textfont=dict(color='black', size=14),
            showlegend=False
        ))

    # Adicionar as arestas da sala
    for edge in edges:
        x_coords = [vertices[edge[0]][0], vertices[edge[1]][0]]
        y_coords = [vertices[edge[0]][1], vertices[edge[1]][1]]
        z_coords = [vertices[edge[0]][2], vertices[edge[1]][2]]

        fig.add_trace(go.Scatter3d(
            x=x_coords,
            y=y_coords,
            z=z_coords,
            mode='lines',
            line=dict(color='black', width=4),
            showlegend=False
        ))

    # Configurações da visualização
    fig.update_layout(
        title=f"Visualização 3D da Sala - {room_key}" if room_key else "Visualização 3D da Sala",
        scene=dict(
            xaxis_title="X (m)",
            yaxis_title="Y (m)",
            zaxis_title="Z (m)",
            aspectmode='data'
        ),
        legend_title="Superfícies",
        margin=dict(l=0, r=0, t=30, b=0)
    )

    fig.show()

# Caminho do arquivo JSON
json_file_path = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/conf_room_setup_2.json'

# Solicitar entrada do usuário
room_key = input("Digite a sala que deseja visualizar (ex: room_0): ")

# Carregar dados da sala escolhida
room_data = load_room_data(json_file_path, room_key)

# Visualizar a sala com rótulos e arestas
plot_3d_room_with_labels_and_edges(room_data, room_key=room_key)

"""SALVANDO EM .parquet"""

from google.colab import drive
drive.mount('/content/drive')

pip install pyarrow

pip install fastparquet

import json
import pandas as pd
import numpy as np

# Caminhos para os arquivos JSON

room_file = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/conf_room_setup_2.json'
source_file = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/conf_source_2.json'
receiver_file = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/conf_receivers_2.json'
noise_file = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/conf_noise_source_2.json'
sim_params_file = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/conf_sim_params.json'

# Carregar os arquivos JSON
with open(room_file, 'r') as rf, open(source_file, 'r') as sf, open(receiver_file, 'r') as rcf, open(noise_file, 'r') as nf, open(sim_params_file, 'r') as spf:
    rooms = json.load(rf)
    sources = json.load(sf)
    receivers = json.load(rcf)
    noises = json.load(nf)
    sim_params = json.load(spf)["simulation_params"]

# Listas para armazenar dados achatados
room_list = []
source_list = []
receiver_list = []
noise_list = []

# Processar cada sala
for room_key in rooms.keys():
    room_data = rooms[room_key]
    source_data = sources[room_key]
    receiver_data = receivers[room_key]
    noise_data = noises[room_key]

    # Dimensões da sala
    room_entry = {
        "room_key": room_key,
        "dimensions": room_data["dimension"],
        "temperature": room_data.get("temperature", -1),
        "humidity": room_data.get("humidity", -1),
        "absorption_coefficients": room_data.get("surface", {}).get("absorption", []),
        "diffusion_coefficients": room_data.get("surface", {}).get("diffusion", []),
        "frequencies": room_data.get("surface", {}).get("frequency", [])
    }
    room_list.append(room_entry)

    # Fontes
    for i, pos in enumerate(source_data["source_pos"]):
        source_entry = {
            "room_key": room_key,
            "source_index": i,
            "position": pos,
            "description": source_data["source_description"][i],
            "direction": source_data["source_direction"][i] if "source_direction" in source_data else [0, 0, 0]
        }
        source_list.append(source_entry)

    # Receivers
    for i, barycenter in enumerate(receiver_data["barycenter"]):
        receiver_entry = {
            "room_key": room_key,
            "receiver_index": i,
            "barycenter": barycenter,
            "mic_pos_1": receiver_data["mic_pos_1"][i],
            "mic_pos_2": receiver_data["mic_pos_2"][i],
            "direction": receiver_data["direction"][i] if "direction" in receiver_data else [0, 0, 0]
        }
        receiver_list.append(receiver_entry)

    # Fontes de Ruído
    for i, pos in enumerate(noise_data["source_pos"]):
        noise_entry = {
            "room_key": room_key,
            "noise_index": i,
            "position": pos,
            "description": noise_data["source_description"][i],
            "direction": noise_data["source_direction"][i] if "source_direction" in noise_data else [0, 0, 0]
        }
        noise_list.append(noise_entry)

# Converter listas em DataFrames
room_df = pd.DataFrame(room_list)
source_df = pd.DataFrame(source_list)
receiver_df = pd.DataFrame(receiver_list)
noise_df = pd.DataFrame(noise_list)

# Salvar como arquivos Parquet
output_dir = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas'

room_df.to_parquet(f"{output_dir}/rooms.parquet", index=False)
source_df.to_parquet(f"{output_dir}/sources.parquet", index=False)
receiver_df.to_parquet(f"{output_dir}/receivers.parquet", index=False)
noise_df.to_parquet(f"{output_dir}/noises.parquet", index=False)

print(f"Dados salvos em formato Parquet em: {output_dir}")

import pandas as pd

# Caminhos para os arquivos Parquet
noises_path = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/noises.parquet'
receivers_path = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/receivers.parquet'
rooms_path = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/rooms.parquet'
sources_path = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/sources.parquet'


# Ler os arquivos Parquet
noises_df = pd.read_parquet(noises_path)
receivers_df = pd.read_parquet(receivers_path)
rooms_df = pd.read_parquet(rooms_path)
sources_df = pd.read_parquet(sources_path)

# Exibir os dados carregados
print("Noises DataFrame:")
print(noises_df.head())

print("\nReceivers DataFrame:")
print(receivers_df.head())

print("\nRooms DataFrame:")
print(rooms_df.head())

print("\nSources DataFrame:")
print(sources_df.head())

import json
import pandas as pd
import numpy as np

# Caminhos para os arquivos Parquet
output_dir = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas'
noises_path = f"{output_dir}/noises.parquet"
receivers_path = f"{output_dir}/receivers.parquet"
rooms_path = f"{output_dir}/rooms.parquet"
sources_path = f"{output_dir}/sources.parquet"

# Carregar os arquivos Parquet
room_df = pd.read_parquet(rooms_path)
source_df = pd.read_parquet(sources_path)
receiver_df = pd.read_parquet(receivers_path)
noise_df = pd.read_parquet(noises_path)

# Função para selecionar um coeficiente de absorção específica
def get_absorption_coefficient(rooms_df, room_key, frequency, side):
    abs_coeff_json = rooms_df.loc[rooms_df["room_key"] == room_key, "absorption_coefficients"].values[0]
    abs_coeff = json.loads(abs_coeff_json) if isinstance(abs_coeff_json, str) else abs_coeff_json
    key = f"{room_key}/Coeficiente_Absorcao_F_{frequency}_L_{side}"
    return abs_coeff.get(key, None)  # Retorna None se a chave não existir

# Solicitar entrada do usuário
room_key = input("Digite a sala (ex: room_0): ")
frequency = input("Digite a frequência (ex: 4000): ")
side = input("Digite o lado (ex: 2): ")

# Buscar e imprimir o coeficiente
coefficient = get_absorption_coefficient(room_df, room_key, frequency, side)
print(f"Coeficiente de absorção para {room_key}, frequência {frequency} Hz, lado {side}: {coefficient}")

"""DELIMITANDO REGIÕES DO ESPAÇO PARA RUIDOS"""

import json
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from tabulate import tabulate

# Caminhos para os arquivos Parquet
output_dir = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas'
noises_path = f"{output_dir}/noises.parquet"
receivers_path = f"{output_dir}/receivers.parquet"
rooms_path = f"{output_dir}/rooms.parquet"
sources_path = f"{output_dir}/sources.parquet"

# Carregar os arquivos Parquet
room_df = pd.read_parquet(rooms_path)
source_df = pd.read_parquet(sources_path)
receiver_df = pd.read_parquet(receivers_path)
noise_df = pd.read_parquet(noises_path)

# Função para verificar perpendicularidade
def is_perpendicular(vector1, vector2, tolerance=1e-6):
    if np.linalg.norm(vector1) == 0 or np.linalg.norm(vector2) == 0:
        return "N/A"  # Retorna "N/A" se algum dos vetores for nulo
    dot_product = np.dot(vector1, vector2)
    return "Sim" if abs(dot_product) < tolerance else "Não"

# Função para calcular a distância entre microfones e verificar perpendicularidade
def calculate_microphone_distances(receivers_data):
    table_data = []
    for idx, row in receivers_data.iterrows():
        mic1 = np.array(row['mic_pos_1'])
        mic2 = np.array(row['mic_pos_2'])
        direction = np.array(row['direction'])
        distance = np.linalg.norm(mic1 - mic2)
        base_vector = mic1 - mic2
        if np.linalg.norm(base_vector) != 0:
            base_vector = base_vector / np.linalg.norm(base_vector)
        perpendicular = is_perpendicular(base_vector, direction)
        table_data.append([idx, round(distance, 4), perpendicular])
    print(tabulate(table_data, headers=["Receptor", "Distância entre Microfones (m)", "Direção Perpendicular"], tablefmt="grid"))

# Função para adicionar vetores de direção com cone na extremidade
def add_direction_vectors(fig, positions, directions, color, name):
    for pos, dir_vec in zip(positions.T, directions.T):
        norm = np.linalg.norm(dir_vec)
        if norm > 0:
            unit_vector = dir_vec / norm
            end_point = pos + 0.3 * unit_vector
            # Linha indicando a direção
            fig.add_trace(go.Scatter3d(
                x=[pos[0], end_point[0]],
                y=[pos[1], end_point[1]],
                z=[pos[2], end_point[2]],
                mode='lines',
                line=dict(color=color, width=4),
                name=name
            ))
            # Cone para indicar o sentido
            fig.add_trace(go.Cone(
                x=[end_point[0]],
                y=[end_point[1]],
                z=[end_point[2]],
                u=[unit_vector[0]],
                v=[unit_vector[1]],
                w=[unit_vector[2]],
                sizemode="absolute",
                sizeref=0.15,
                colorscale=[[0, color], [1, color]],
                showscale=False,
                name=f"Cone {name}"
            ))

# Função para adicionar uma caixa (volume) translúcida ao gráfico
def add_box(fig, xmin, xmax, ymin, ymax, zmin, zmax, color, opacity, name):
    # Define os 8 vértices da caixa
    x = [xmin, xmax, xmax, xmin, xmin, xmax, xmax, xmin]
    y = [ymin, ymin, ymax, ymax, ymin, ymin, ymax, ymax]
    z = [zmin, zmin, zmin, zmin, zmax, zmax, zmax, zmax]
    # Definir as faces (cada face dividida em 2 triângulos)
    i = [0, 0, 4, 4, 0, 0, 3, 3, 0, 0, 1, 1]
    j = [1, 2, 5, 6, 1, 5, 2, 6, 3, 7, 2, 6]
    k = [2, 3, 6, 7, 5, 4, 6, 7, 7, 4, 6, 5]

    fig.add_trace(go.Mesh3d(
        x=x, y=y, z=z,
        i=i, j=j, k=k,
        opacity=opacity,
        color=color,
        name=name,
        showscale=False
    ))

# Função para visualizar a sala em 3D com volumes de ruído e vetores de direção
def plot_3d_room(room_size, arrs, mics, srcs_dir, srcs_omn, srcs_nse,
                 dir_srcs, dir_nse, dir_mics, room_key):
    fig = go.Figure()

    # Desenhar as bordas da sala (Shoebox)
    for z in [0, room_size[2]]:
        for y in [0, room_size[1]]:
            fig.add_trace(go.Scatter3d(
                x=[0, room_size[0]], y=[y, y], z=[z, z],
                mode='lines', line=dict(color='black')
            ))
        for x in [0, room_size[0]]:
            fig.add_trace(go.Scatter3d(
                x=[x, x], y=[0, room_size[1]], z=[z, z],
                mode='lines', line=dict(color='black')
            ))
    for x in [0, room_size[0]]:
        for y in [0, room_size[1]]:
            fig.add_trace(go.Scatter3d(
                x=[x, x], y=[y, y], z=[0, room_size[2]],
                mode='lines', line=dict(color='black')
            ))

    # Plot dos arrays de microfones (barycentros)
    fig.add_trace(go.Scatter3d(
        x=arrs[0, :], y=arrs[1, :], z=arrs[2, :],
        mode='markers', marker=dict(size=6, color='black', symbol='cross'),
        name='Baricentros do Array'
    ))

    # Plot dos microfones individuais
    fig.add_trace(go.Scatter3d(
        x=mics[0, :], y=mics[1, :], z=mics[2, :],
        mode='markers', marker=dict(size=6, color='blue'),
        name='Microfones'
    ))

    # Plot das fontes direcionais
    if srcs_dir.size > 0:
        fig.add_trace(go.Scatter3d(
            x=srcs_dir[0, :], y=srcs_dir[1, :], z=srcs_dir[2, :],
            mode='markers', marker=dict(size=8, color='red', symbol='diamond'),
            name='Fontes Direcionais'
        ))
    # Plot das fontes omnidirecionais
    if srcs_omn.size > 0:
        fig.add_trace(go.Scatter3d(
            x=srcs_omn[0, :], y=srcs_omn[1, :], z=srcs_omn[2, :],
            mode='markers', marker=dict(size=8, color='black', symbol='circle'),
            name='Fontes Omnidirecionais'
        ))
    # Plot das fontes de ruído
    if srcs_nse.size > 0:
        fig.add_trace(go.Scatter3d(
            x=srcs_nse[0, :], y=srcs_nse[1, :], z=srcs_nse[2, :],
            mode='markers', marker=dict(size=8, color='orange', symbol='cross'),
            name='Fontes de Ruído'
        ))

    # Adicionar vetores de direção para fontes direcionais, ruído e microfones
    if dir_srcs.size > 0:
        add_direction_vectors(fig, srcs_dir, dir_srcs, 'red', 'Direção Fontes')
    if dir_nse.size > 0:
        add_direction_vectors(fig, srcs_nse, dir_nse, 'orange', 'Direção Ruído')
    if dir_mics.size > 0:
        add_direction_vectors(fig, arrs, dir_mics, 'blue', 'Direção Microfones')

    # --- Adicionando volumes translucidos para os limites dos ruídos ---
    # Definindo parâmetros (assumindo safety_distance = 0.5)
    safety_distance = 0.5
    x_center = room_size[0] / 2
    y_center = room_size[1] / 2
    z_top = room_size[2]

    # Ruído 2: 30~50 cm abaixo do teto
    add_box(fig,
            xmin=safety_distance,
            xmax=room_size[0] - safety_distance,
            ymin=safety_distance,
            ymax=room_size[1] - safety_distance,
            zmin=z_top - 0.5,
            zmax=z_top - 0.3,
            color='lightgreen',
            opacity=0.3,
            name='Volume Ruído 2')

    # Ruído 3: 20~40 cm da lateral esquerda
    add_box(fig,
            xmin=0.3,
            xmax=room_size[0] - 0.3,
            ymin=safety_distance + 0.2,
            ymax=safety_distance + 0.4,
            zmin=0.3,
            zmax=z_top - 0.3,
            color='lightblue',
            opacity=0.3,
            name='Volume Ruído 3')

    # Ruído 4: 20~40 cm da lateral direita
    add_box(fig,
            xmin=0.3,
            xmax=room_size[0] - 0.3,
            ymin=room_size[1] - (safety_distance + 0.4),
            ymax=room_size[1] - (safety_distance + 0.2),
            zmin=0.3,
            zmax=z_top - 0.3,
            color='lightpink',
            opacity=0.3,
            name='Volume Ruído 4')

    # Ruído 5: 30~50 cm acima do chão
    add_box(fig,
            xmin=safety_distance,
            xmax=room_size[0] - safety_distance,
            ymin=safety_distance,
            ymax=room_size[1] - safety_distance,
            zmin=0.3,
            zmax=0.5,
            color='lightyellow',
            opacity=0.3,
            name='Volume Ruído 5')
    # --- Fim dos volumes ---

    fig.update_layout(
        title=f"Configuração 3D da Sala: {room_key}",
        scene=dict(
            xaxis_title='X (m)',
            yaxis_title='Y (m)',
            zaxis_title='Z (m)',
            aspectmode='data'
        )
    )
    fig.show()

# --- Execução ---

room_key = input("Digite a sala (ex: room_0): ")

room_data = room_df[room_df['room_key'] == room_key].iloc[0]
source_data = source_df[source_df['room_key'] == room_key]
receivers_data = receiver_df[receiver_df['room_key'] == room_key]
noises_data = noise_df[noise_df['room_key'] == room_key]

room_size = np.array(room_data['dimensions'])

arrs = np.stack(receivers_data['barycenter'].apply(np.array).to_numpy()).T
mics = np.concatenate([
    np.stack(receivers_data['mic_pos_1'].apply(np.array).to_numpy()),
    np.stack(receivers_data['mic_pos_2'].apply(np.array).to_numpy())
], axis=0).T

# Fontes omnidirecionais (descrição "omni")
if not source_data[source_data['description'] == 'omni'].empty:
    srcs_omn = np.stack(source_data[source_data['description'] == 'omni']['position'].apply(np.array).to_numpy()).T
else:
    srcs_omn = np.array([])

# Fontes direcionais: registros com descrição diferente de "omni"
directional_data = source_data[source_data['description'] != 'omni']
if not directional_data.empty:
    srcs_dir = np.stack(directional_data['position'].apply(np.array).to_numpy()).T
    dir_srcs = np.stack(directional_data['direction'].apply(np.array).to_numpy()).T
else:
    srcs_dir = np.array([])
    dir_srcs = np.array([])

# Fontes de ruído
if not noises_data.empty:
    srcs_nse = np.stack(noises_data['position'].apply(np.array).to_numpy()).T
    dir_nse = np.stack(noises_data['direction'].apply(np.array).to_numpy()).T
else:
    srcs_nse = np.array([])
    dir_nse = np.array([])

# Direções dos microfones
if not receivers_data.empty:
    dir_mics = np.stack(receivers_data['direction'].apply(np.array).to_numpy()).T
else:
    dir_mics = np.array([])

calculate_microphone_distances(receivers_data)
plot_3d_room(room_size, arrs, mics, srcs_dir, srcs_omn, srcs_nse, dir_srcs, dir_nse, dir_mics, room_key)

"""# GERANDO RESPOSTAS AO IMPULSO"""

from google.colab import drive
drive.mount('/content/drive')

"""# INSTALANDO gpuRIR

"""

!git clone https://github.com/DavidDiazGuerra/gpuRIR.git

!pip install cmake
!apt-get install libcuRAND-dev

!pip install https://github.com/DavidDiazGuerra/gpuRIR/zipball/master

!apt-get install cuda

"""COMPARANDO OS DOIS MÉTODOS DO SIMULADOR: (gpuRIR e gpuRIR_bind)"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script para comparar duas simulações de Resposta ao Impulso da Sala (RIR):
- Código 1: Método gpuRIR (β calculado a partir de T60 e abs_weights)
- Código 2: Método gpuRIR_bind com coeficientes β definidos explicitamente a partir de α

Ambos os métodos usam os mesmos parâmetros físicos (sala, posições, fs, etc.) e os resultados
são exibidos sobrepostos em um único gráfico interativo, além de serem salvos em arquivos WAV separados.
"""

import numpy as np
import numpy.matlib
from math import ceil
import plotly.graph_objects as go
import soundfile as sf

# ============================
# Parâmetros Comuns para ambos os Códigos
# ============================
room_sz = [3, 3, 2.5]                   # Dimensões da sala [m]
fs = 16000.0                            # Frequência de amostragem [Hz]
pos_src = np.array([[1, 2.9, 0.5],
                    [1, 2,   0.5]])        # Posições das fontes [m]
pos_rcv = np.array([[2.0, 2.0, 1.5]])     # Posição do receptor [m]

# Parâmetros para o método baseado em T60 (Código 1)
T60 = 0.4                               # Tempo de reverberação (T60) [s]
att_diff = 15.0                         # Atenuação para início do modelo difuso (dB)
att_max = 60.0                          # Atenuação máxima (dB)
abs_weights = [0.6]*5 + [0.6]             # Coeficientes de absorção (usados para calcular β)

# Parâmetros comuns para número de imagens e transição difusa
# (NB: esses parâmetros influenciam a duração e a resolução da simulação)
# Para o método gpuRIR, os mesmos são calculados a partir de T60;
# Para gpuRIR_bind, usaremos os mesmos valores para fins de comparação.
nb_img = None       # Será definido conforme cada método
Tdiff = None        # Tempo de transição para o modelo difuso
Tmax  = None        # Duração da RIR (em segundos)

# Padrões polares e orientações
mic_pattern  = "card"                   # Receptor: cardioide
spkr_pattern = "omni"                   # Fonte: omnidirecional
orV_rcv = np.array([[0, 1, 0]])           # Orientação do receptor (necessária para 'card')
orV_src = None                          # Não necessário para fontes omni

# ============================
# Simulação com gpuRIR (Código 1)
# ============================
import gpuRIR

# Configura o simulador para gpuRIR
gpuRIR.activateMixedPrecision(False)
gpuRIR.activateLUT(True)

# Cálculo dos parâmetros de simulação utilizando o método de Sabine
beta_code1 = gpuRIR.beta_SabineEstimation(room_sz, T60, abs_weights=abs_weights)
Tdiff = gpuRIR.att2t_SabineEstimator(att_diff, T60)
Tmax  = gpuRIR.att2t_SabineEstimator(att_max, T60)
nb_img = gpuRIR.t2n(Tdiff, room_sz)

# Imprime o valor da variável nb_img
print("nb_img =", nb_img)

# Garante a orientação para cada receptor (caso haja mais de um)
orV_rcv_code1 = np.matlib.repmat(orV_rcv[0], pos_rcv.shape[0], 1)

# Executa a simulação com gpuRIR
RIRs_code1 = gpuRIR.simulateRIR(room_sz, beta_code1, pos_src, pos_rcv, nb_img, Tmax, fs,
                                Tdiff=Tdiff, orV_rcv=orV_rcv_code1, mic_pattern=mic_pattern)

# Seleciona a RIR da primeira fonte e do primeiro receptor e gera o vetor de tempo
rir1 = RIRs_code1[0, 0, :]
nSamples1 = int(ceil(Tmax * fs))
t1 = np.arange(nSamples1) / fs

# ============================
# Simulação com gpuRIR_bind (Código 2)
# ============================
import gpuRIR_bind

# Neste método, os coeficientes de reflexão são definidos explicitamente.
# Suponha que você tenha os coeficientes de absorção para intensidade (α)
# Ordem: [alpha_x0, alpha_x1, alpha_y0, alpha_y1, alpha_z0, alpha_z1]
alpha = [0.25, 0.12, 0.2, 0.18, 0.12, 0.19]

# Converte os coeficientes de absorção (intensidade) para coeficientes de reflexão (amplitude)
beta_code2 = np.sqrt(1 - np.array(alpha))

# Inicializa o simulador gpuRIR_bind
gpuRIR_bind_simulator = gpuRIR_bind.gpuRIR_bind(mixed_precision=False)

def simulateRIR_bind(room_sz, beta, pos_src, pos_rcv, nb_img, Tmax, fs, Tdiff=None,
                     spkr_pattern="omni", mic_pattern="card",
                     orV_src=None, orV_rcv=None, c=343.0):
    """
    Simula a Resposta ao Impulso da Sala (RIR) usando gpuRIR_bind com
    os coeficientes de reflexão (β) definidos explicitamente.

    Se os coeficientes originais forem de absorção (α) para intensidade,
    converta-os previamente usando: beta = sqrt(1 - α)
    """
    # Dicionário dos padrões polares
    polar_patterns = {
        "omni": 0,
        "card": 1,
        "homni": 2,
        "hypcard": 3,
        "subcard": 4,
        "bidir": 5,
    }

    # Conversão dos dados para float32, garantindo que a memória seja contígua
    pos_src = pos_src.astype('float32', order='C', copy=False)
    pos_rcv = pos_rcv.astype('float32', order='C', copy=False)

    if Tdiff is None:
        Tdiff = Tmax
    if orV_rcv is None:
        orV_rcv = np.zeros_like(pos_rcv)
    else:
        orV_rcv = orV_rcv.astype('float32', order='C', copy=False)
    if orV_src is None:
        orV_src = np.zeros_like(pos_src)
    else:
        orV_src = orV_src.astype('float32', order='C', copy=False)

    return gpuRIR_bind_simulator.simulateRIR_bind(
        room_sz, beta, pos_src, pos_rcv, orV_src, orV_rcv,
        polar_patterns[spkr_pattern], polar_patterns[mic_pattern],
        nb_img, Tdiff, Tmax, fs, c
    )

# Para manter consistência na comparação, usamos os mesmos parâmetros nb_img, Tmax, Tdiff
# já definidos na simulação do Código 1
RIRs_code2 = simulateRIR_bind(room_sz, beta_code2, pos_src, pos_rcv, nb_img, Tmax, fs, Tdiff,
                              spkr_pattern=spkr_pattern, mic_pattern=mic_pattern,
                              orV_src=orV_src, orV_rcv=orV_rcv, c=343.0)

# Seleciona a RIR da primeira fonte e do primeiro receptor e gera o vetor de tempo
rir2 = RIRs_code2[0, 0, :]
nSamples2 = int(ceil(Tmax * fs))
t2 = np.arange(nSamples2) / fs


# ============================
# Criação do Gráfico de Comparação Sobreposto com Cores Translúcidas
# ============================
fig = go.Figure()

fig.add_trace(go.Scatter(
    x=t1,
    y=rir1,
    mode='lines',
    name='gpuRIR (β via T60)',
    line=dict(color='rgba(0, 0, 0, 0.5)')   # Preto translúcido
))

fig.add_trace(go.Scatter(
    x=t2,
    y=rir2,
    mode='lines',
    name='gpuRIR_bind (β via α, parâmetros escolhidos)',
    line=dict(color='rgba(255, 0, 0, 0.5)')   # Vermelho translúcido
))

fig.update_layout(
    title="Comparação de RIR: gpuRIR vs gpuRIR_bind",
    xaxis_title="Tempo (s)",
    yaxis_title="Amplitude",
    template="plotly_white"
)

fig.show()

# ============================
# Salvando Cada RIR em Arquivos WAV Diferentes
# ============================
output_wav_path1 = "rir_gpuRIR.wav"
sf.write(output_wav_path1, rir1, int(fs))
print(f"RIR do método gpuRIR salva em WAV em: {output_wav_path1}")

output_wav_path2 = "rir_gpuRIR_bind.wav"
sf.write(output_wav_path2, rir2, int(fs))
print(f"RIR do método gpuRIR_bind salva em WAV em: {output_wav_path2}")

"""PARA CODIGO 2 TOTALMENTE INDEPENDENTE"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script para comparar duas simulações de Resposta ao Impulso da Sala (RIR):
- Código 1: Método gpuRIR (β calculado a partir de T60 e abs_weights)
- Código 2: Método gpuRIR_bind com coeficientes β definidos explicitamente a partir de α,
            utilizando parâmetros escolhidos independentemente de T60.

Ambos os métodos usam os mesmos parâmetros físicos (sala, posições, fs, etc.) e os resultados
são exibidos sobrepostos em um único gráfico interativo, além de serem salvos em arquivos WAV separados.
"""

import numpy as np
import numpy.matlib
from math import ceil
import plotly.graph_objects as go
import soundfile as sf

# ============================
# Parâmetros Comuns para ambos os métodos
# ============================
room_sz = [3, 3, 2.5]                   # Dimensões da sala [m]
fs = 16000.0                            # Frequência de amostragem [Hz]
pos_src = np.array([[1, 2.9, 0.5],
                    [1, 2,   0.5]])       # Posições das fontes [m]
pos_rcv = np.array([[2.0, 2.0, 1.5]])    # Posição do receptor [m]

# Parâmetros para o método baseado em T60 (Código 1)
T60 = 0.3                             # Tempo de reverberação (T60) [s]
att_diff = 15.0                         # Atenuação para início do modelo difuso (dB)
att_max = 60.0                          # Atenuação máxima (dB)
abs_weights = [0.9]*5 + [1]             # Coeficientes de absorção (para cálculo de β)

# Parâmetros comuns para padrões polares e orientações
mic_pattern  = "card"                   # Padrão do receptor (cardioide)
spkr_pattern = "omni"                   # Padrão da fonte (omnidirecional)
orV_rcv = np.array([[0, 1, 0]])           # Orientação do receptor (necessária para 'card')
orV_src = None                          # Não necessário para fontes omni

# ============================
# Simulação com gpuRIR (Código 1)
# ============================
import gpuRIR

# Configura o simulador para gpuRIR
gpuRIR.activateMixedPrecision(False)
gpuRIR.activateLUT(True)

# Cálculo dos parâmetros (baseado em T60)
beta_code1 = gpuRIR.beta_SabineEstimation(room_sz, T60, abs_weights=abs_weights)
Tdiff = gpuRIR.att2t_SabineEstimator(att_diff, T60)
Tmax  = gpuRIR.att2t_SabineEstimator(att_max, T60)
nb_img = gpuRIR.t2n(Tdiff, room_sz)

# Imprime o valor de nb_img para verificação (este é calculado com T60)
print("nb_img =", nb_img)

# Garante a orientação para cada receptor (caso haja mais de um)
orV_rcv_code1 = np.matlib.repmat(orV_rcv[0], pos_rcv.shape[0], 1)

# Executa a simulação com gpuRIR
RIRs_code1 = gpuRIR.simulateRIR(room_sz, beta_code1, pos_src, pos_rcv, nb_img, Tmax, fs,
                                Tdiff=Tdiff, orV_rcv=orV_rcv_code1, mic_pattern=mic_pattern)
rir1 = RIRs_code1[0, 0, :]
nSamples1 = int(ceil(Tmax * fs))
t1 = np.arange(nSamples1) / fs

# ============================
# Simulação com gpuRIR_bind (Código 2)
# ============================
import gpuRIR_bind

# Neste método, os coeficientes de reflexão são definidos explicitamente.
# Suponha que você tenha os coeficientes de absorção (α)
# Ordem: [alpha_x0, alpha_x1, alpha_y0, alpha_y1, alpha_z0, alpha_z1]
alpha = [0.45, 0.32, 0.77, 0.38, 0.22, 0.29]
beta_code2 = np.sqrt(1 - np.array(alpha))

# Inicializa o simulador gpuRIR_bind
gpuRIR_bind_simulator = gpuRIR_bind.gpuRIR_bind(mixed_precision=False)

def simulateRIR_bind(room_sz, beta, pos_src, pos_rcv, nb_img, Tmax, fs, Tdiff=None,
                     spkr_pattern="omni", mic_pattern="card", orV_src=None, orV_rcv=None, c=343.0):
    """
    Simula a RIR usando gpuRIR_bind com coeficientes de reflexão (β) definidos explicitamente.
    (Para coeficientes de absorção (α), converta-os com: beta = sqrt(1 - α))
    """
    polar_patterns = {
        "omni": 0,
        "card": 1,
        "homni": 2,
        "hypcard": 3,
        "subcard": 4,
        "bidir": 5,
    }
    pos_src = pos_src.astype('float32', order='C', copy=False)
    pos_rcv = pos_rcv.astype('float32', order='C', copy=False)
    if Tdiff is None:
        Tdiff = Tmax
    if orV_rcv is None:
        orV_rcv = np.zeros_like(pos_rcv)
    else:
        orV_rcv = orV_rcv.astype('float32', order='C', copy=False)
    if orV_src is None:
        orV_src = np.zeros_like(pos_src)
    else:
        orV_src = orV_src.astype('float32', order='C', copy=False)

    return gpuRIR_bind_simulator.simulateRIR_bind(
        room_sz, beta, pos_src, pos_rcv, orV_src, orV_rcv,
        polar_patterns[spkr_pattern], polar_patterns[mic_pattern],
        nb_img, Tdiff, Tmax, fs, c
    )

# Para o método gpuRIR_bind, escolhemos os parâmetros manualmente (independentes de T60)
Tdiff_bind = 0.075           # Exemplo: 0.1 s para início do modelo difuso
Tmax_bind = 1.0              # Exemplo: 1 segundo de duração total da RIR
nb_img_bind = [30, 40, 30]    # Exemplo: 30 imagens em cada dimensão

# Executa a simulação com gpuRIR_bind usando os parâmetros escolhidos
RIRs_code2 = simulateRIR_bind(room_sz, beta_code2, pos_src, pos_rcv, nb_img_bind, Tmax_bind, fs, Tdiff=Tdiff_bind,
                              spkr_pattern=spkr_pattern, mic_pattern=mic_pattern,
                              orV_src=orV_src, orV_rcv=orV_rcv, c=343.0)
rir2 = RIRs_code2[0, 0, :]
nSamples2 = int(ceil(Tmax_bind * fs))
t2 = np.arange(nSamples2) / fs

# ============================
# Criação do Gráfico de Comparação Sobreposto com Cores Translúcidas
# ============================
fig = go.Figure()

fig.add_trace(go.Scatter(
    x=t1,
    y=rir1,
    mode='lines',
    name='gpuRIR (β via T60)',
    line=dict(color='rgba(0, 0, 0, 0.5)')   # Preto translúcido
))

fig.add_trace(go.Scatter(
    x=t2,
    y=rir2,
    mode='lines',
    name='gpuRIR_bind (β via α, parâmetros escolhidos)',
    line=dict(color='rgba(255, 0, 0, 0.5)')   # Vermelho translúcido
))

fig.update_layout(
    title="Comparação de RIR: gpuRIR vs gpuRIR_bind",
    xaxis_title="Tempo (s)",
    yaxis_title="Amplitude",
    template="plotly_white"
)

fig.show()

# ============================
# Salvando Cada RIR em Arquivos WAV Diferentes
# ============================
output_wav_path1 = "rir_gpuRIR.wav"
sf.write(output_wav_path1, rir1, int(fs))
print(f"RIR do método gpuRIR salva em WAV em: {output_wav_path1}")

output_wav_path2 = "rir_gpuRIR_bind.wav"
sf.write(output_wav_path2, rir2, int(fs))
print(f"RIR do método gpuRIR_bind salva em WAV em: {output_wav_path2}")

# ============================
# Impressão dos Parâmetros Utilizados
# ============================
print("Tmax =", Tmax)
print("Tdiff =", Tdiff)
print("nb_img =", nb_img)

"""CALCULANDO T60"""

pip install acoustics

import numpy as np
from scipy.io import wavfile
from scipy import stats

from acoustics.signal import bandpass
from acoustics.bands import (_check_band_type, octave_low, octave_high, third_low, third_high)

SOUNDSPEED = 343.0

def t60_impulse(file_path, bands, rt='t30'):
    """
    Compute the reverberation time T60 from a WAV impulse response for each target frequency band.

    :param file_path: Path to the WAV file containing the full-band impulse response.
    :param bands: NumPy array of target frequencies (defines octave or third bands).
    :param rt: Reverberation time estimator type (supports 't30', 't20', 't10' or 'edt').
    :returns: A NumPy array with the computed T60 (reverberation time) for each band.
    """
    # Ler o arquivo WAV
    fs, raw_signal = wavfile.read(file_path)

    # Determinar o tipo de banda (octave ou third)
    band_type = _check_band_type(bands)
    if band_type == 'octave':
        low = octave_low(bands[0], bands[-1])
        high = octave_high(bands[0], bands[-1])
    elif band_type == 'third':
        low = third_low(bands[0], bands[-1])
        high = third_high(bands[0], bands[-1])
    else:
        raise ValueError("Unsupported band type.")

    # Configurar os parâmetros do método baseado no tipo de RT
    rt = rt.lower()
    if rt == 't30':
        init = -5.0
        end = -35.0
        factor = 2.0
    elif rt == 't20':
        init = -5.0
        end = -25.0
        factor = 3.0
    elif rt == 't10':
        init = -5.0
        end = -15.0
        factor = 6.0
    elif rt == 'edt':
        init = 0.0
        end = -10.0
        factor = 6.0
    else:
        raise ValueError("Invalid RT estimator type. Use 't30', 't20', 't10' or 'edt'.")

    # Define um epsilon para evitar divisão por zero
    eps = 1e-12

    # Inicializa o array para armazenar os T60 para cada banda
    t60 = np.zeros(bands.size)

    # Para cada banda, aplicar o filtro, computar a integração de Schroeder e ajustar a regressão linear
    for i in range(bands.size):
        # Filtrar o sinal para a banda atual
        filtered_signal = bandpass(raw_signal, low[i], high[i], fs, order=8)
        # Normalizar o sinal filtrado (usando o valor máximo)
        norm_signal = np.abs(filtered_signal) / (np.max(np.abs(filtered_signal)) + eps)
        # Realizar a integração de Schroeder: soma cumulativa reversa dos quadrados
        sch = np.cumsum(norm_signal[::-1]**2)[::-1]
        # Converter a energia em dB (adiciona eps para evitar log de zero)
        sch_db = 10.0 * np.log10((sch + eps) / (np.max(sch) + eps))

        # Encontrar os índices correspondentes aos níveis dB desejados
        init_index = np.abs(sch_db - init).argmin()
        end_index  = np.abs(sch_db - end).argmin()
        if end_index <= init_index:
            t60[i] = np.nan
            continue

        # Construir o eixo temporal para a parte selecionada
        x = np.arange(init_index, end_index + 1) / fs
        y = sch_db[init_index:end_index + 1]

        # Realizar a regressão linear sobre o decaimento
        slope, intercept = stats.linregress(x, y)[0:2]
        if np.abs(slope) < 1e-12:
            t60[i] = np.nan
            continue

        # Determinar os tempos correspondentes aos níveis init e end usando a regressão
        t_start = (init - intercept) / slope
        t_end   = (end - intercept) / slope

        # Computar o T60 (multiplicando pelo fator que depende do método)
        t60[i] = factor * (t_end - t_start)

    return t60

# Arquivos de entrada
file_path_gpuRIR = "/content/rir_gpuRIR.wav"
file_path_gpuRIR_bind = "/content/rir_gpuRIR_bind.wav"

# Definindo as bandas de interesse (exemplo: bandas de oitava)
bands = np.array([125, 250, 500, 1000, 2000, 4000])

# Calcula o T60 para cada arquivo utilizando o estimador 't30'
computed_t60_gpuRIR = t60_impulse(file_path_gpuRIR, bands, rt='t30')
computed_t60_gpuRIR_bind = t60_impulse(file_path_gpuRIR_bind, bands, rt='t30')

print("Computed T60 values for gpuRIR:", computed_t60_gpuRIR)
print("Computed T60 values for gpuRIR_bind:", computed_t60_gpuRIR_bind)

"""para:

1. abs_weights = [1]*5 + [1]   

Computed T60 values for gpuRIR: [0.41546487 0.48122437 0.39607455 0.41137137 0.39362607 0.40416461]

2. abs_weights = [0.5]*5 + [0.5]  

Computed T60 values for gpuRIR: [0.41546487 0.48122437 0.39607455 0.41137137 0.39362607 0.40416461]

OBSERVAÇÃO:

1. PARA O CÓDIGO 1 (USANDO T60):

OS VALORES DE T6O FINAIS POR BANDA SE APROXIMAM DO T60 TARGET:

Computed T60 values: [0.46; 0.48; 0.44; 0.40;  0.41; 0.40]

FORTEMENTE DEPENDENTE DE T60 INPUT

2. PARA O CÓDIGO 2:


Computed T60 values DEPENDENTE DOS COEFICIENTES.

# COMPARAÇÃO ENTRE SIMULADORES

https://github.com/boeddeker/rirgen?tab=readme-ov-file

https://github.com/audiolabs/rir-generator
"""

pip install git+https://github.com/boeddeker/rirgen

pip install rir-generator

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script para comparar quatro simulações de Resposta ao Impulso da Sala (RIR):
- Código 1: gpuRIR (β calculado a partir de T60 e abs_weights)
- Código 2: gpuRIR_bind (β definido explicitamente a partir de α)
- Simulação com rir_generator
- Simulação com rirgen

Todos os métodos usam os mesmos parâmetros físicos (dimensões da sala, posições, fs, etc.)
e os resultados são exibidos sobrepostos em um gráfico interativo, além de serem salvos em arquivos WAV separados.
"""

import numpy as np
import numpy.matlib
from math import ceil
import plotly.graph_objects as go
import soundfile as sf

# ----------------------------
# Importa os módulos adicionais de simulação
# ----------------------------
import gpuRIR
import gpuRIR_bind
import rir_generator
import rirgen

# ============================
# Parâmetros Comuns para todos os métodos
# ============================
room_sz = [3, 3, 2.5]         # Dimensões da sala [m]
# Para os módulos rir_generator e rirgen, usamos a mesma sala:
room_dim = room_sz

fs = 16000.0                  # Frequência de amostragem [Hz]
pos_src = np.array([[1, 2.9, 0.5],
                    [1, 2,   0.5]])  # Posições das fontes [m]
pos_rcv = np.array([[2.0, 2.0, 1.5]])   # Posição do receptor [m]

# Parâmetros para o método baseado em T60 (usado em gpuRIR)
T60 = 0.4                     # Tempo de reverberação (T60) [s]
att_diff = 15.0               # Atenuação para início do modelo difuso (dB)
att_max = 60.0                # Atenuação máxima (dB)
abs_weights = [0.9]*5 + [0.5]   # Coeficientes de absorção para cálculo de β

# Parâmetros comuns para número de imagens e transição difusa
# Para gpuRIR os parâmetros são calculados a partir de T60.
Tdiff = None                  # Tempo de transição para o modelo difuso
Tmax = None                   # Duração da RIR (s)
nb_img = None                 # Número de imagens (a ser calculado)

# Padrões polares e orientações
mic_pattern  = "card"         # Padrão polar do receptor (cardioide)
spkr_pattern = "omni"         # Padrão polar da fonte (omnidirecional)
orV_rcv = np.array([[0, 1, 0]])  # Orientação do receptor (necessária para 'card')
orV_src = None                # Não necessário para fontes omni

# ----------------------------
# Simulação com gpuRIR (Código 1)
# ----------------------------
# Configura o simulador gpuRIR
gpuRIR.activateMixedPrecision(False)
gpuRIR.activateLUT(True)

# Cálculo dos parâmetros usando o método de Sabine
beta_code1 = gpuRIR.beta_SabineEstimation(room_sz, T60, abs_weights=abs_weights)
Tdiff = gpuRIR.att2t_SabineEstimator(att_diff, T60)
Tmax  = gpuRIR.att2t_SabineEstimator(att_max, T60)
nb_img = gpuRIR.t2n(Tdiff, room_sz)

# Imprime o valor de nb_img para verificação
print("nb_img =", nb_img)

# Garante a orientação para cada receptor (no caso de vários)
orV_rcv_code1 = np.matlib.repmat(orV_rcv[0], pos_rcv.shape[0], 1)

# Executa a simulação com gpuRIR
RIRs_code1 = gpuRIR.simulateRIR(room_sz, beta_code1, pos_src, pos_rcv, nb_img, Tmax, fs,
                                Tdiff=Tdiff, orV_rcv=orV_rcv_code1, mic_pattern=mic_pattern)
rir_gpuRIR = RIRs_code1[0, 0, :]

# ----------------------------
# Simulação com gpuRIR_bind (Código 2)
# ----------------------------
# ============================
# Simulação com gpuRIR_bind (Código 2)
# ============================
import gpuRIR_bind

# Neste método, os coeficientes de reflexão são definidos explicitamente.
# Suponha que você tenha os coeficientes de absorção (α)
# Ordem: [alpha_x0, alpha_x1, alpha_y0, alpha_y1, alpha_z0, alpha_z1]
alpha = [0.45, 0.32, 0.77, 0.38, 0.22, 0.29]
beta_code2 = np.sqrt(1 - np.array(alpha))

# Inicializa o simulador gpuRIR_bind
gpuRIR_bind_simulator = gpuRIR_bind.gpuRIR_bind(mixed_precision=False)

def simulateRIR_bind(room_sz, beta, pos_src, pos_rcv, nb_img, Tmax, fs, Tdiff=None,
                     spkr_pattern="omni", mic_pattern="card", orV_src=None, orV_rcv=None, c=343.0):
    """
    Simula a RIR usando gpuRIR_bind com coeficientes de reflexão (β) definidos explicitamente.
    (Para coeficientes de absorção (α), converta-os com: beta = sqrt(1 - α))
    """
    polar_patterns = {
        "omni": 0,
        "card": 1,
        "homni": 2,
        "hypcard": 3,
        "subcard": 4,
        "bidir": 5,
    }
    pos_src = pos_src.astype('float32', order='C', copy=False)
    pos_rcv = pos_rcv.astype('float32', order='C', copy=False)
    if Tdiff is None:
        Tdiff = Tmax
    if orV_rcv is None:
        orV_rcv = np.zeros_like(pos_rcv)
    else:
        orV_rcv = orV_rcv.astype('float32', order='C', copy=False)
    if orV_src is None:
        orV_src = np.zeros_like(pos_src)
    else:
        orV_src = orV_src.astype('float32', order='C', copy=False)

    return gpuRIR_bind_simulator.simulateRIR_bind(
        room_sz, beta, pos_src, pos_rcv, orV_src, orV_rcv,
        polar_patterns[spkr_pattern], polar_patterns[mic_pattern],
        nb_img, Tdiff, Tmax, fs, c
    )

# Para o método gpuRIR_bind, escolhemos os parâmetros manualmente (independentes de T60)
Tdiff_bind = 0.075           # Exemplo: 0.1 s para início do modelo difuso
Tmax_bind = 1.0              # Exemplo: 1 segundo de duração total da RIR
nb_img_bind = [30, 40, 30]    # Exemplo: 30 imagens em cada dimensão

# Executa a simulação com gpuRIR_bind usando os parâmetros escolhidos
RIRs_code2 = simulateRIR_bind(room_sz, beta_code2, pos_src, pos_rcv, nb_img_bind, Tmax_bind, fs, Tdiff=Tdiff_bind,
                              spkr_pattern=spkr_pattern, mic_pattern=mic_pattern,
                              orV_src=orV_src, orV_rcv=orV_rcv, c=343.0)
rir2 = RIRs_code2[0, 0, :]
nSamples2 = int(ceil(Tmax_bind * fs))
t2 = np.arange(nSamples2) / fs

# ----------------------------
# Simulação com rir_generator
# ----------------------------
# Para compatibilidade, usamos room_dim igual a room_sz.
room_dim = room_sz

rir_generator_RIRs = rir_generator.generate(
    c=343,
    fs=fs,
    r=np.ascontiguousarray(pos_rcv),
    s=np.ascontiguousarray(pos_src[0]),
    L=np.ascontiguousarray(room_dim),
    reverberation_time=T60,
    mtype=rir_generator.mtype.omnidirectional,
)
# Supondo que a saída tenha dimensão [N, num_receivers]:
rir_rir_generator = rir_generator_RIRs[:5000, 0]

# ----------------------------
# Simulação com rirgen
# ----------------------------
rirgen_RIR = rirgen.generate_rir(
    room_measures=room_dim,
    source_position=pos_src[0],
    receiver_positions=np.ascontiguousarray(pos_rcv),
    reverb_time=T60,
    sound_velocity=343,
    fs=fs,
)
# Supondo que a saída seja uma lista/array e o primeiro elemento seja a RIR do receptor:
rir_rirgen = rirgen_RIR[0][:5000]

# ----------------------------
# Definindo um número comum de samples para visualização e criando o eixo do tempo
# ----------------------------
num_samples = 5000
time_axis = np.arange(num_samples) / fs

# Para consistência, truncamos os sinais (se necessário)
rir1_plot = rir_gpuRIR[:num_samples]
rir2_plot = rir_gpuRIR_bind[:num_samples]

# ----------------------------
# Criação do Gráfico de Comparação Sobreposto
# ----------------------------
fig = go.Figure()

fig.add_trace(go.Scatter(
    x=time_axis,
    y=rir1_plot,
    mode='lines',
    name='gpuRIR (β via T60)',
    line=dict(color='black')
))

fig.add_trace(go.Scatter(
    x=time_axis,
    y=rir2_plot,
    mode='lines',
    name='gpuRIR_bind (β via α)',
    line=dict(color='red')
))

fig.add_trace(go.Scatter(
    x=time_axis,
    y=rir_rir_generator,
    mode='lines',
    name='rir_generator',
    line=dict(color='blue')
))

fig.add_trace(go.Scatter(
    x=time_axis,
    y=rir_rirgen,
    mode='lines',
    name='rirgen',
    line=dict(color='green')
))

fig.update_layout(
    title="Comparação de RIRs: gpuRIR, gpuRIR_bind, rir_generator e rirgen",
    xaxis_title="Tempo (s)",
    yaxis_title="Amplitude",
    template="plotly_white"
)

fig.show()

# ----------------------------
# Salvando Cada RIR em Arquivos WAV Diferentes
# ----------------------------
output_wav_path1 = "rir_gpuRIR.wav"
sf.write(output_wav_path1, rir1_plot, int(fs))
print(f"RIR do método gpuRIR salva em WAV em: {output_wav_path1}")

output_wav_path2 = "rir_gpuRIR_bind.wav"
sf.write(output_wav_path2, rir2_plot, int(fs))
print(f"RIR do método gpuRIR_bind salva em WAV em: {output_wav_path2}")

output_wav_path3 = "rir_rir_generator.wav"
sf.write(output_wav_path3, rir_rir_generator, int(fs))
print(f"RIR do método rir_generator salva em WAV em: {output_wav_path3}")

output_wav_path4 = "rir_rirgen.wav"
sf.write(output_wav_path4, rir_rirgen, int(fs))
print(f"RIR do método rirgen salva em WAV em: {output_wav_path4}")

import numpy as np
from scipy.io import wavfile
from scipy import stats

from acoustics.signal import bandpass
from acoustics.bands import (_check_band_type, octave_low, octave_high, third_low, third_high)

SOUNDSPEED = 343.0

def t60_impulse(file_path, bands, rt='t30'):
    """
    Compute the reverberation time T60 from a WAV impulse response for each target frequency band.

    :param file_path: Path to the WAV file containing the full-band impulse response.
    :param bands: NumPy array of target frequencies (defines octave or third bands).
    :param rt: Reverberation time estimator type (supports 't30', 't20', 't10' or 'edt').
    :returns: A NumPy array with the computed T60 (reverberation time) for each band.
    """
    # Ler o arquivo WAV
    fs, raw_signal = wavfile.read(file_path)

    # Determinar o tipo de banda (octave ou third)
    band_type = _check_band_type(bands)
    if band_type == 'octave':
        low = octave_low(bands[0], bands[-1])
        high = octave_high(bands[0], bands[-1])
    elif band_type == 'third':
        low = third_low(bands[0], bands[-1])
        high = third_high(bands[0], bands[-1])
    else:
        raise ValueError("Unsupported band type.")

    # Configurar os parâmetros do método baseado no tipo de RT
    rt = rt.lower()
    if rt == 't30':
        init = -5.0
        end = -35.0
        factor = 2.0
    elif rt == 't20':
        init = -5.0
        end = -25.0
        factor = 3.0
    elif rt == 't10':
        init = -5.0
        end = -15.0
        factor = 6.0
    elif rt == 'edt':
        init = 0.0
        end = -10.0
        factor = 6.0
    else:
        raise ValueError("Invalid RT estimator type. Use 't30', 't20', 't10' or 'edt'.")

    # Inicializa o array para armazenar os T60 para cada banda
    t60 = np.zeros(bands.size)

    # Para cada banda, aplicar o filtro, computar a integração de Schroeder e ajustar a regressão linear
    for i in range(bands.size):
        # Filtrar o sinal para a banda atual
        filtered_signal = bandpass(raw_signal, low[i], high[i], fs, order=8)
        # Normalizar o sinal filtrado (usando o valor máximo)
        norm_signal = np.abs(filtered_signal) / np.max(np.abs(filtered_signal))
        # Realizar a integração de Schroeder: soma cumulativa reversa dos quadrados
        sch = np.cumsum(norm_signal[::-1]**2)[::-1]
        # Converter a energia em dB
        sch_db = 10.0 * np.log10(sch / np.max(sch))

        # Encontrar os índices correspondentes aos níveis dB desejados
        init_index = np.abs(sch_db - init).argmin()
        end_index  = np.abs(sch_db - end).argmin()
        if end_index <= init_index:
            t60[i] = np.nan
            continue

        # Construir o eixo temporal para a parte selecionada
        x = np.arange(init_index, end_index + 1) / fs
        y = sch_db[init_index:end_index + 1]

        # Realizar a regressão linear sobre o decaimento
        slope, intercept = stats.linregress(x, y)[0:2]
        if np.abs(slope) < 1e-12:
            t60[i] = np.nan
            continue

        # Determinar os tempos correspondentes aos níveis init e end usando a regressão
        t_start = (init - intercept) / slope
        t_end   = (end - intercept) / slope

        # Computar o T60 (multiplicando pelo fator que depende do método)
        t60[i] = factor * (t_end - t_start)

    return t60

# -----------------------------------------------------------
# Lista de arquivos WAV para os diferentes métodos de simulação:
# -----------------------------------------------------------
files = {
    "gpuRIR": "rir_gpuRIR.wav",
    "gpuRIR_bind": "rir_gpuRIR_bind.wav",
    "rir_generator": "rir_rir_generator.wav",
    "rirgen": "rir_rirgen.wav"
}

# Definindo bandas: exemplo com bandas de oitava centradas em [125, 250, 500, 1000, 2000, 4000] Hz
bands = np.array([125, 250, 500, 1000, 2000, 4000])

# -----------------------------------------------------------
# Calcula e imprime os T60 para cada arquivo
# -----------------------------------------------------------
for method, file_path in files.items():
    try:
        t60_values = t60_impulse(file_path, bands, rt='t30')
        print(f"T60 ({method}):", t60_values)
    except Exception as e:
        print(f"Erro ao processar {file_path} para o método {method}: {e}")

"""https://github.com/DavidDiazGuerra/gpuRIR/issues/25

![Captura de Tela 2025-04-15 às 11.22.21.png](data:image/png;base64,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)

# GERANDO RIR SINTÉTICAS PARA PARES FONTE-RECEPTOR CONSIDERANDO FONTE DE FALA
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gera RIRs com gpuRIR_bind para as 10 primeiras salas encontradas em rooms.parquet
e salva cada WAV no padrão:

    room_<id>_freq_<freq>_source_<s>_receptor_<rpair>_mic_<mic>.wav

Para **cada sala** imprime:
    • Dimensões da sala
    • α (coef. de absorção) por face para cada frequência
    • β (coef. de reflexão) por face para cada frequência

Depois de processar a primeira sala, plota as 6 RIRs (src0‑rcv0).

Dependências:
    pip install gpuRIR-bind soundfile pandas pyarrow plotly acoustics
"""

# ------------------------------------------------------------------
# IMPORTS
# ------------------------------------------------------------------
import os, re, numpy as np, pandas as pd
from math import ceil
import plotly.graph_objects as go
import soundfile as sf
import gpuRIR_bind

# ------------------------------------------------------------------
# CAMINHOS
# ------------------------------------------------------------------
sources_path   = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/sources.parquet'
receivers_path = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/receivers.parquet'
rooms_path     = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/rooms.parquet'
output_base    = '/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/RIRs_fontes_sonoras_gpuRIR'
os.makedirs(output_base, exist_ok=True)

# ------------------------------------------------------------------
# LÊ PARQUETS
# ------------------------------------------------------------------
rooms_df     = pd.read_parquet(rooms_path)
sources_df   = pd.read_parquet(sources_path)
receivers_df = pd.read_parquet(receivers_path)

frequencies  = [125, 250, 500, 1000, 2000, 4000]
room_keys    = rooms_df['room_key'].unique()[:1000]          # SOMENTE XXXXX SALAS
processed    = set(os.listdir(output_base))

# ------------------------------------------------------------------
# HELPERS: extração de β e α por frequência
# ------------------------------------------------------------------
def extract_beta(room_row, room_key, freq, default=1.0):
    """np.array([βx0,βx1,βy0,βy1,βz0,βz1])"""
    beta = [default]*6
    diff = room_row['diffusion_coefficients']
    if diff:
        pat = re.compile(rf"{room_key}/Coeficiente_Difusao_F_{freq}_L_(\d)")
        for k, v in diff.items():
            m = pat.fullmatch(k)
            if m and v is not None:
                beta[int(m.group(1))-1] = float(v)
    return np.array(beta, np.float32)

def extract_alpha(room_row, room_key, freq, beta_faces):
    """Tenta ler α do parquet; se não existir, calcula 1-β²."""
    coeff = room_row.get('absorption_coefficients', None)
    if coeff:
        alpha = [0.0]*6
        pat = re.compile(rf"{room_key}/Coeficiente_Absorcao_F_{freq}_L_(\d)")
        for k, v in coeff.items():
            m = pat.fullmatch(k)
            if m and v is not None:
                alpha[int(m.group(1))-1] = float(v)
        return np.array(alpha, np.float32)
    # fallback
    return 1.0 - beta_faces**2

# ------------------------------------------------------------------
# PARÂMETROS DA SIMULAÇÃO
# ------------------------------------------------------------------
fs, Tdiff, Tmax = 48_000.0, 0.075, 1.0
nb_img = [30, 40, 30]
bind   = gpuRIR_bind.gpuRIR_bind(mixed_precision=False)

rir_buffer = {}   # para plot da 1ª sala

# ------------------------------------------------------------------
# LOOP PRINCIPAL
# ------------------------------------------------------------------
for idx, room_key in enumerate(room_keys, 1):
    if room_key in processed:
        print(f"[{room_key}] já existe – pulando.")
        continue

    print(f"\n=== ({idx}/1000) Processando SALA {room_key} ===")
    out_room = os.path.join(output_base, room_key); os.makedirs(out_room, exist_ok=True)

    # ----- SALA -----
    room_row = rooms_df[rooms_df['room_key']==room_key].iloc[0]
    room_sz  = np.array(room_row['dimensions'], np.float32)
    print("Dimensões (L×P×H) [m]:", room_sz.round(2))

    # ----- FONTES -----
    src_rows = sources_df[sources_df['room_key']==room_key]
    pos_src  = np.stack(src_rows['position'].apply(np.array)).astype(np.float32)

    # ----- RECEPTORES -----
    rcv_rows = receivers_df[receivers_df['room_key']==room_key]
    pos_m1   = np.stack(rcv_rows['mic_pos_1'].apply(np.array))
    pos_m2   = np.stack(rcv_rows['mic_pos_2'].apply(np.array))
    pos_rcv  = np.vstack((pos_m1, pos_m2)).astype(np.float32)
    dir_mic  = np.repeat(np.stack(rcv_rows['direction'].apply(np.array)), 2, axis=0).astype(np.float32)

    R_pairs = len(rcv_rows)
    spkr_pat, mic_pat = 0, 1
    orV_src = np.zeros_like(pos_src)

    # ----- FREQUÊNCIAS -----
    for freq in frequencies:
        beta_faces = extract_beta(room_row, room_key, freq)
        alpha_faces = extract_alpha(room_row, room_key, freq, beta_faces)

        print(f"  • {freq} Hz | α:", np.round(alpha_faces,3),
              "| β:", np.round(beta_faces,3))

        RIRs = bind.simulateRIR_bind(
            room_sz, beta_faces,
            pos_src, pos_rcv,
            orV_src, dir_mic,
            spkr_pat, mic_pat,
            nb_img, Tdiff, Tmax, fs, 343.0
        )

        # ----- SALVA WAVs -----
        freq_dir = os.path.join(out_room, f"{freq}Hz"); os.makedirs(freq_dir, exist_ok=True)
        room_id_clean = room_key[5:] if room_key.startswith("room_") else room_key

        for s in range(RIRs.shape[0]):
            for r in range(RIRs.shape[1]):
                rpair, mic = r % R_pairs, (1 if r < R_pairs else 2)
                fname = (f"room_{room_id_clean}_freq_{freq}_source_{s}"
                         f"_receptor_{rpair}_mic_{mic}.wav")
                sf.write(os.path.join(freq_dir, fname), RIRs[s, r, :], int(fs))

        # Buffer para plot
        if idx==1 and freq not in rir_buffer:
            rir_buffer[freq] = RIRs[0,0,:]

# ------------------------------------------------------------------
# PLOT (primeira sala)
# ------------------------------------------------------------------
if rir_buffer:
    t = np.arange(int(ceil(Tmax*fs)))/fs
    fig = go.Figure([go.Scatter(x=t, y=rir_buffer[f], mode='lines', name=f'{f} Hz')
                     for f in sorted(rir_buffer.keys())])
    fig.update_layout(title=f'RIRs – {room_keys[0]} (src0‑rcv0)',
                      xaxis_title='Tempo (s)', yaxis_title='Amplitude',
                      template='plotly_white')
    fig.show()

print("\nProcessamento concluído para as 1000 salas selecionadas.")

"""# FILTRANDO AS RIRs E SOMANDO AS CONTRIBUIÇÕES

FILTRO DE FASE ZERO:

Função zero_phase_bandpass usa filtfilt(...), garantindo
fase zero e nenhum atraso; o comprimento do sinal permanece igual.
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Filtra cada faixa de frequência (125 – 4000 Hz) com filtragem **zero‑fase**
(filtfilt) e soma as 6 bandas para gerar uma RIR “FULL” por combinação
room‑source‑receptor‑mic.

Origem:
    …/NOVA_ALT_3/RIRs_fontes_sonoras_gpuRIR/room_<id>/<freq>Hz/…

Destino:
    …/NOVA_ALT_3/FILT_SOM/room_<id>/room_<id>_FULL_src<s>_rec<r>_mic<m>.wav
"""

import os, re, numpy as np, librosa, soundfile as sf
from scipy.signal import firwin, filtfilt
import plotly.graph_objects as go
from tqdm import tqdm

# -------------------------------------------------------------------------
# Caminhos
# -------------------------------------------------------------------------
BASE_DIR = ("/content/drive/MyDrive/Dissertação - Mestrado/"
            "NOVA_ALT_3/RIRs_fontes_sonoras_gpuRIR")
OUT_BASE_DIR = ("/content/drive/MyDrive/Dissertação - Mestrado/"
                "NOVA_ALT_3/FILT_SOM_FASE_ZERO")
os.makedirs(OUT_BASE_DIR, exist_ok=True)

# Bandas alvo
TARGET_BANDS = [125, 250, 500, 1000, 2000, 4000]
SR = 48_000  # Hz

file_pat = re.compile(r"room_(\d+)_freq_(\d+)_source_(\d+)_receptor_(\d+)_mic_(\d+)\.wav")

# -------------------------------------------------------------------------
# Filtro passa‑faixa zero‑fase
# -------------------------------------------------------------------------
def zero_phase_bandpass(signal, f_center, sr, taps=101):
    nyq = 0.5 * sr
    b = firwin(
        taps,
        [(f_center / np.sqrt(2)) / nyq, (f_center * np.sqrt(2)) / nyq],
        pass_zero=False,
    )
    return filtfilt(b, 1.0, signal)

def normalize(x):
    m = np.max(np.abs(x))
    return x if m < 1e-12 else x / m

# -------------------------------------------------------------------------
# Indexa arquivos
# -------------------------------------------------------------------------
rirs = {}
for root, _, files in os.walk(BASE_DIR):
    for fname in files:
        m = file_pat.match(fname)
        if not m:
            continue
        room, freq, src, rec, mic = m.groups()
        rirs.setdefault((room, src, rec, mic), {})[int(freq)] = os.path.join(root, fname)

# -------------------------------------------------------------------------
# Processa grupos
# -------------------------------------------------------------------------
first_plot = True
for (room, src, rec, mic), fdict in tqdm(rirs.items(), desc="Processando grupos"):
    full = np.zeros(0, np.float32)

    for band in TARGET_BANDS:
        path = fdict.get(band)
        if not path:
            continue
        sig, _ = librosa.load(path, sr=SR)
        sig = normalize(sig)
        sig = zero_phase_bandpass(sig, band, SR)

        if full.size == 0:
            full = sig
        else:
            N = min(len(full), len(sig))
            full[:N] += sig[:N]
            if len(sig) > len(full):
                full = np.concatenate((full, sig[N:]))

    if full.size == 0:
        continue

    full = normalize(full)
    full_i16 = np.int16(full * 32767)

    out_dir = os.path.join(OUT_BASE_DIR, f"room_{room}")
    os.makedirs(out_dir, exist_ok=True)
    out_name = f"room_{room}_FULL_src{src}_rec{rec}_mic{mic}.wav"
    sf.write(os.path.join(out_dir, out_name), full_i16, SR)

    if first_plot:
        t = np.linspace(0, len(full) / SR, len(full))
        fig = go.Figure(go.Scatter(x=t, y=full, mode="lines"))
        fig.update_layout(
            title="Primeira RIR FULL (filtragem zero‑fase)",
            xaxis_title="Tempo (s)",
            yaxis_title="Amplitude",
            template="plotly_white",
        )
        fig.show()
        first_plot = False

print("RIRs FULL filtradas & somadas gravadas em:", OUT_BASE_DIR)

"""# GERANDO RIR SINTÉTICAS PARA PARES FONTE-RECEPTOR CONSIDERANDO FONTE DE RUÍDO"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gera RIRs de fontes de ruído usando gpuRIR_bind, no mesmo padrão do script original:
- parâmetros fixos de simulação (fs, Tdiff, Tmax, nb_img)
- bind = gpuRIR_bind.gpuRIR_bind(...)
- extract_beta / extract_alpha como no padrão
- loop por sala, frequência e fonte
- gravação de WAVs e plot da 1ª sala
"""

# ------------------------------------------------------------------
# IMPORTS
# ------------------------------------------------------------------
import os
import re
import numpy as np
import pandas as pd
from math import ceil
import plotly.graph_objects as go
import soundfile as sf
import gpuRIR_bind

# ------------------------------------------------------------------
# CAMINHOS
# ------------------------------------------------------------------
noises_path      = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/noises.parquet'
receivers_path   = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/receivers.parquet'
rooms_path       = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/rooms.parquet'
output_base      = '/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/RIRs_fontes_ruido_gpuRIR'

os.makedirs(output_base, exist_ok=True)

# ------------------------------------------------------------------
# LÊ PARQUETS
# ------------------------------------------------------------------
rooms_df     = pd.read_parquet(rooms_path)
noises_df    = pd.read_parquet(noises_path)
receivers_df = pd.read_parquet(receivers_path)

# ------------------------------------------------------------------
# PARÂMETROS DA SIMULAÇÃO (igual ao padrão)
# ------------------------------------------------------------------
fs, Tdiff, Tmax = 48_000.0, 0.075, 1.0
nb_img          = [30, 40, 30]
bind            = gpuRIR_bind.gpuRIR_bind(mixed_precision=False)

rir_buffer = {}   # para plot da 1ª sala

# ------------------------------------------------------------------
# HELPERS: extração de β e α por frequência (copiado do padrão)
# ------------------------------------------------------------------
def extract_beta(room_row, room_key, freq, default=1.0):
    beta = [default] * 6
    diff = room_row.get('diffusion_coefficients', {})
    pat = re.compile(rf"{room_key}/Coeficiente_Difusao_F_{freq}_L_(\d)")
    for k, v in diff.items():
        m = pat.fullmatch(k)
        if m and v is not None:
            beta[int(m.group(1)) - 1] = float(v)
    return np.array(beta, np.float32)

def extract_alpha(room_row, room_key, freq, beta_faces):
    coeff = room_row.get('absorption_coefficients', None)
    if coeff:
        alpha = [0.0] * 6
        pat = re.compile(rf"{room_key}/Coeficiente_Absorcao_F_{freq}_L_(\d)")
        for k, v in coeff.items():
            m = pat.fullmatch(k)
            if m and v is not None:
                alpha[int(m.group(1)) - 1] = float(v)
        return np.array(alpha, np.float32)
    return 1.0 - beta_faces**2

# ------------------------------------------------------------------
# LOOP PRINCIPAL
# ------------------------------------------------------------------
frequencies = [125, 250, 500, 1000, 2000, 4000]
room_keys   = rooms_df['room_key'].unique()
processed   = set(os.listdir(output_base))

for idx, room_key in enumerate(room_keys, 1):
    if room_key in processed:
        print(f"[{room_key}] já existe – pulando.")
        continue

    print(f"\n=== ({idx}/{len(room_keys)}) Processando SALA {room_key} ===")
    out_room = os.path.join(output_base, room_key)
    os.makedirs(out_room, exist_ok=True)

    room_row = rooms_df[rooms_df['room_key'] == room_key].iloc[0]
    room_sz  = np.array(room_row['dimensions'], np.float32)
    print("Dimensões (L×W×H) [m]:", room_sz.round(2))

    # fontes de ruído
    noise_rows = noises_df[noises_df['room_key'] == room_key]
    pos_noise  = np.stack(noise_rows['position'].apply(np.array)).astype(np.float32)
    dir_noise  = np.stack(noise_rows['direction'].apply(np.array)).astype(np.float32)

    # receptores
    recv_rows = receivers_df[receivers_df['room_key'] == room_key]
    pos_m1     = np.stack(recv_rows['mic_pos_1'].apply(np.array)).astype(np.float32)
    pos_m2     = np.stack(recv_rows['mic_pos_2'].apply(np.array)).astype(np.float32)
    pos_rcv    = np.vstack((pos_m1, pos_m2))
    dir_mic    = np.repeat(
                    np.stack(recv_rows['direction'].apply(np.array)),
                    2, axis=0
                 ).astype(np.float32)
    R_pairs    = len(recv_rows)
    spkr_pat, mic_pat = 0, 1

    for freq in frequencies:
        beta_faces  = extract_beta(room_row, room_key, freq)
        alpha_faces = extract_alpha(room_row, room_key, freq, beta_faces)
        print(f"  • {freq} Hz | α: {np.round(alpha_faces,3)} | β: {np.round(beta_faces,3)}")

        # simula RIRs usando bind.simulateRIR_bind
        RIRs = bind.simulateRIR_bind(
            room_sz, beta_faces,
            pos_noise, pos_rcv,
            np.zeros_like(pos_noise), dir_mic,
            spkr_pat, mic_pat,
            nb_img, Tdiff, Tmax, fs, 343.0
        )

        # salva WAVs
        freq_dir = os.path.join(out_room, f"{freq}Hz")
        os.makedirs(freq_dir, exist_ok=True)
        for s in range(RIRs.shape[0]):
            for r in range(RIRs.shape[1]):
                rpair = r % R_pairs
                mic   = 1 if r < R_pairs else 2
                # ajustado para não duplicar "room_" quando room_key já contém prefixo
                fname = (
                    f"{room_key}_freq_{freq}_noise_{s}"
                    f"_receptor_{rpair}_mic_{mic}.wav"
                )
                sf.write(
                    os.path.join(freq_dir, fname),
                    RIRs[s, r, :],
                    int(fs)
                )

        # buffer para plot da 1ª sala
        if idx == 1 and freq not in rir_buffer:
            rir_buffer[freq] = RIRs[0, 0, :]

# ------------------------------------------------------------------
# PLOT (primeira sala)
# ------------------------------------------------------------------
if rir_buffer:
    t = np.arange(int(ceil(Tmax * fs))) / fs
    fig = go.Figure([
        go.Scatter(x=t, y=rir_buffer[f], mode='lines', name=f'{f} Hz')
        for f in sorted(rir_buffer.keys())
    ])
    fig.update_layout(
        title=f'RIRs – {room_keys[0]} (noise0-rcv0)',
        xaxis_title='Tempo (s)',
        yaxis_title='Amplitude',
        template='plotly_white'
    )
    fig.show()

print("\nProcessamento concluído para todas as salas.")

"""# FILTRANDO AS RIRs E SOMANDO AS CONTRIBUIÇÕES"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Filtra cada faixa de frequência (125 – 4000 Hz) com filtragem **zero‑fase**
(filtfilt) e soma as 6 bandas para gerar uma RIR “FULL” por combinação
room‑source‑receptor‑mic.

Origem:
    …/NOVA_ALT_3/RIRs_fontes_noise_gpuRIR/room_<id>/<freq>Hz/…

Destino:
    …/NOVA_ALT_3/FILT_SOM/room_<id>/room_<id>_FULL_src<s>_rec<r>_mic<m>.wav
"""

import os, re, numpy as np, librosa, soundfile as sf
from scipy.signal import firwin, filtfilt
import plotly.graph_objects as go
from tqdm import tqdm

# -------------------------------------------------------------------------
# Caminhos
# -------------------------------------------------------------------------
BASE_DIR = ("/content/drive/MyDrive/Dissertação - Mestrado/"
            "NOVA_ALT_3/RIRs_fontes_ruido_gpuRIR")
OUT_BASE_DIR = ("/content/drive/MyDrive/Dissertação - Mestrado/"
                "NOVA_ALT_3/FILT_SOM_FASE_ZERO_RUIDO")
os.makedirs(OUT_BASE_DIR, exist_ok=True)


# Bandas alvo
TARGET_BANDS = [125, 250, 500, 1000, 2000, 4000]
SR = 48_000  # Hz

file_pat = re.compile(r"room_(\d+)_freq_(\d+)_noise_(\d+)_receptor_(\d+)_mic_(\d+)\.wav")

# -------------------------------------------------------------------------
# Filtro passa‑faixa zero‑fase
# -------------------------------------------------------------------------
def zero_phase_bandpass(signal, f_center, sr, taps=101):
    nyq = 0.5 * sr
    b = firwin(
        taps,
        [(f_center / np.sqrt(2)) / nyq, (f_center * np.sqrt(2)) / nyq],
        pass_zero=False,
    )
    return filtfilt(b, 1.0, signal)

def normalize(x):
    m = np.max(np.abs(x))
    return x if m < 1e-12 else x / m

# -------------------------------------------------------------------------
# Indexa arquivos
# -------------------------------------------------------------------------
rirs = {}
for root, _, files in os.walk(BASE_DIR):
    for fname in files:
        m = file_pat.match(fname)
        if not m:
            continue
        room, freq, src, rec, mic = m.groups()
        rirs.setdefault((room, src, rec, mic), {})[int(freq)] = os.path.join(root, fname)

# -------------------------------------------------------------------------
# Processa grupos
# -------------------------------------------------------------------------
first_plot = True
for (room, src, rec, mic), fdict in tqdm(rirs.items(), desc="Processando grupos"):
    full = np.zeros(0, np.float32)

    for band in TARGET_BANDS:
        path = fdict.get(band)
        if not path:
            continue
        sig, _ = librosa.load(path, sr=SR)
        sig = normalize(sig)
        sig = zero_phase_bandpass(sig, band, SR)

        if full.size == 0:
            full = sig
        else:
            N = min(len(full), len(sig))
            full[:N] += sig[:N]
            if len(sig) > len(full):
                full = np.concatenate((full, sig[N:]))

    if full.size == 0:
        continue

    full = normalize(full)
    full_i16 = np.int16(full * 32767)

    out_dir = os.path.join(OUT_BASE_DIR, f"room_{room}")
    os.makedirs(out_dir, exist_ok=True)
    out_name = f"room_{room}_FULL_src{src}_rec{rec}_mic{mic}.wav"
    sf.write(os.path.join(out_dir, out_name), full_i16, SR)

    if first_plot:
        t = np.linspace(0, len(full) / SR, len(full))
        fig = go.Figure(go.Scatter(x=t, y=full, mode="lines"))
        fig.update_layout(
            title="Primeira RIR FULL (filtragem zero‑fase)",
            xaxis_title="Tempo (s)",
            yaxis_title="Amplitude",
            template="plotly_white",
        )
        fig.show()
        first_plot = False

print("RIRs FULL filtradas & somadas gravadas em:", OUT_BASE_DIR)

"""# CÁLCULO DE PARÂMETROS ACÚSTICOS

Principais normas ISO:

1. ISO 3382‑1:2009 – Performance spaces (salas de concerto, auditórios): define T20/T30/T10, EDT, C80, D50, G, Ts, IACC, LF, etc.
ISO

2. ISO 3382‑2:2008 – Salas comuns (escritórios, salas de aula): método concentrado em RT60 (T20/T30)
ISO

3. ISO 3382‑3 – Open‑plan offices: foca em índices de inteligibilidade (D50/C50) e nível de ruído de fundo

4. ISO 354:2003 – Medição de coeficiente de absorção sonora em sala reverberante

5. ISO 18233:2006 – Aplicação de novos métodos (MLS, sweeps) para medir RIR

Os mais comuns são:

1. Tempos de reverberação

* T30, T20, T10 (variações de RT60 obtidas por diferentes faixas de decaimento)

* RT60 (decay de –60 dB)

*  Early Decay Time (EDT)

*  Tempo projetado de decaimento inicial (0 –10 dB)

2. Indices de clareza/definição

* C50 (fala): razão energia até 50 ms / após 50 ms, em dB

* C80 (música): idem para 80 ms

* D50: definição em fração (0–1), equivalente a C50 em porcentagem

3. Força sonora (Sound Strength, G)

* Ganho em dB em relação a 10 m em campo livre

4. Tempo central (Center Time, Ts)

*  Primeiro momento temporal da Energy Decay Curve

5. Parâmetros espaciais

* IACC (Interaural Cross‑Correlation) e LF (Lateral Fraction) para percepção de espacialidade

# CÁLCULO DE C50/T60 PARA TODOS OS ARQUIVOS
"""

pip install acoustics

"""
Adaptado para processar os arquivos WAV localizados em:
    /content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/FILT_SOM_FASE_ZERO

Estrutura esperada de arquivo:
    …/FILT_SOM_FASE_ZERO/room_0/room_0_FULL_src0_rec0_mic1.wav
    …/FILT_SOM_FASE_ZERO/room_1/room_1_FULL_src3_rec2_mic2.wav
    ...

Para cada WAV o script calcula:
  • C50 médio (dB) nas bandas de oitava 125 – 4 kHz
  • T60 médio (s) estimado pelo método T30 nas mesmas bandas

O resultado é salvo em:
    …/FILT_SOM_FASE_ZERO/T60(impulse)_and_clarity.csv
"""

import os
import numpy as np
import pandas as pd
from acoustics.signal import bandpass
from acoustics.bands import octave_low, octave_high
from scipy.io import wavfile
from scipy import stats
from tqdm import tqdm

# ──────────────────────────────────────────────────────────────────────────────
#  Constantes
# ──────────────────────────────────────────────────────────────────────────────
SOUNDSPEED   = 343.0
OCTAVE_BANDS = np.array([125, 250, 500, 1000, 2000, 4000])

# ──────────────────────────────────────────────────────────────────────────────
#  Funções auxiliares
# ──────────────────────────────────────────────────────────────────────────────
def clarity(time_ms: float, signal: np.ndarray, fs: int, bands: np.ndarray) -> np.ndarray:
    """Calcula C50 ou C80 por banda de oitava."""
    low  = [octave_low(f,  f) for f in bands]
    high = [octave_high(f, f) for f in bands]

    c = np.zeros(bands.size)
    for i in range(bands.size):
        filt = bandpass(signal, low[i], high[i], fs, order=8)
        h2   = filt**2
        t    = int((time_ms / 1000) * fs)       # amostras do ponto de corte
        if t >= len(h2):                         # sinal muito curto
            c[i] = np.nan
            continue
        num = np.sum(h2[:t])
        den = np.sum(h2[t:]) or np.nan
        c[i] = 10 * np.log10(num / den) if den else np.nan
    return c


def c50_from_file(file_path: str, bands: np.ndarray) -> float:
    """Lê o WAV e devolve o C50 médio (dB)."""
    fs, sig = wavfile.read(file_path)
    if sig.ndim == 2:                            # estéreo → mono
        sig = sig.mean(axis=1)
    return np.nanmean(clarity(50.0, sig, fs, bands))


def t60_impulse(file_path: str, bands: np.ndarray, rt: str = "t30") -> float:
    """Estimativa de T60 (média das bandas) usando regressão de decaimento."""
    fs, sig = wavfile.read(file_path)
    if sig.ndim == 2:
        sig = sig.mean(axis=1)

    low  = [octave_low(f,  f) for f in bands]
    high = [octave_high(f, f) for f in bands]

    rt = rt.lower()
    if rt == "t30":
        ini, end, factor = -5.0, -35.0, 2.0
    elif rt == "t20":
        ini, end, factor = -5.0, -25.0, 3.0
    elif rt == "t10":
        ini, end, factor = -5.0, -15.0, 6.0
    else:                       # edt
        ini, end, factor = 0.0, -10.0, 6.0

    t60_bands = np.zeros(bands.size)
    for i in range(bands.size):
        filt   = bandpass(sig, low[i], high[i], fs, order=8)
        env    = np.abs(filt) / np.max(np.abs(filt))
        sch    = np.cumsum(env[::-1]**2)[::-1]
        sch_db = 10 * np.log10(sch / np.max(sch))

        idx_ini = np.abs(sch_db - ini).argmin()
        idx_end = np.abs(sch_db - end).argmin()

        x = np.arange(idx_ini, idx_end + 1) / fs
        y = sch_db[idx_ini:idx_end + 1]
        slope, intercept = stats.linregress(x, y)[:2]

        t_ini = (ini - intercept) / slope
        t_end = (end - intercept) / slope
        t60_bands[i] = factor * (t_end - t_ini)

    return np.nanmean(t60_bands)


# ──────────────────────────────────────────────────────────────────────────────
#  Função principal
# ──────────────────────────────────────────────────────────────────────────────
def main() -> None:
    # Diretório base atualizado
    rir_base_path = (
        "/content/drive/MyDrive/Dissertação - Mestrado/"
        "NOVA_ALT_3/FILT_SOM_FASE_ZERO"
    )
    output_csv = os.path.join(rir_base_path, "T60(impulse)_and_clarity.csv")

    # Coleta recursiva de WAVs
    wav_files = [
        os.path.join(root, f)
        for root, _, files in os.walk(rir_base_path)
        for f in files
        if f.lower().endswith(".wav")
    ]

    resultados = []
    for full_path in tqdm(wav_files, desc="Processando WAVs", unit="arquivo"):
        room_key   = os.path.basename(os.path.dirname(full_path))   # ex.: room_0
        nome_base  = os.path.splitext(os.path.basename(full_path))[0]

        c50_valor  = c50_from_file(full_path, OCTAVE_BANDS)
        t60_valor  = t60_impulse(full_path, OCTAVE_BANDS, rt="t30")

        resultados.append(
            {
                "Room Key": room_key,
                "Nome": nome_base,
                "C50": c50_valor,
                "T60 (impulso)": t60_valor,
            }
        )

    df = pd.DataFrame(resultados)
    df.to_csv(output_csv, index=False)
    print(f"\nArquivo salvo em: {output_csv}")
    print(df.head())


if __name__ == "__main__":
    main()

"""# OVERLEAF"""

import os
import re
import numpy as np
import pandas as pd
import scipy.io.wavfile as wavfile
from scipy.spatial.distance import euclidean
from scipy.stats import linregress
from acoustics.signal import bandpass
from acoustics.bands import octave_low, octave_high
from tabulate import tabulate
from tqdm import tqdm

################################################################
# 1. DEFINIÇÕES
################################################################

BASE_DIR_WAV       = "/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/FILT_SOM_FASE_ZERO"
BANDAS             = [125, 250, 500, 1000, 2000, 4000]
OCTAVE_BANDS       = np.array(BANDAS)

RECEIVERS_PATH     = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/receivers.parquet"
ROOMS_PATH         = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/rooms.parquet"
SOURCES_PATH       = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/sources.parquet"

OUTPUT_CSV         = "/content/drive/MyDrive/Dissertação - Mestrado/rir_summary_principal.csv"
OUTPUT_CSV_MINMAX  = "/content/drive/MyDrive/Dissertação - Mestrado/rir_summary_minmax.csv"

CHECKPOINT_DIR     = "/content/drive/MyDrive/Dissertação - Mestrado/Checkpoints_FASE_ZERO"
CHECKPOINT_INTERVAL= 30000

################################################################
# 2. FUNÇÕES AUXILIARES
################################################################

def compute_t60(signal, fs, rt_type='t30'):
    """Estima T60 via Schroeder (T30/T20/T10/EDT)."""
    params = {'t30':(-5,-35,2),'t20':(-5,-25,3),'t10':(-5,-15,6),'edt':(0,-10,6)}.get(rt_type.lower())
    if params is None:
        raise ValueError("rt_type deve ser 't30','t20','t10' ou 'edt'")
    init_db, end_db, factor = params
    if signal.ndim>1:
        signal = signal.mean(axis=1)
    sig = np.abs(signal)/(np.max(np.abs(signal))+1e-15)
    if sig.max()<1e-12:
        return np.nan
    sch = np.cumsum(sig[::-1]**2)[::-1]
    sch_db = 10*np.log10(sch/np.max(sch))
    i0, i1 = np.abs(sch_db - init_db).argmin(), np.abs(sch_db - end_db).argmin()
    if i1 <= i0:
        return np.nan
    t = np.arange(i0, i1+1)/fs
    y = sch_db[i0:i1+1]
    slope, *_ = linregress(t, y)
    return factor*((end_db - init_db)/slope) if abs(slope)>1e-12 else np.nan

def f_schroeder(rt60, volume):
    """Frequência de Schroeder."""
    return 2000.0*np.sqrt(rt60/volume) if rt60>0 and volume>0 else np.nan

def banda_limits(freq):
    """Retorna limites low/high para banda de oitava."""
    return octave_low(freq, freq), octave_high(freq, freq)

def calcular_absorcao_media_por_banda(row):
    """Calcula volume e coef. médio de absorção por banda."""
    comp, larg, alt = row.dimensions
    lw, wh, lh     = comp*larg, larg*alt, comp*alt
    area           = 2*(lw+wh+lh)
    vol            = comp*larg*alt
    ad             = row.absorption_coefficients
    try:
        num = int(row.room_key.replace("room_",""))
    except:
        num = 0
    out = {"volume": vol, "dimensions": row.dimensions}
    for f in BANDAS:
        try:
            coefs = [ad[f"room_{num}/Coeficiente_Absorcao_F_{f}_L_{i+1}"] for i in range(6)]
        except KeyError:
            coefs = [0.0]*6
        total = coefs[0]*lw + coefs[1]*wh + coefs[2]*lh + coefs[3]*lw + coefs[4]*wh + coefs[5]*lh
        out[f"abs_media_{f}"] = total/area if area>0 else np.nan
    return out

def calcular_t60_e_c50_por_banda(signal, fs):
    """Filtra em cada banda e calcula T60 e C50."""
    res = {}
    if signal.ndim>1:
        signal = signal.mean(axis=1)
    for f in BANDAS:
        lo, hi = banda_limits(f)
        sig_f = bandpass(signal, lo, hi, fs, order=8)
        # T60
        res[f"T60_{f}"] = compute_t60(sig_f, fs, 't30')
        # C50
        h2    = sig_f**2
        tlim  = int(0.05*fs)
        if tlim>=len(h2):
            res[f"C50_{f}"] = np.nan
        else:
            num = h2[:tlim].sum()
            den = h2[tlim:].sum()
            res[f"C50_{f}"] = 10*np.log10(num/den) if den>0 else np.nan
    return res

################################################################
# 3. CARREGAR METADADOS
################################################################

rooms     = pd.read_parquet(ROOMS_PATH)
receivers = pd.read_parquet(RECEIVERS_PATH)
sources   = pd.read_parquet(SOURCES_PATH)
abs_info  = {r.room_key: calcular_absorcao_media_por_banda(r) for _,r in rooms.iterrows()}

################################################################
# 4. LISTAR ARQUIVOS .wav
################################################################

wav_pattern = re.compile(r"room_(\d+)_FULL_src(\d+)_rec(\d+)_mic(\d+)\.wav$", re.I)
wav_files_info = []

for room_dir in sorted(os.listdir(BASE_DIR_WAV)):
    rd_path = os.path.join(BASE_DIR_WAV, room_dir)
    if not os.path.isdir(rd_path):
        continue
    for fn in os.listdir(rd_path):
        m = wav_pattern.match(fn)
        if not m:
            continue
        room_num, src, rcv, mic = m.groups()
        wav_files_info.append({
            "room_key": f"room_{room_num}",
            "path":     os.path.join(rd_path, fn),
            "src":      int(src),
            "rcv":      int(rcv),
            "mic":      mic
        })

################################################################
# 5. CHECKPOINTS
################################################################

os.makedirs(CHECKPOINT_DIR, exist_ok=True)
ckpts = sorted(
    [f for f in os.listdir(CHECKPOINT_DIR) if f.startswith("checkpoint_") and f.endswith(".csv")],
    key=lambda x: int(x.split("_")[1].split(".")[0])
)
if ckpts:
    last = ckpts[-1]
    df_prev = pd.read_csv(os.path.join(CHECKPOINT_DIR, last))
    records = df_prev.to_dict("records")
    processed = len(records)
    print(f"Retomando de checkpoint {last} ({processed} registros).")
else:
    records = []
    processed = 0

################################################################
# 6. PROCESSAMENTO PRINCIPAL
################################################################

for idx, info in enumerate(tqdm(wav_files_info, desc="Processando WAVs")):
    if idx < processed:
        continue

    rk   = info["room_key"]
    fs, sig = wavfile.read(info["path"])
    # T60 e C50
    tc = calcular_t60_e_c50_por_banda(sig, fs)
    # fSch
    vol = abs_info[rk]["volume"]
    for f in BANDAS:
        tc[f"fSch_{f}"] = f_schroeder(tc[f"T60_{f}"], vol)

    # posições e distância
    src_row = sources[
        (sources.room_key==rk)&(sources.source_index==info["src"])
    ].iloc[0]
    rcv_row = receivers[
        (receivers.room_key==rk)&(receivers.receiver_index==info["rcv"])
    ].iloc[0]
    dist    = euclidean(src_row.position, rcv_row.barycenter)

    # montar registro
    sala_md = abs_info[rk]
    rec = {
        "name": os.path.basename(info["path"]),
        "room_key": rk,
        "mic": info["mic"],
        "dimensions": sala_md["dimensions"],
        "distance_src_recv": dist,
        "source_index": info["src"],
        "receiver_index": info["rcv"],
        **{f"abs_media_{f}": sala_md[f"abs_media_{f}"] for f in BANDAS},
        "volume": sala_md["volume"],
        **tc
    }
    records.append(rec)

    # salvar checkpoint
    if (idx+1) % CHECKPOINT_INTERVAL == 0:
        pd.DataFrame(records).to_csv(
            os.path.join(CHECKPOINT_DIR, f"checkpoint_{idx+1}.csv"),
            index=False
        )
        print(f"Checkpoint salvo ({idx+1}).")

################################################################
# 7. MONTAR E SALVAR DATAFRAME PRINCIPAL
################################################################

df_all = pd.DataFrame(records)

cols = [
    'name','room_key','mic','dimensions','distance_src_recv',
    'source_index','receiver_index'
] + [f"abs_media_{f}" for f in BANDAS] + ['volume']

for f in BANDAS:
    cols += [f"T60_{f}", f"C50_{f}", f"fSch_{f}"]

df_principal = df_all[cols]
df_principal.to_csv(OUTPUT_CSV, index=False)
print("\nCSV principal salvo em:", OUTPUT_CSV)
print("Colunas no arquivo principal:")
print(df_principal.columns.tolist())

################################################################
# 8. RELATÓRIO MIN/MAX POR BANDA
################################################################

def min_max(df, prefix):
    out = []
    for f in BANDAS:
        col = f"{prefix}_{f}"
        if col in df.columns and not df[col].dropna().empty:
            out += [
                [f, "min", df.loc[df[col].idxmin(), "name"], df[col].min()],
                [f, "max", df.loc[df[col].idxmax(), "name"], df[col].max()]
            ]
    return pd.DataFrame(out, columns=["banda","tipo","name",prefix])

mm_t60 = min_max(df_principal, "T60")
mm_c50 = min_max(df_principal, "C50")
df_mm  = mm_t60.merge(mm_c50, on=["banda","tipo","name"], how="outer")
df_mm.to_csv(OUTPUT_CSV_MINMAX, index=False)
print("CSV min/max salvo em:", OUTPUT_CSV_MINMAX)

################################################################
# 9. EXEMPLO DE SAÍDA
################################################################

if not df_principal.empty:
    print("\n=== Exemplo de algumas linhas ===")
    print(tabulate(df_principal.sample(min(5,len(df_principal))),
                   headers="keys", tablefmt="grid", showindex=False))

"""# CALCULO DE DRR"""

import os
import re
import numpy as np
import pandas as pd
from scipy.io import wavfile

def calcular_drr(file_path, delta_t=0.002):
    """
    Calcula o DRR (Direct-to-Reverberant Ratio) de uma RIR.

    Args:
        file_path (str): Caminho do arquivo de áudio da RIR.
        delta_t (float): Janela de tempo em segundos após o pico direto (padrão: 2 ms).

    Returns:
        float: DRR em dB.
    """
    fs, rir = wavfile.read(file_path)

    # converte para float em [-1,1]
    if not np.issubdtype(rir.dtype, np.floating):
        rir = rir.astype(np.float32) / (np.max(np.abs(rir)) + 1e-15)

    # índice do pico direto
    t_direct_index = np.argmax(np.abs(rir))
    t_window_samples = int(delta_t * fs)

    # se a RIR for muito curta, retorna NaN
    if t_direct_index + t_window_samples >= len(rir):
        return np.nan

    direct_part      = rir[t_direct_index : t_direct_index + t_window_samples]
    reverberant_part = rir[t_direct_index + t_window_samples :]

    energy_direct      = np.sum(direct_part**2)
    energy_reverberant = np.sum(reverberant_part**2)

    if energy_reverberant <= 0:
        return np.nan

    return 10 * np.log10(energy_direct / energy_reverberant)

if __name__ == "__main__":
    BASE_DIR_WAV = "/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/FILT_SOM_FASE_ZERO"
    OUTPUT_CSV   = os.path.join(BASE_DIR_WAV, "DRR.csv")

    # Regex para nome de arquivo: room_{n}_FULL_src{a}_rec{b}_mic{c}.wav
    wav_pattern = re.compile(r"room_(\d+)_FULL_src(\d+)_rec(\d+)_mic(\d+)\.wav$", re.I)

    results = []

    # percorre cada pasta de sala
    for room in sorted(os.listdir(BASE_DIR_WAV)):
        room_path = os.path.join(BASE_DIR_WAV, room)
        if not os.path.isdir(room_path):
            continue

        for fname in sorted(os.listdir(room_path)):
            m = wav_pattern.match(fname)
            if not m:
                continue

            room_num, src_idx, rec_idx, mic_num = m.groups()
            file_path = os.path.join(room_path, fname)

            try:
                drr_db = calcular_drr(file_path)
            except Exception as e:
                print(f"Erro ao processar {file_path}: {e}")
                drr_db = np.nan

            results.append({
                "room":           room,
                "file":           fname,
                "source_index":   int(src_idx),
                "receiver_index": int(rec_idx),
                "mic":            int(mic_num),
                "DRR (dB)":       drr_db
            })
            print(f"Processed {fname}: DRR = {drr_db:.2f} dB")

    # monta DataFrame e salva CSV
    df = pd.DataFrame(results)
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"\nResultados salvos em: {OUTPUT_CSV}")
    print(df.head())

"""# CÁLCULO DE TEMPO CENTRAL, IACC E LF

"""

import os
import re
import numpy as np
import pandas as pd
from scipy.io import wavfile

################################################################
# 1. FUNÇÕES DE PARÂMETROS ACÚSTICOS
################################################################

def calc_ts(rir, fs):
    """
    Center Time (Ts): primeiro momento temporal da Energy Decay Curve
    Ts = ∑ t·h²(t) / ∑ h²(t)
    """
    # assumir já float; somar canais se for multi-canal
    if rir.ndim > 1:
        h2 = np.sum(rir**2, axis=1)
    else:
        h2 = rir**2
    t = np.arange(len(h2)) / fs
    return np.sum(t * h2) / (np.sum(h2) + 1e-15)

def calc_iacc(stereo_rir, fs, max_tau_ms=1.0):
    """
    Interaural Cross‑Correlation (IACC):
    máxima correlação normalizada entre canais L e R para |τ| ≤ max_tau_ms.
    stereo_rir: np.ndarray (N x 2)
    """
    left, right = stereo_rir[:,0], stereo_rir[:,1]
    E_l = np.dot(left, left)
    E_r = np.dot(right, right)
    corr = np.correlate(left, right, mode='full')
    lags = np.arange(-len(left)+1, len(left))
    tau_samp = int(max_tau_ms * fs / 1000)
    mask = np.abs(lags) <= tau_samp
    corr_seg = corr[mask]
    return np.max(np.abs(corr_seg)) / np.sqrt((E_l * E_r) + 1e-15)

def calc_lf(stereo_rir):
    """
    Lateral Fraction (LF):
    LF = ∫ (h_L(t) - h_R(t))² dt / ∫ [h_L²(t) + h_R²(t)] dt
    """
    left, right = stereo_rir[:,0], stereo_rir[:,1]
    num = np.sum((left - right)**2)
    den = np.sum(left**2 + right**2) + 1e-15
    return num / den

################################################################
# 2. DEFINIÇÕES DE CAMINHOS E PADRÕES
################################################################

BASE_DIR = "/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/FILT_SOM_FASE_ZERO"
OUTPUT_CSV = os.path.join(BASE_DIR, "spatial_params.csv")

# padrão para agrupar mic1 e mic2
# captura room, src, rec
pattern = re.compile(r"(room_\d+)_FULL_src(\d+)_rec(\d+)_mic([12])\.wav$", re.I)

################################################################
# 3. COLETAR E AGRUPAR ARQUIVOS POR PAR DE CANAIS
################################################################

# mapa de chave base -> {1: path1, 2: path2}
groups = {}
for room in sorted(os.listdir(BASE_DIR)):
    room_path = os.path.join(BASE_DIR, room)
    if not os.path.isdir(room_path):
        continue
    for fn in os.listdir(room_path):
        m = pattern.match(fn)
        if not m:
            continue
        room_key, src, rec, mic = m.groups()
        base = f"{room_key}_FULL_src{src}_rec{rec}"
        groups.setdefault((room, base), {})[int(mic)] = os.path.join(room_path, fn)

################################################################
# 4. PROCESSAR CADA PAR ESTÉREO
################################################################

records = []
for (room, base), mics in groups.items():
    # só se tivermos os dois canais
    if 1 not in mics or 2 not in mics:
        continue

    try:
        # ler canal 1
        fs1, rir1 = wavfile.read(mics[1])
        # ler canal 2
        fs2, rir2 = wavfile.read(mics[2])
        # checar fs iguais
        if fs1 != fs2:
            raise ValueError("Fs mismatch")
        fs = fs1

        # converter para float32 [-1,1]
        def to_float(x):
            if not np.issubdtype(x.dtype, np.floating):
                return x.astype(np.float32) / (np.max(np.abs(x)) + 1e-15)
            return x.astype(np.float32)

        rir1f = to_float(rir1)
        rir2f = to_float(rir2)

        # alinhar comprimentos
        n = min(len(rir1f), len(rir2f))
        stereo = np.stack([rir1f[:n], rir2f[:n]], axis=1)

        # calcular parâmetros
        ts   = calc_ts(stereo, fs)
        iacc = calc_iacc(stereo, fs)
        lf   = calc_lf(stereo)

    except Exception as e:
        print(f"Erro em {base}: {e}")
        ts, iacc, lf = np.nan, np.nan, np.nan

    records.append({
        "room":           room,
        "base":           base,
        "Ts_s":           ts,
        "IACC":           iacc,
        "LateralFraction":lf
    })
    print(f"{base}: Ts={ts:.4f}s, IACC={iacc:.3f}, LF={lf:.3f}")

################################################################
# 5. SALVAR RESULTADOS
################################################################

df = pd.DataFrame(records)
df.to_csv(OUTPUT_CSV, index=False)
print(f"\nSalvo em: {OUTPUT_CSV}")
print(df.head())

"""# COMANDO PARA EXTRAIR COEFICIENTES DE ABSORÇÃO DO CONJUNTO DE DADOS PARA CALCULOS DE T60 PELAS FÓRMULAS"""

import pandas as pd
from tabulate import tabulate

# Carregar os arquivos
rooms = pd.read_parquet('/content/drive/MyDrive/Dissertação - Mestrado/config_salas/rooms.parquet')



# Lista para armazenar os resultados
results = []

# Iterar sobre as salas
for index, row in rooms.iterrows():
    # Obter dimensões da sala
    dimensions = row['dimensions']
    comprimento, largura, altura = dimensions

    # Calcular área e volume
    lw = comprimento * largura  # Superfície 1
    wh = largura * altura       # Superfície 2
    lh = comprimento * altura   # Superfície 3
    surface_area = 2 * (lw + wh + lh)
    volume = comprimento * largura * altura

    # Obter coeficientes de absorção
    absorption_coeff = row['absorption_coefficients']
    frequencies = row['frequencies']

    # Calcular coeficientes médios de absorção por banda de frequência
    mean_absorption = []
    for freq in frequencies:
        absorp_band = [
            absorption_coeff[f"room_{index}/Coeficiente_Absorcao_F_{freq}_L_{i+1}"]
            for i in range(6)
        ]
        mean_band = (
            absorp_band[0] * lw +
            absorp_band[1] * wh +
            absorp_band[2] * lh +
            absorp_band[3] * lw +
            absorp_band[4] * wh +
            absorp_band[5] * lh
        )
        mean_absorp_coeff_band = mean_band / surface_area
        mean_absorption.append(mean_absorp_coeff_band)

    # Adicionar resultados na lista
    results.append({
        "Sala": f"room_{index}",
        "Área Superficial (m²)": round(surface_area, 2),
        "Volume (m³)": round(volume, 2),
        "Superfície 1 (m²)": round(lw, 2),  # Comprimento x Largura
        "Superfície 2 (m²)": round(wh, 2),  # Largura x Altura
        "Superfície 3 (m²)": round(lh, 2),  # Comprimento x Altura
        "Superfície 4 (m²)": round(lw, 2),  # Igual à superfície 1
        "Superfície 5 (m²)": round(wh, 2),  # Igual à superfície 2
        "Superfície 6 (m²)": round(lh, 2),  # Igual à superfície 3
        "Absorção Média (125 Hz)": round(mean_absorption[0], 4),
        "Absorção Média (250 Hz)": round(mean_absorption[1], 4),
        "Absorção Média (500 Hz)": round(mean_absorption[2], 4),
        "Absorção Média (1000 Hz)": round(mean_absorption[3], 4),
        "Absorção Média (2000 Hz)": round(mean_absorption[4], 4),
        "Absorção Média (4000 Hz)": round(mean_absorption[5], 4),
    })

# Definir os cabeçalhos da tabela
headers = [
    "Sala", "Área Superficial (m²)", "Volume (m³)",
    "Superfície 1 (m²)", "Superfície 2 (m²)", "Superfície 3 (m²)",
    "Superfície 4 (m²)", "Superfície 5 (m²)", "Superfície 6 (m²)",
    "Absorção Média (125 Hz)", "Absorção Média (250 Hz)",
    "Absorção Média (500 Hz)", "Absorção Média (1000 Hz)",
    "Absorção Média (2000 Hz)", "Absorção Média (4000 Hz)"
]

# Exibir a tabela usando tabulate
print(tabulate(results, headers="keys", tablefmt="grid"))

# Salvar resultados em CSV
results_df = pd.DataFrame(results)
results_df.to_csv('/content/drive/MyDrive/Dissertação - Mestrado/config_salas/absorption_results.csv', index=False)

import os
import pandas as pd

# Caminhos dos arquivos
rooms_path = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/rooms.parquet'
absorption_results_path = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/absorption_results.csv'


# Carregar o arquivo rooms.parquet
rooms_data = pd.read_parquet(rooms_path)

# Verificar se absorption_results.csv existe
if not os.path.exists(absorption_results_path):
    print(f"O arquivo {absorption_results_path} não existe. Criando um arquivo vazio com as colunas esperadas...")

    # Criar DataFrame vazio com as colunas esperadas
    empty_columns = [
        'Sala', 'Área Superficial (m²)', 'Volume (m³)',
        'Absorção Média (125 Hz)', 'Absorção Média (250 Hz)',
        'Absorção Média (500 Hz)', 'Absorção Média (1000 Hz)',
        'Absorção Média (2000 Hz)', 'Absorção Média (4000 Hz)'
    ]

    empty_df = pd.DataFrame(columns=empty_columns)

    # Criar diretório se não existir
    os.makedirs(os.path.dirname(absorption_results_path), exist_ok=True)

    # Salvar o DataFrame vazio como CSV
    empty_df.to_csv(absorption_results_path, index=False)
    print(f"Arquivo criado em: {absorption_results_path}")

# Carregar o CSV (seja o criado ou o que já existia)
absorption_results = pd.read_csv(absorption_results_path)

# Solicitar ao usuário a sala a ser analisada
room_to_analyze = input("Insira a sala a ser analisada (ex: room_0): ")

# Garantir que a sala está presente nos dois arquivos
if room_to_analyze in rooms_data['room_key'].values and room_to_analyze in absorption_results['Sala'].values:
    # Obter informações do arquivo rooms.parquet
    room_info = rooms_data[rooms_data['room_key'] == room_to_analyze]

    # Obter informações do arquivo absorption_results.csv
    absorption_info = absorption_results[absorption_results['Sala'] == room_to_analyze]

    # Exibir as informações
    print("\nInformações da sala:")
    print("Room Key:", room_to_analyze)
    print("Dimensões:", room_info['dimensions'].values[0])
    print("Temperatura:", room_info['temperature'].values[0], "°C")
    print("Umidade:", room_info['humidity'].values[0])
    print("Coeficientes de Absorção:", room_info['absorption_coefficients'].values[0])
    print("Frequências:", room_info['frequencies'].values[0])

    print("\nInformações de Área e Volume:")
    print("Área Superficial (m²):", absorption_info['Área Superficial (m²)'].values[0])
    print("Volume (m³):", absorption_info['Volume (m³)'].values[0])
    print("\nCoeficientes de Absorção Média por Banda de Frequência:")
    print("Absorção Média (125 Hz):", absorption_info['Absorção Média (125 Hz)'].values[0])
    print("Absorção Média (250 Hz):", absorption_info['Absorção Média (250 Hz)'].values[0])
    print("Absorção Média (500 Hz):", absorption_info['Absorção Média (500 Hz)'].values[0])
    print("Absorção Média (1000 Hz):", absorption_info['Absorção Média (1000 Hz)'].values[0])
    print("Absorção Média (2000 Hz):", absorption_info['Absorção Média (2000 Hz)'].values[0])
    print("Absorção Média (4000 Hz):", absorption_info['Absorção Média (4000 Hz)'].values[0])

else:
    print(f"Sala {room_to_analyze} não encontrada em um dos arquivos.")

"""# T60 A PARTIR DAS FÓMULAS (T60 Sabine, T60 Eyring (s), T60 Millington (s))"""

import os
import numpy as np
import pandas as pd
import re

# Constantes
SOUNDSPEED = 343.0
OCTAVE_BANDS = np.array([125, 250, 500, 1000, 2000, 4000])

def mean_alpha(alphas, surfaces):
    """
    Calcula a média das absorções (alphas) ponderada pelas áreas (surfaces).
    """
    return np.average(alphas, axis=0, weights=surfaces)

def nrc(alphas):
    """
    Calcula o NRC (Noise Reduction Coefficient) médio,
    considerando as frequências de 250, 500, 1000 e 2000 Hz.
    """
    return np.mean([alphas[1], alphas[2], alphas[3], alphas[4]])

def t60_sabine(surface_area, alpha, volume, c=SOUNDSPEED):
    """
    Fórmula de Sabine para estimar o T60 em segundos.
    T60 = 24 * ln(10) * Volume / (c * (Área * alpha))
    """
    A = surface_area * alpha
    return 24 * np.log(10) * volume / (c * A)

def t60_eyring(surface_area, alpha, volume, c=SOUNDSPEED):
    """
    Fórmula de Eyring para estimar o T60 em segundos.
    T60 = 24 * ln(10) * Volume / (c * (-Área * ln(1 - alpha)))
    """
    A = -surface_area * np.log(1 - alpha)
    return 24 * np.log(10) * volume / (c * A)

def t60_millington(surface_area, alpha, volume, c=SOUNDSPEED):
    """
    Fórmula de Millington para estimar o T60 em segundos.
    T60 = 24 * ln(10) * Volume / (c * sum(-Área * ln(1 - alpha)))
    """
    A = -np.sum(surface_area * np.log(1 - alpha))
    return 24 * np.log(10) * volume / (c * A)

def gerar_t60_formulas():
    """
    Lê as informações de salas (rooms.parquet) e coeficientes de absorção (absorption_results.csv),
    calcula somente as seguintes funções para cada banda de oitava e para cada sala:
      - t60_sabine
      - t60_eyring
      - t60_millington
    (Removendo a coluna 'NRC' do resultado e ainda mantendo 'Frequency (Hz)' apenas
     para permitir o pivot, mas não haverá coluna final de 'Frequency (Hz)'.)

    Salva o resultado em 'T60_formulas.csv' no diretório especificado.
    """
    rooms_path = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/rooms.parquet'
    absorption_results_path = '/content/drive/MyDrive/Dissertação - Mestrado/config_salas/absorption_results.csv'
    output_directory = '/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3'
    output_csv_filename = 'T60_formulas.csv'
    output_csv_path = os.path.join(output_directory, output_csv_filename)

    # Carregar dados
    rooms_df = pd.read_parquet(rooms_path)
    absorption_df = pd.read_csv(absorption_results_path)

    # Identificar chaves de salas em comum
    room_keys = set(rooms_df['room_key']).intersection(absorption_df['Sala'])

    resultados = []
    for room in room_keys:
        absorption_data = absorption_df[absorption_df['Sala'] == room]

        surface_area = float(absorption_data['Área Superficial (m²)'].iloc[0])
        volume = float(absorption_data['Volume (m³)'].iloc[0])

        # Alphas médios por banda de oitava
        alphas = [
            float(absorption_data[f'Absorção Média ({freq} Hz)'].iloc[0])
            for freq in OCTAVE_BANDS
        ]

        # Calcular T60 (Sabine, Eyring, Millington) em cada banda
        for freq, alpha in zip(OCTAVE_BANDS, alphas):
            sabine_val = t60_sabine(surface_area, alpha, volume)
            eyring_val = t60_eyring(surface_area, alpha, volume)
            millington_val = t60_millington(surface_area, alpha, volume)

            resultados.append({
                'Room Key': room,
                'Frequency (Hz)': freq,
                'T60 Sabine (s)': sabine_val,
                'T60 Eyring (s)': eyring_val,
                'T60 Millington (s)': millington_val,
                'Surface Area (m²)': surface_area,
                'Volume (m³)': volume
            })

    df_resultados = pd.DataFrame(resultados)
    # Ordenar antes de salvar, caso queira 'Room Key' organizado no arquivo "longo"
    def extract_room_number(key):
        m = re.search(r'room_(\d+)', key)
        return int(m.group(1)) if m else 999999

    df_resultados['Room Num'] = df_resultados['Room Key'].apply(extract_room_number)
    df_resultados.sort_values(by=['Room Num', 'Frequency (Hz)'], inplace=True)
    df_resultados.drop(columns=['Room Num'], inplace=True)

    df_resultados.to_csv(output_csv_path, index=False)
    print(f"Arquivo gerado sem coluna 'NRC' em: {output_csv_path}")
    print(df_resultados.head())

    return output_csv_path  # Retorna o caminho do CSV gerado

def pivotar_t60_formulas(csv_entrada, csv_saida):
    """
    Lê o arquivo CSV `csv_entrada` (que contém colunas:
      [Room Key, Frequency (Hz), T60 Sabine (s), T60 Eyring (s), T60 Millington (s),
       Surface Area (m²), Volume (m³)])
    e gera um CSV `csv_saida` onde cada sala (Room Key) aparece em UMA linha
    e cada frequência (Hz) aparece como colunas separadas, nas formas:
       - T60 Sabine (s) 125 (Hz)
       - T60 Eyring (s) 125 (Hz)
       - T60 Millington (s) 125 (Hz)
       etc.

    Também inclui, em colunas separadas, os valores de Surface Area (m²)
    e Volume (m³) para cada sala (sem 'NRC'), e organiza o resultado
    por ordem crescente de Room Key (room_0, room_1, etc.).
    """
    df = pd.read_csv(csv_entrada)

    # Pivot: index='Room Key', columns='Frequency (Hz)', values=...
    df_t60 = df.pivot_table(
        index='Room Key',
        columns='Frequency (Hz)',
        values=['T60 Sabine (s)', 'T60 Eyring (s)', 'T60 Millington (s)']
    )

    df_t60.columns = [
        f"{col[0]} {int(col[1])} (Hz)"
        for col in df_t60.columns
    ]

    # Coletar colunas únicas (Room Key, Surface Area, Volume)
    df_info = df[['Room Key', 'Surface Area (m²)', 'Volume (m³)']].drop_duplicates(subset='Room Key')
    df_info.set_index('Room Key', inplace=True)

    df_final = df_info.join(df_t60, how='inner')
    df_final.reset_index(inplace=True)

    # Agora, ordenar por número de sala (room_0, room_1, etc.)
    def extract_room_number(key):
        m = re.search(r'room_(\d+)', key)
        return int(m.group(1)) if m else 999999

    df_final['Room Num'] = df_final['Room Key'].apply(extract_room_number)
    df_final.sort_values(by='Room Num', inplace=True)
    df_final.drop(columns='Room Num', inplace=True)

    df_final.to_csv(csv_saida, index=False)
    print(f"Arquivo gerado com colunas pivotadas (sem 'NRC', sem 'Frequency (Hz)'): {csv_saida}")
    print(df_final.head())

def main():
    csv_gerado = gerar_t60_formulas()

    output_directory = '/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3'
    pivot_csv_filename = 'T60_formulas_wide.csv'
    pivot_csv_path = os.path.join(output_directory, pivot_csv_filename)

    pivotar_t60_formulas(csv_gerado, pivot_csv_path)

if __name__ == "__main__":
    main()

"""# COMPILAÇÃO DE TODOS OS ARQUIVOS .csv"""

import pandas as pd

# ————— Assumindo que você já carregou seus DataFrames em dfs:
# dfs['rir_summary_principal'], dfs['DRR'], dfs['spatial_params'], dfs['T60_formulas_wide']

# 1) Preparar rir_summary_principal e DRR
df_rir = dfs['rir_summary_principal'].copy()
# extrai “room_key” de name, e.g. “room_0_FULL_src0_rec0_mic1.wav” → “room_0”
df_rir['room_key'] = (
    df_rir['name']
      .str.split('_')
      .str[:2]
      .str.join('_')
)

df_drr = dfs['DRR'].copy()
df_drr = df_drr.rename(columns={'file': 'name'})

# merge inicial: 50 000 registros
df = df_rir.merge(df_drr, on='name', how='left')


# 2) Expandir spatial_params de 25 000 para 50 000 entradas
df_sp = dfs['spatial_params'].copy()
# extrai também “room_key” de base, e.g. “room_0_FULL_src0_rec0”
df_sp['room_key'] = (
    df_sp['base']
      .str.split('_')
      .str[:2]
      .str.join('_')
)

# duplicar cada linha para mic1 e mic2
df_sp_mic1 = df_sp.assign(name = df_sp['base'] + '_mic1.wav')
df_sp_mic2 = df_sp.assign(name = df_sp['base'] + '_mic2.wav')
df_sp_expanded = pd.concat([df_sp_mic1, df_sp_mic2], ignore_index=True)

# merge dos parâmetros espaciais
df = df.merge(
    df_sp_expanded.drop(columns=['base']),
    on=['name','room_key'],
    how='left'
)


# 3) Merge com T60_formulas_wide (1 000 → 50 000 registros via room_key)
df_t60 = dfs['T60_formulas_wide'].copy().rename(columns={'Room Key':'room_key'})

df = df.merge(df_t60, on='room_key', how='left')


# ————— Verificação final
print(f"Registros no DataFrame final: {len(df):,}")   # deve ser 50 000
print(df.columns)                                   # todas as colunas de todos os merges
print(df.head())

df.info()

"""# TARGETS

BASE: ARTIGO: GRAFICOS BONS de SNR COEFF DE ABS.pdf

TARGET SERA = Millington, Eyring, Sabine, e usando ISOS (BIBILIOTECA GITHUB ACOUSTICS)

Principais normas ISO:

1. ISO 3382‑1:2009 – Performance spaces (salas de concerto, auditórios): define T20/T30/T10, EDT, C80, D50, G, Ts, IACC, LF, etc.
ISO

2. ISO 3382‑2:2008 – Salas comuns (escritórios, salas de aula): método concentrado em RT60 (T20/T30)
ISO

3. ISO 3382‑3 – Open‑plan offices: foca em índices de inteligibilidade (D50/C50) e nível de ruído de fundo

4. ISO 354:2003 – Medição de coeficiente de absorção sonora em sala reverberante

5. ISO 18233:2006 – Aplicação de novos métodos (MLS, sweeps) para medir RIR

"""

# Supondo que seu DataFrame final se chame `df`

# 1) Liste as colunas a remover
cols_to_drop = [
    'mic_x',
    'room_x',
    'source_index_y',
    'receiver_index_y',
    'mic_y',
    'room_y'
]

# 2) Remova-as do DataFrame
df = df.drop(columns=cols_to_drop)

# 3) Verifique o resultado
print(df.info())

import os

# Diretório de saída
output_dir = '/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS'
os.makedirs(output_dir, exist_ok=True)

# Caminho completo do arquivo
output_path = os.path.join(output_dir, 'merged_params.csv')

# Salvar como CSV sem o índice
df.to_csv(output_path, index=False)

print(f"DataFrame salvo em: {output_path}")

"""# ANALISANDO OS ÁUDIOS ANECÓICOS

Eixo vertical (Centroide Espectral - Hz): Representa a frequência média ponderada das componentes espectrais do sinal, em Hertz (Hz). Se o centroide espectral estiver em uma frequência baixa, significa que o sinal tem mais energia em frequências baixas (graves), enquanto um centroide em uma frequência mais alta indica uma predominância de frequências mais altas (agudas).

Eixo horizontal (Tempo - s): Representa o tempo ao longo da duração do áudio. Cada ponto no gráfico mostra o centroide espectral em um determinado instante no tempo.

FONTE: https://github.com/musikalkemist/AudioSignalProcessingForML/blob/master/23-%20Spectral%20centroid%20and%20bandwidth/Spectral%20centroid%20and%20bandwidth.ipynb
"""

import random
import os
import librosa
import matplotlib.pyplot as plt
import soundfile as sf
from IPython.display import Audio

# Caminho para o diretório contendo os arquivos de áudio
speech_root_dir = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/LibriSpeech/train-clean-100"

# Busca todos os arquivos .flac no diretório
all_flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]

# Seleciona 5 arquivos .flac aleatórios
random_audio_paths = random.sample(all_flacs, 5)

# Definir o tamanho do quadro e o comprimento do salto
FRAME_SIZE = 1024
HOP_LENGTH = 512

# Plotando os centroides espectrais para os 5 áudios aleatórios
plt.figure(figsize=(25, 15))

for i, audio_path in enumerate(random_audio_paths, 1):
    # Carrega o áudio com Librosa
    audio_data, sr = librosa.load(audio_path)

    # Calcular o centroide espectral
    sc = librosa.feature.spectral_centroid(y=audio_data, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)[0]

    # Convertendo os quadros em tempo
    frames = range(len(sc))
    t = librosa.frames_to_time(frames, hop_length=HOP_LENGTH)

    # Adiciona o gráfico para cada áudio
    plt.subplot(5, 1, i)
    plt.plot(t, sc, label=f'Áudio {i}', color='b')
    plt.title(f'Centroide Espectral - Áudio {i}')
    plt.xlabel('Tempo (s)')
    plt.ylabel('Centroide Espectral (Hz)')
    plt.tight_layout()

plt.show()

import random
import os
import librosa
import matplotlib.pyplot as plt
import soundfile as sf

# Caminho para o diretório contendo os arquivos de áudio
speech_root_dir = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/LibriSpeech/train-clean-100"

# Busca todos os arquivos .flac no diretório
all_flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]

# Seleciona 5 arquivos .flac aleatórios
random_audio_paths = random.sample(all_flacs, 5)

# Definir o tamanho do quadro e o comprimento do salto
FRAME_SIZE = 1024
HOP_LENGTH = 512

# Plotando os centroides espectrais para os 5 áudios aleatórios no mesmo gráfico
plt.figure(figsize=(25, 10))

for i, audio_path in enumerate(random_audio_paths, 1):
    # Carrega o áudio com Librosa
    audio_data, sr = librosa.load(audio_path)

    # Calcular o centroide espectral
    sc = librosa.feature.spectral_centroid(y=audio_data, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)[0]

    # Convertendo os quadros em tempo
    frames = range(len(sc))
    t = librosa.frames_to_time(frames, hop_length=HOP_LENGTH)

    # Adiciona o gráfico para cada áudio no mesmo gráfico
    plt.plot(t, sc, label=f'Áudio {i}')

# Personalizando o gráfico
plt.title('Centroide Espectral para 5 Áudios Aleatórios')
plt.xlabel('Tempo (s)')
plt.ylabel('Centroide Espectral (Hz)')
plt.legend(loc='upper right')
plt.tight_layout()

plt.show()

import random
import os
import librosa
import matplotlib.pyplot as plt
import soundfile as sf

# Caminho para o diretório contendo os arquivos de áudio
speech_root_dir = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/LibriSpeech/train-clean-100"

# Busca todos os arquivos .flac no diretório
all_flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]

# Seleciona 5 arquivos .flac aleatórios
random_audio_paths = random.sample(all_flacs, 5)

# Definir o tamanho do quadro e o comprimento do salto
FRAME_SIZE = 1024
HOP_LENGTH = 512

# Duração do áudio truncado em segundos
audio_duration = 5
fs_target = 16000  # Frequência de amostragem

# Plotando os centroides espectrais para os 5 áudios aleatórios no mesmo gráfico
plt.figure(figsize=(25, 10))

for i, audio_path in enumerate(random_audio_paths, 1):
    # Carrega o áudio com Librosa e trunca para 5 segundos
    audio_data, sr = librosa.load(audio_path, sr=fs_target, duration=audio_duration)

    # Calcular o centroide espectral
    sc = librosa.feature.spectral_centroid(y=audio_data, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)[0]

    # Convertendo os quadros em tempo
    frames = range(len(sc))
    t = librosa.frames_to_time(frames, hop_length=HOP_LENGTH)

    # Adiciona o gráfico para cada áudio no mesmo gráfico
    plt.plot(t, sc, label=f'Áudio {i}')

# Personalizando o gráfico
plt.title('Centroide Espectral para 5 Áudios Aleatórios (5 segundos)')
plt.xlabel('Tempo (s)')
plt.ylabel('Centroide Espectral (Hz)')
plt.legend(loc='upper right')
plt.tight_layout()

plt.show()

"""PARA TODOS OS AUDIOS USANDO MATPLOTLIB"""

import random
import os
import librosa
import plotly.graph_objects as go
import numpy as np
import soundfile as sf
from tqdm import tqdm  # Importando o tqdm

# Caminho para o diretório contendo os arquivos de áudio
speech_root_dir = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/LibriSpeech/train-clean-100"

# Busca todos os arquivos .flac no diretório
all_flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]

# Seleciona um número de áudios para cálculo (ex: 500 áudios)
num_files_to_process = 100
random_audio_paths = random.sample(all_flacs, num_files_to_process)

# Definir o tamanho do quadro e o comprimento do salto
FRAME_SIZE = 1024
HOP_LENGTH = 512

# Duração do áudio truncado em segundos
audio_duration = 5
fs_target = 16000  # Frequência de amostragem

# Inicializa uma lista para armazenar os centroides espectrais
centroid_list = []
num_frames = 0

# Processa os áudios e acumula o centroide espectral
for i, audio_path in tqdm(enumerate(random_audio_paths, 1), total=num_files_to_process, desc="Processando áudios"):
    # Carrega o áudio com Librosa e trunca para 5 segundos
    audio_data, sr = librosa.load(audio_path, sr=fs_target, duration=audio_duration)

    # Calcular o centroide espectral
    sc = librosa.feature.spectral_centroid(y=audio_data, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)[0]

    # Adiciona o centroide espectral à lista
    centroid_list.append(sc)

    # Armazena o número de frames do primeiro áudio
    if num_frames == 0:
        num_frames = len(sc)

# Interpolação para garantir que todos os centroides tenham o mesmo número de frames
centroid_avg = np.zeros((num_frames,))

for sc in tqdm(centroid_list, desc="Interpolando centroides", total=len(centroid_list)):
    # Interpola o centroide espectral para o número de frames desejado
    sc_resized = np.interp(np.linspace(0, len(sc)-1, num_frames), np.arange(len(sc)), sc)
    centroid_avg += sc_resized

# Calcula a média do centroide espectral
centroid_avg /= len(centroid_list)

# Convertendo os quadros em tempo
t = librosa.frames_to_time(range(num_frames), hop_length=HOP_LENGTH)

# Usando Plotly para criar o gráfico interativo
fig = go.Figure()

# Adicionando a curva de média do centroide espectral
fig.add_trace(go.Scatter(x=t, y=centroid_avg, mode='lines', name='Média do Centroide Espectral', line=dict(color='blue')))

# Personalizando o gráfico
fig.update_layout(
    title=f'Média do Centroide Espectral para {num_files_to_process} Áudios Aleatórios (5 segundos)',
    xaxis_title='Tempo (s)',
    yaxis_title='Centroide Espectral (Hz)',
    template='plotly_white'
)

# Exibindo o gráfico
fig.show()

import random
import os
import librosa
import plotly.graph_objects as go
import numpy as np
import soundfile as sf
from tqdm import tqdm  # Importando o tqdm

# Caminho para o diretório contendo os arquivos de áudio
speech_root_dir = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/LibriSpeech/train-clean-100"

# Busca todos os arquivos .flac no diretório
all_flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]

# Seleciona 100 áudios aleatórios para cálculo
num_files_to_process = 100
random_audio_paths = random.sample(all_flacs, num_files_to_process)

# Definir o tamanho do quadro e o comprimento do salto
FRAME_SIZE = 1024
HOP_LENGTH = 512

# Duração do áudio truncado em segundos
audio_duration = 5
fs_target = 16000  # Frequência de amostragem

# Inicializa uma lista para armazenar as larguras espectrais
bandwidth_list = []
num_frames = 0

# Processa os áudios e acumula a largura espectral
for i, audio_path in tqdm(enumerate(random_audio_paths, 1), total=num_files_to_process, desc="Processando áudios"):
    # Carrega o áudio com Librosa e trunca para 5 segundos
    audio_data, sr = librosa.load(audio_path, sr=fs_target, duration=audio_duration)

    # Calcular a largura espectral
    bandwidth = librosa.feature.spectral_bandwidth(y=audio_data, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)[0]

    # Adiciona a largura espectral à lista
    bandwidth_list.append(bandwidth)

    # Armazena o número de frames do primeiro áudio
    if num_frames == 0:
        num_frames = len(bandwidth)

# Inicializa a figura do gráfico
fig = go.Figure()

# Adiciona cada curva de largura espectral individual ao gráfico
for i, bandwidth in tqdm(enumerate(bandwidth_list, 1), total=len(bandwidth_list), desc="Plotando as curvas"):
    # Interpolando cada largura espectral para o número de frames desejado
    bandwidth_resized = np.interp(np.linspace(0, len(bandwidth)-1, num_frames), np.arange(len(bandwidth)), bandwidth)

    # Adicionando a curva com uma cor translúcida
    fig.add_trace(go.Scatter(
        x=librosa.frames_to_time(range(num_frames), hop_length=HOP_LENGTH),
        y=bandwidth_resized,
        mode='lines',
        name=f'Audiol {i}',  # Nome identificador de cada áudio
        line=dict(color='rgba(0, 0, 255, 0.1)'),  # Cor com opacidade para permitir ver todas as curvas
        showlegend=False  # Não mostrar legenda para cada linha individual
    ))

# Personalizando o gráfico
fig.update_layout(
    title=f'100 Curvas da Largura Espectral para {num_files_to_process} Áudios Aleatórios (5 segundos)',
    xaxis_title='Tempo (s)',
    yaxis_title='Largura Espectral (Hz)',
    template='plotly_white'
)

# Exibindo o gráfico
fig.show()

import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf

# Caminho para o arquivo de áudio
audio_path = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/LibriSpeech/train-clean-100/103/1240/103-1240-0000.flac"

# Carregar o áudio
y, sr = librosa.load(audio_path, sr=None)

# Calcular a largura espectral
spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)

# Calcular o centroide espectral
centroid = librosa.feature.spectral_centroid(y=y, sr=sr)

# Calcular o espectrograma (magnitude)
S, phase = librosa.magphase(librosa.stft(y=y))

# Calcular o espectrograma reatribuído (reassigned spectrogram)
freqs, times, D = librosa.reassigned_spectrogram(y, fill_nan=True)

# Criando a figura do gráfico com mais clareza
fig, ax = plt.subplots(nrows=2, figsize=(12, 8), sharex=True)

# --- Plotando o gráfico 1: Largura Espectral ---
times_bw = librosa.times_like(spec_bw)  # Converter para tempos

ax[0].semilogy(times_bw, spec_bw[0], label='Spectral Bandwidth', color='blue', linewidth=2)
ax[0].set_ylabel('Spectral Bandwidth (Hz)', fontsize=12)
ax[0].set_title('Spectral Bandwidth Over Time', fontsize=14)
ax[0].legend(loc='upper right')
ax[0].grid(True, which='both', linestyle='--', linewidth=0.5)
ax[0].label_outer()

# --- Plotando o gráfico 2: Espectrograma e Região de Centroide ± Largura Espectral ---
# Exibindo o espectrograma logarítmico
img = librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),
                               y_axis='log', x_axis='time', ax=ax[1], cmap='inferno')

ax[1].set_title('Log Power Spectrogram', fontsize=14)
ax[1].set_ylabel('Frequency (Hz)', fontsize=12)

# Preenchendo a área entre o centroide ± largura espectral
ax[1].fill_between(times_bw, np.maximum(0, centroid[0] - spec_bw[0]),
                   np.minimum(centroid[0] + spec_bw[0], sr / 2),
                   alpha=0.5, label='Centroid ± Bandwidth', color='orange')

# Plotando o centroide espectral
ax[1].plot(times_bw, centroid[0], label='Spectral Centroid', color='white', linewidth=2)

ax[1].legend(loc='lower right')
ax[1].grid(True, which='both', linestyle='--', linewidth=0.5)

# Exibindo a barra de cores para o espectrograma
cbar = fig.colorbar(img, ax=ax[1], format="%+2.0f dB")
cbar.set_label('Amplitude (dB)', fontsize=12)

# Ajustando o layout para evitar sobreposição de elementos
plt.tight_layout()

# Exibindo o gráfico
plt.show()

import random
import os
import librosa
import plotly.graph_objects as go
import numpy as np
import soundfile as sf
from tqdm import tqdm  # Importando o tqdm

# Caminho para o diretório contendo os arquivos de áudio
speech_root_dir = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/LibriSpeech/train-clean-100"

# Busca todos os arquivos .flac no diretório
all_flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]

# Seleciona 100 áudios aleatórios para cálculo
num_files_to_process = 100
random_audio_paths = random.sample(all_flacs, num_files_to_process)

# Definir o tamanho do quadro e o comprimento do salto
FRAME_SIZE = 1024
HOP_LENGTH = 512

# Duração do áudio truncado em segundos
audio_duration = 5
fs_target = 16000  # Frequência de amostragem

# Inicializa uma lista para armazenar as larguras espectrais
bandwidth_list = []
num_frames = 0

# Processa os áudios e acumula a largura espectral
for i, audio_path in tqdm(enumerate(random_audio_paths, 1), total=num_files_to_process, desc="Processando áudios"):
    # Carrega o áudio com Librosa e trunca para 5 segundos
    audio_data, sr = librosa.load(audio_path, sr=fs_target, duration=audio_duration)

    # Calcular a largura espectral
    bandwidth = librosa.feature.spectral_bandwidth(y=audio_data, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)[0]

    # Adiciona a largura espectral à lista
    bandwidth_list.append(bandwidth)

    # Armazena o número de frames do primeiro áudio
    if num_frames == 0:
        num_frames = len(bandwidth)

# Inicializa a lista para armazenar a largura espectral interpolada para todos os áudios
bandwidth_resized_list = []

# Interpolação para garantir que todas as larguras espectrais tenham o mesmo número de frames
for bandwidth in tqdm(bandwidth_list, desc="Interpolando larguras espectrais", total=len(bandwidth_list)):
    # Interpola a largura espectral para o número de frames desejado
    bandwidth_resized = np.interp(np.linspace(0, len(bandwidth)-1, num_frames), np.arange(len(bandwidth)), bandwidth)
    bandwidth_resized_list.append(bandwidth_resized)

# Calcula a média da largura espectral
bandwidth_avg = np.mean(bandwidth_resized_list, axis=0)

# Convertendo os quadros em tempo
t = librosa.frames_to_time(range(num_frames), hop_length=HOP_LENGTH)

# Usando Plotly para criar o gráfico interativo
fig = go.Figure()

# Adicionando a curva de largura espectral média
fig.add_trace(go.Scatter(x=t, y=bandwidth_avg, mode='lines', name='Média da Largura Espectral', line=dict(color='black', width=3)))

# Adicionando as 100 curvas individuais
for i, bandwidth_resized in tqdm(enumerate(bandwidth_resized_list, 1), total=len(bandwidth_resized_list), desc="Plotando as curvas"):
    # Adicionando a curva com cor translúcida
    fig.add_trace(go.Scatter(
        x=t,
        y=bandwidth_resized,
        mode='lines',
        name=f'Audiol {i}',  # Nome identificador de cada áudio
        line=dict(color='rgba(0, 0, 255, 0.1)'),  # Cor translúcida
        showlegend=False  # Não mostrar legenda para cada linha individual
    ))

# Personalizando o gráfico
fig.update_layout(
    title=f'100 Curvas da Largura Espectral para {num_files_to_process} Áudios Aleatórios (5 segundos)',
    xaxis_title='Tempo (s)',
    yaxis_title='Largura Espectral (Hz)',
    template='plotly_white'
)

# Exibindo o gráfico
fig.show()

"""CENTROIDE"""

import os
import librosa
import plotly.graph_objects as go
import numpy as np
import soundfile as sf
from tqdm import tqdm  # Importando o tqdm

# Caminho para o diretório contendo os arquivos de áudio
speech_root_dir = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/LibriSpeech/train-clean-100"

# Busca todos os arquivos .flac no diretório
all_flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]

# Definir o tamanho do quadro e o comprimento do salto
FRAME_SIZE = 1024
HOP_LENGTH = 512

# Duração do áudio truncado em segundos
audio_duration = 5
fs_target = 16000  # Frequência de amostragem

# Inicializa uma lista para armazenar os centroides espectrais
centroid_list = []
num_frames = 0

# Processa os áudios e acumula o centroide espectral
for i, audio_path in tqdm(enumerate(all_flacs, 1), total=len(all_flacs), desc="Processing audio files"):
    # Carrega o áudio com Librosa e trunca para 5 segundos
    audio_data, sr = librosa.load(audio_path, sr=fs_target, duration=audio_duration)

    # Calcular o centroide espectral
    sc = librosa.feature.spectral_centroid(y=audio_data, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)[0]

    # Adiciona o centroide espectral à lista
    centroid_list.append(sc)

    # Armazena o número de frames do primeiro áudio
    if num_frames == 0:
        num_frames = len(sc)

# Interpolação para garantir que todos os centroides tenham o mesmo número de frames
centroid_avg = np.zeros((num_frames,))

for sc in tqdm(centroid_list, desc="Interpolating centroids", total=len(centroid_list)):
    # Interpola o centroide espectral para o número de frames desejado
    sc_resized = np.interp(np.linspace(0, len(sc)-1, num_frames), np.arange(len(sc)), sc)
    centroid_avg += sc_resized

# Calcula a média do centroide espectral
centroid_avg /= len(centroid_list)

# Convertendo os quadros em tempo
t = librosa.frames_to_time(range(num_frames), hop_length=HOP_LENGTH)

# Usando Plotly para criar o gráfico interativo
fig = go.Figure()

# Adicionando a curva de média do centroide espectral
fig.add_trace(go.Scatter(x=t, y=centroid_avg, mode='lines', name='Spectral Centroid Mean', line=dict(color='blue')))

# Personalizando o gráfico
fig.update_layout(
    title=f'Mean Spectral Centroid for All Audios ({len(all_flacs)} Audios) (5 seconds)',
    xaxis_title='Time (s)',
    yaxis_title='Spectral Centroid (Hz)',
    template='plotly_white'
)

# Exibindo o gráfico
fig.show()

"""LARGURA DE BANDA"""

import os
import librosa
import plotly.graph_objects as go
import numpy as np
import soundfile as sf
from tqdm import tqdm  # Importando o tqdm

# Caminho para o diretório contendo os arquivos de áudio
speech_root_dir = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/LibriSpeech/train-clean-100"

# Busca todos os arquivos .flac no diretório
all_flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]

# Definir o tamanho do quadro e o comprimento do salto
FRAME_SIZE = 1024
HOP_LENGTH = 512

# Duração do áudio truncado em segundos
audio_duration = 5
fs_target = 16000  # Frequência de amostragem

# Inicializa uma lista para armazenar as larguras espectrais
bandwidth_list = []
num_frames = 0

# Processa os áudios e acumula a largura espectral
for i, audio_path in tqdm(enumerate(all_flacs, 1), total=len(all_flacs), desc="Processing audio files"):
    # Carrega o áudio com Librosa e trunca para 5 segundos
    audio_data, sr = librosa.load(audio_path, sr=fs_target, duration=audio_duration)

    # Calcular a largura espectral
    bandwidth = librosa.feature.spectral_bandwidth(y=audio_data, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)[0]

    # Adiciona a largura espectral à lista
    bandwidth_list.append(bandwidth)

    # Armazena o número de frames do primeiro áudio
    if num_frames == 0:
        num_frames = len(bandwidth)

# Interpolação para garantir que todas as larguras espectrais tenham o mesmo número de frames
bandwidth_avg = np.zeros((num_frames,))

for bandwidth in tqdm(bandwidth_list, desc="Interpolating bandwidths", total=len(bandwidth_list)):
    # Interpola a largura espectral para o número de frames desejado
    bandwidth_resized = np.interp(np.linspace(0, len(bandwidth)-1, num_frames), np.arange(len(bandwidth)), bandwidth)
    bandwidth_avg += bandwidth_resized

# Calcula a média da largura espectral
bandwidth_avg /= len(bandwidth_list)

# Convertendo os quadros em tempo
t = librosa.frames_to_time(range(num_frames), hop_length=HOP_LENGTH)

# Usando Plotly para criar o gráfico interativo
fig = go.Figure()

# Adicionando a curva de média da largura espectral
fig.add_trace(go.Scatter(x=t, y=bandwidth_avg, mode='lines', name='Spectral Bandwidth Mean', line=dict(color='blue')))

# Personalizando o gráfico
fig.update_layout(
    title=f'Mean Spectral Bandwidth for All Audios ({len(all_flacs)} Audios) (5 seconds)',
    xaxis_title='Time (s)',
    yaxis_title='Spectral Bandwidth (Hz)',
    template='plotly_white'
)

# Exibindo o gráfico
fig.show()

"""PEGAR GRAFICOS DE GERAÇÃO_DE_ESPECTROGRAMAS.ipynb

# CONVOLUINDO AUDIOS ANECOICOS COM RIRs

# CONVOLUINDO E REGISTRANDO O TEMPO DE INÍCIO E FIM DE RUÍDOS
"""

from google.colab import drive
import os

# Monta o Google Drive
drive.mount('/content/drive')

"""## SEM RUÍDO"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
convolution_with_speech_only_mono.py
────────────────────────────────────────────────────────────────────────
• Escolhe fala aleatória por registro, convolui apenas fala,
  processa cada microfone individualmente e salva WAVs mono.
• CSV inclui: Sala, Nome do Arquivo, Fonte, Receptor, Audio_fala
• **Atualizado**: remove o prefixo duplicado nos nomes dos WAVs e
  na coluna “Nome do Arquivo”.
• **Novo**: NÃO há mais truncagem das RIRs — elas são usadas na íntegra.
"""

import os, re, random
import numpy as np
import pandas as pd
import librosa, soundfile as sf
from scipy.signal import fftconvolve
from tqdm.auto import tqdm

# ------------------ PATHS ------------------
speech_root_dir = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/"
ir_speech_root  = "/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/FILT_SOM_FASE_ZERO"
output_raw_root = "/content/drive/MyDrive/PREPROCESSING_1s/CONV/MONO_SR_sem_trunc_mod"
csv_output_dir  = "/content/drive/MyDrive/PREPROCESSING_1s/CONV/METRICS_SR_sem_trunc_mod"
checkpoint_file = "/content/drive/MyDrive/PREPROCESSING_1s/CONV/checkpoint_SR_sem_trunc_mod.txt"

receivers_path  = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/receivers.parquet"
sources_path    = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/sources.parquet"

# ------------------ LOAD CONFIG ------------------
receivers_df = pd.read_parquet(receivers_path)
sources_df   = pd.read_parquet(sources_path)

# ------------------ PARAMETERS ------------------
speed_of_sound = 343.0   # m/s
fs_target      = 16000   # Hz
audio_fs       = 16000   # Hz speech
audio_duration = 1      # s

# ----------------- HELPERS -----------------
def read_checkpoint():
    return open(checkpoint_file).read().strip() if os.path.exists(checkpoint_file) else None

def write_checkpoint(room):
    with open(checkpoint_file, "w") as f:
        f.write(room)

def pad_or_trim(sig, length):
    return sig[:length] if len(sig) >= length else np.pad(sig, (0, length - len(sig)))

def load_audio(path):
    audio, fs = sf.read(path)
    if fs != audio_fs:
        audio = librosa.resample(audio, orig_sr=fs, target_sr=audio_fs)
    return pad_or_trim(audio, fs_target * audio_duration)

def load_rir(path):
    """Carrega a RIR integral; se não existir, devolve um vetor de zeros de 1 s."""
    if not os.path.exists(path):
        return np.zeros(fs_target, dtype=np.float32)          # 1 segundo silencioso
    rir, fs = sf.read(path)
    if fs != fs_target:
        rir = librosa.resample(rir, orig_sr=fs, target_sr=fs_target)
    return rir.astype(np.float32)

def convolve_audio(x, h):
    if h.size == 0:
        return np.zeros_like(x)
    return fftconvolve(x, h, mode="full")[: len(x)]

def normalize(x):
    m = np.max(np.abs(x))
    return x / m if m > 0 else x

def apply_tdoa(sig1, sig2, delta):
    L = len(sig1)
    b1, b2 = np.zeros(L, dtype=sig1.dtype), np.zeros(L, dtype=sig2.dtype)
    b1[:] = sig1
    if delta >= 0:
        b2[delta:] = sig2[: L - delta]
    else:
        d = -delta
        b1[d:] = sig1[: L - d]
        b2[:] = sig2
    return b1, b2

# -------------------- MAIN --------------------
def main():
    os.makedirs(csv_output_dir, exist_ok=True)

    # ——— Coleção de falas anecóicas (.flac) ———
    flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]
    if not flacs:
        raise FileNotFoundError("Nenhum .flac encontrado em speech_root_dir")

    # ——— Salas disponíveis ———
    salas = sorted(d for d in os.listdir(ir_speech_root)
                   if os.path.isdir(os.path.join(ir_speech_root, d)))
    last = read_checkpoint()
    if last in salas:
        salas = salas[salas.index(last) + 1 :]

    for sala in tqdm(salas, desc="Salas"):
        in_sp = os.path.join(ir_speech_root, sala)
        out_s = os.path.join(output_raw_root, sala)
        os.makedirs(out_s, exist_ok=True)
        csv_path = os.path.join(csv_output_dir, f"{sala}_metrics.csv")

        room_recv = receivers_df[receivers_df.room_key == sala]
        room_src  = sources_df[sources_df.room_key == sala]

        records = []
        for mic1 in sorted(os.listdir(in_sp)):
            if not mic1.endswith("_mic1.wav"):
                continue
            base = mic1[:-len("_mic1.wav")]            # ex.: room_0_FULL_src0_rec0

            # ——— Seleciona fala aleatória ———
            speech_path  = random.choice(flacs)
            speech_audio = load_audio(speech_path)

            # ——— Índices de fonte e receptor ———
            src_i, rec_i = map(int, re.search(r"src(\d+)_rec(\d+)", base).groups())

            rec_row = room_recv[room_recv.receiver_index == rec_i].iloc[0]
            src_row = room_src[room_src.source_index == src_i].iloc[0]
            p1, p2  = np.array(rec_row.mic_pos_1), np.array(rec_row.mic_pos_2)
            p_src   = np.array(src_row.position)

            delta = int(round((np.linalg.norm(p_src - p2) - np.linalg.norm(p_src - p1))
                              / speed_of_sound * fs_target))

            # ——— Convoluções ———
            y1 = convolve_audio(speech_audio, load_rir(os.path.join(in_sp, mic1)))
            y2 = convolve_audio(speech_audio, load_rir(os.path.join(in_sp, f"{base}_mic2.wav")))
            y1, y2 = apply_tdoa(y1, y2, delta)

            mix1 = normalize(y1)
            mix2 = normalize(y2)

            # ---------- SALVA (sem prefixo duplicado) ----------
            f1_name = f"{base}_mic1.wav"
            f2_name = f"{base}_mic2.wav"
            sf.write(os.path.join(out_s, f1_name), mix1, fs_target)
            sf.write(os.path.join(out_s, f2_name), mix2, fs_target)

            # ---------- MÉTRICAS ----------
            records.append({
                "Sala": sala,
                "Nome do Arquivo": f"{base}_mic1",
                "Fonte": src_i,
                "Receptor": rec_i,
                "Audio_fala": speech_path
            })
            records.append({
                "Sala": sala,
                "Nome do Arquivo": f"{base}_mic2",
                "Fonte": src_i,
                "Receptor": rec_i,
                "Audio_fala": speech_path
            })

        pd.DataFrame(records).to_csv(csv_path, index=False)
        write_checkpoint(sala)

    print("Processamento concluído para todas as salas.")

if __name__ == "__main__":
    main()

"""### CORRIGINDO 3 ARQUIVOS CORROMPIDOS"""

import os, re, random
import numpy as np
import pandas as pd
import librosa, soundfile as sf
from scipy.signal import fftconvolve

# --- Caminhos gerais ---
speech_root_dir = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/"
ir_speech_root  = "/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/FILT_SOM_FASE_ZERO"
output_raw_root = "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_SR_sem_trunc_mod"

receivers_path = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/receivers.parquet"
sources_path   = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/sources.parquet"

# --- Parâmetros ---
speed_of_sound = 343.0
fs_target      = 16000
audio_fs       = 16000
audio_duration = 5

# --- Funções utilitárias ---
def pad_or_trim(sig, length):
    return sig[:length] if len(sig) >= length else np.pad(sig, (0, length - len(sig)))

def load_audio(path):
    audio, fs = sf.read(path)
    if fs != audio_fs:
        audio = librosa.resample(audio, orig_sr=fs, target_sr=audio_fs)
    return pad_or_trim(audio, fs_target * audio_duration)

def load_rir(path):
    if not os.path.exists(path):
        return np.zeros(fs_target, dtype=np.float32)
    rir, fs = sf.read(path)
    if fs != fs_target:
        rir = librosa.resample(rir, orig_sr=fs, target_sr=fs_target)
    return rir.astype(np.float32)

def convolve_audio(x, h):
    if h.size == 0:
        return np.zeros_like(x)
    return fftconvolve(x, h, mode="full")[: len(x)]

def normalize(x):
    m = np.max(np.abs(x))
    return x / m if m > 0 else x

def apply_tdoa(sig1, sig2, delta):
    L = len(sig1)
    b1, b2 = np.zeros(L, dtype=sig1.dtype), np.zeros(L, dtype=sig2.dtype)
    b1[:] = sig1
    if delta >= 0:
        b2[delta:] = sig2[: L - delta]
    else:
        d = -delta
        b1[d:] = sig1[: L - d]
        b2[:] = sig2
    return b1, b2

# --- Sobrescrever arquivos específicos ---
def overwrite_convolutions(target_files):
    receivers_df = pd.read_parquet(receivers_path)
    sources_df = pd.read_parquet(sources_path)

    # Lista .flac de fala
    flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]

    for filepath in target_files:
        sala = re.search(r"room_(\d+)", filepath).group(0)
        base = os.path.basename(filepath).replace("_mic1.wav", "").replace("_mic2.wav", "")
        src_i, rec_i = map(int, re.search(r"src(\d+)_rec(\d+)", base).groups())

        # Seleciona fala aleatória
        speech_path  = random.choice(flacs)
        speech_audio = load_audio(speech_path)

        # Caminho da sala
        in_sp = os.path.join(ir_speech_root, sala)
        out_s = os.path.join(output_raw_root, sala)
        os.makedirs(out_s, exist_ok=True)

        # Posições
        room_recv = receivers_df[receivers_df.room_key == sala]
        room_src  = sources_df[sources_df.room_key == sala]
        rec_row = room_recv[room_recv.receiver_index == rec_i].iloc[0]
        src_row = room_src[room_src.source_index == src_i].iloc[0]

        p1 = np.array(rec_row.mic_pos_1)
        p2 = np.array(rec_row.mic_pos_2)
        p_src = np.array(src_row.position)

        delta = int(round((np.linalg.norm(p_src - p2) - np.linalg.norm(p_src - p1))
                          / speed_of_sound * fs_target))

        # Convoluções
        rir1 = load_rir(os.path.join(in_sp, f"{base}_mic1.wav"))
        rir2 = load_rir(os.path.join(in_sp, f"{base}_mic2.wav"))
        y1 = convolve_audio(speech_audio, rir1)
        y2 = convolve_audio(speech_audio, rir2)
        y1, y2 = apply_tdoa(y1, y2, delta)
        mix1 = normalize(y1)
        mix2 = normalize(y2)

        # Sobrescreve arquivos
        sf.write(os.path.join(out_s, f"{base}_mic1.wav"), mix1, fs_target)
        sf.write(os.path.join(out_s, f"{base}_mic2.wav"), mix2, fs_target)

        print(f"Reprocessado: {sala} | {base} | src {src_i} → rec {rec_i}")

# ---------- Arquivos a serem sobrescritos ----------
targets = [
    "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_SR_sem_trunc_mod/room_470/room_470_FULL_src3_rec4_mic1.wav",
    "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_SR_sem_trunc_mod/room_471/room_471_FULL_src3_rec1_mic1.wav",
    "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_SR_sem_trunc_mod/room_471/room_471_FULL_src4_rec4_mic2.wav"
]

overwrite_convolutions(targets)

"""## 1R"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
convolution_with_noise0_tdoa_no_spec.py
────────────────────────────────────────────────────────────────────────
• Escolhe um áudio de fala aleatório por registro, processa cada microfone
  individualmente e salva WAVs mono.
• Remove o prefixo duplicado “<sala>_” nos nomes dos WAVs gerados e
  na coluna “Nome do Arquivo” do CSV.
• **Novo**: NÃO há mais truncagem das RIRs — elas são usadas completas.

Colunas do CSV:
Sala, Nome do Arquivo, Fonte, Receptor, Audio_fala,
SNR_target_dB, SNR_real, Início_ruído_0, Fim_ruído_0
"""

import os
import re
import random
import numpy as np
import pandas as pd
import librosa
import soundfile as sf
from scipy.signal import fftconvolve
from tqdm.auto import tqdm

# ------------------ PATHS ------------------
speech_root_dir  = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/"
rir_speech_root  = "/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/FILT_SOM_FASE_ZERO"
rir_noise_root   = "/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/FILT_SOM_FASE_ZERO_RUIDO"
output_raw_root  = "/content/drive/MyDrive/PREPROCESSING/convolucoes/MONO_1R_sem_trunc"
csv_output_dir   = "/content/drive/MyDrive/PREPROCESSING/convolucoes/METRICS_1R_sem_trunc"
checkpoint_file  = "/content/drive/MyDrive/PREPROCESSING/convolucoes/checkpoint_1R_sem_trunc.txt"

noises_path      = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/noises.parquet"
receivers_path   = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/receivers.parquet"
sources_path     = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/sources.parquet"

# ------------------ CARREGA CONFIGURAÇÕES ------------------
noises_df    = pd.read_parquet(noises_path)
receivers_df = pd.read_parquet(receivers_path)
sources_df   = pd.read_parquet(sources_path)

# ------------------ PARÂMETROS ------------------
speed_of_sound  = 343.0     # m/s
fs_target       = 16000     # Hz (final)
audio_fs        = 16000     # Hz fala
noise_fs        = 44100     # Hz ruídos
audio_duration  = 5         # segundos

# ------------------ RUÍDO ÍNDICE 0 ------------------
noise_file_0 = (
    "/content/drive/MyDrive/Dissertação - Mestrado - Ruídos/"
    "Ruidos_dissertacao-20250427T211807Z-001/"
    "Ruidos_dissertacao/Ruidos/"
    "dcase2016_task2_train_dev/dcase2016_task2_train/airconditioning.wav"
)

# ----------------- HELPERS -----------------
def read_checkpoint():
    return open(checkpoint_file).read().strip() if os.path.exists(checkpoint_file) else None

def write_checkpoint(room):
    with open(checkpoint_file, "w") as f:
        f.write(room)

def pad_or_trim(sig, length):
    return sig[:length] if len(sig) >= length else np.pad(sig, (0, length - len(sig)))

def load_audio(path, source):
    audio, fs = sf.read(path)
    target_sr = audio_fs if source == "speech" else noise_fs
    if fs != target_sr:
        audio = librosa.resample(audio, orig_sr=fs, target_sr=target_sr)

    # adequa ao fs_target
    if target_sr != fs_target:
        audio = librosa.resample(audio, orig_sr=target_sr, target_sr=fs_target)

    desired_len = fs_target * audio_duration

    if source == "noise":
        if len(audio) == 0:
            return np.zeros(desired_len, dtype=np.float32)
        reps = int(np.ceil(desired_len / len(audio)))
        audio = np.tile(audio, reps)[:desired_len]
    else:
        audio = pad_or_trim(audio, desired_len)

    return audio.astype(np.float32)

def load_rir(path):
    """Carrega a RIR integral (sem truncagem)."""
    if not os.path.exists(path):
        return np.zeros(fs_target, dtype=np.float32)  # fallback: 1 s de zeros
    rir, fs = sf.read(path)
    if fs != fs_target:
        rir = librosa.resample(rir, orig_sr=fs, target_sr=fs_target)
    return rir.astype(np.float32)

def convolve_audio(x, h):
    y = fftconvolve(x, h, mode="full")
    return y[: len(x)]

def normalize(x):
    peak = np.max(np.abs(x))
    return x / peak if peak > 0 else x

def apply_tdoa(sig1, sig2, delta):
    L = len(sig1)
    b1, b2 = np.zeros(L, dtype=sig1.dtype), np.zeros(L, dtype=sig2.dtype)
    b1[:] = sig1
    if delta >= 0:
        if delta < L:
            b2[delta:] = sig2[: L - delta]
    else:
        d = -delta
        if d < L:
            b1[d:] = sig1[: L - d]
        b2[:] = sig2
    return b1, b2

# -------------------- EXECUÇÃO --------------------
def main():
    flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]
    if not flacs:
        raise FileNotFoundError("Nenhum arquivo .flac encontrado em speech_root_dir")

    salas = sorted(d for d in os.listdir(rir_speech_root)
                   if os.path.isdir(os.path.join(rir_speech_root, d)))
    last = read_checkpoint()
    if last in salas:
        salas = salas[salas.index(last) + 1:]

    for sala in tqdm(salas, desc="Salas"):
        in_sp = os.path.join(rir_speech_root, sala)
        in_no = os.path.join(rir_noise_root, sala)
        out_s = os.path.join(output_raw_root, sala)
        os.makedirs(out_s, exist_ok=True)

        csv_path = os.path.join(csv_output_dir, f"{sala}_metrics.csv")
        os.makedirs(os.path.dirname(csv_path), exist_ok=True)

        room_noises = noises_df[noises_df.room_key == sala]
        room_recs   = receivers_df[receivers_df.room_key == sala]
        room_srcs   = sources_df[sources_df.room_key == sala]

        records = []

        for mic1 in sorted(os.listdir(in_sp)):
            if not mic1.endswith("_mic1.wav"):
                continue
            base = mic1[:-len("_mic1.wav")]  # ex.: room_0_FULL_src0_rec0

            speech_path = random.choice(flacs)
            speech_audio = load_audio(speech_path, "speech")

            src_i, rec_i = map(int, re.search(r"src(\d+)_rec(\d+)", base).groups())

            rec_row = room_recs[room_recs.receiver_index == rec_i].iloc[0]
            p1, p2 = np.array(rec_row.mic_pos_1), np.array(rec_row.mic_pos_2)
            src_row = room_srcs[room_srcs.source_index == src_i].iloc[0]
            delta_s = int(round(
                (np.linalg.norm(src_row.position - p2) -
                 np.linalg.norm(src_row.position - p1)) / speed_of_sound * fs_target))

            # Convolução da fala
            y1 = convolve_audio(speech_audio, load_rir(os.path.join(in_sp, mic1)))
            y2 = convolve_audio(speech_audio, load_rir(os.path.join(in_sp, f"{base}_mic2.wav")))
            y1, y2 = apply_tdoa(y1, y2, delta_s)

            # Ruído índice 0
            noise_audio = load_audio(noise_file_0, "noise")
            p_noise = np.array(room_noises[room_noises.noise_index == 0].position.iloc[0])
            delta_n = int(round(
                (np.linalg.norm(p_noise - p2) -
                 np.linalg.norm(p_noise - p1)) / speed_of_sound * fs_target))

            n1 = convolve_audio(noise_audio, load_rir(os.path.join(in_no, base.replace(f"src{src_i}", "src0") + "_mic1.wav")))
            n2 = convolve_audio(noise_audio, load_rir(os.path.join(in_no, base.replace(f"src{src_i}", "src0") + "_mic2.wav")))
            n1, n2 = apply_tdoa(n1, n2, delta_n)

            # Ajuste de ganho para SNR alvo
            snr_target = random.uniform(0, 20)
            p1_pow, p2_pow = np.sum(y1**2), np.sum(y2**2)
            g1 = np.sqrt(p1_pow / (10**(snr_target / 10) * (np.sum(n1**2) + 1e-10)))
            g2 = np.sqrt(p2_pow / (10**(snr_target / 10) * (np.sum(n2**2) + 1e-10)))
            n1 *= g1
            n2 *= g2

            real1 = 10 * np.log10(p1_pow / (np.sum(n1**2) + 1e-10))
            real2 = 10 * np.log10(p2_pow / (np.sum(n2**2) + 1e-10))

            # Mix e normalização
            mix1 = normalize(y1 + n1)
            mix2 = normalize(y2 + n2)

            # Salva WAVs mono
            f1_name = f"{base}_mic1.wav"
            f2_name = f"{base}_mic2.wav"
            sf.write(os.path.join(out_s, f1_name), mix1, fs_target)
            sf.write(os.path.join(out_s, f2_name), mix2, fs_target)

            # Métricas
            records.append({
                "Sala": sala,
                "Nome do Arquivo": f"{base}_mic1",
                "Fonte": src_i,
                "Receptor": rec_i,
                "Audio_fala": speech_path,
                "SNR_target_dB": round(snr_target, 2),
                "SNR_real": round(real1, 2),
                "Início_ruído_0": 0.0,
                "Fim_ruído_0": float(audio_duration)
            })
            records.append({
                "Sala": sala,
                "Nome do Arquivo": f"{base}_mic2",
                "Fonte": src_i,
                "Receptor": rec_i,
                "Audio_fala": speech_path,
                "SNR_target_dB": round(snr_target, 2),
                "SNR_real": round(real2, 2),
                "Início_ruído_0": 0.0,
                "Fim_ruído_0": float(audio_duration)
            })

        # Salva CSV
        df = pd.DataFrame(records, columns=[
            "Sala", "Nome do Arquivo", "Fonte", "Receptor",
            "Audio_fala", "SNR_target_dB", "SNR_real",
            "Início_ruído_0", "Fim_ruído_0"
        ])
        df.to_csv(csv_path, index=False)

        write_checkpoint(sala)

    print("Processamento concluído para todas as salas.")

if __name__ == "__main__":
    main()

"""## 5R"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
convolution_with_all_noises_random_intervals_tdoa.py
──────────────────────────────────────────────────────────────────────────────
• Processa cada microfone individualmente e salva WAVs mono
• Gera CSV com todas as métricas e intervalos de ruído (6 casas decimais)
• Imprime TDOA bruto vs. arredondado (amostras e segundos)
• **Novo**: as RIRs são usadas COMPLETAS (sem truncagem).
• Remove o prefixo duplicado “<sala>_” nos nomes dos WAVs
  e na coluna “Nome do Arquivo”.

Colunas finais no CSV:
Sala,Nome do Arquivo,Fonte,Receptor,Audio_fala,
SNR_target_dB,SNR_real,
Início_ruído_0,Fim_ruído_0,…,Início_ruído_4,Fim_ruído_4
"""

import os, re, random
import numpy as np
import pandas as pd
import librosa, soundfile as sf, matplotlib.pyplot as plt
from scipy.signal import fftconvolve
from tqdm.auto import tqdm
from IPython.display import display, Audio

# ------------------ PATHS ------------------
speech_root_dir  = "/content/drive/MyDrive/Dissertação - Mestrado/LibriSpeech/train-clean-100/"
rir_speech_root  = "/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/FILT_SOM_FASE_ZERO"
rir_noise_root   = "/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/FILT_SOM_FASE_ZERO_RUIDO"
output_raw_root  = "/content/drive/MyDrive/PREPROCESSING/convolucoes/MONO_5R_sem_trunc_mod"
csv_output_dir   = "/content/drive/MyDrive/PREPROCESSING/convolucoes/METRICS_5R_sem_trunc_mod"
checkpoint_file  = "/content/drive/MyDrive/PREPROCESSING/convolucoes/checkpoint_5R_sem_trunc_mod.txt"

noises_path      = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/noises.parquet"
receivers_path   = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/receivers.parquet"
sources_path     = "/content/drive/MyDrive/Dissertação - Mestrado/config_salas/sources.parquet"

# ------------------ LOAD CONFIG ------------------
noises_df    = pd.read_parquet(noises_path)
receivers_df = pd.read_parquet(receivers_path)
sources_df   = pd.read_parquet(sources_path)

# ------------------ PARAMETERS ------------------
speed_of_sound = 343.0   # m/s
fs_target      = 16000   # Hz
audio_fs       = 16000   # Hz speech
noise_fs       = 44100   # Hz noise
audio_duration = 5       # seconds

# ------------------ NOISE FILES & GAINS ------------------
noise_gain  = {0: 2.0, 1: 3.0, 2: 2.0, 3: 2.0, 4: 2.0}
noise_files = {
    idx: (
        "/content/drive/MyDrive/Dissertação - Mestrado - Ruídos/"
        "Ruidos_dissertacao-20250427T211807Z-001/Ruidos_dissertacao/Ruidos/"
        "dcase2016_task2_train_dev/dcase2016_task2_train/" + fname + ".wav"
    )
    for idx, fname in enumerate(
        ["airconditioning", "cough134", "laughter119", "phone052", "keyboard064"]
    )
}

# ----------------- HELPERS -----------------
def read_checkpoint():
    return open(checkpoint_file).read().strip() if os.path.exists(checkpoint_file) else None

def write_checkpoint(room):
    with open(checkpoint_file, "w") as f:
        f.write(room)

def pad_or_trim(sig, length):
    return sig[:length] if len(sig) >= length else np.pad(sig, (0, length - len(sig)))

def load_audio(path, source):
    """Carrega fala (speech) ou ruído (noise) e ajusta para fs_target & duração."""
    audio, fs = sf.read(path)
    target_sr = audio_fs if source == "speech" else noise_fs
    if fs != target_sr:
        audio = librosa.resample(audio, orig_sr=fs, target_sr=target_sr)

    if target_sr != fs_target:
        audio = librosa.resample(audio, orig_sr=target_sr, target_sr=fs_target)

    desired_len = fs_target * audio_duration
    if source == "noise":
        if len(audio) == 0:
            return np.zeros(desired_len, dtype=np.float32)
        reps = int(np.ceil(desired_len / len(audio)))
        audio = np.tile(audio, reps)[:desired_len]
    else:
        audio = pad_or_trim(audio, desired_len)
    return audio.astype(np.float32)

def load_rir(path):
    """Carrega a RIR completa; se não existir, devolve 1 s de zeros."""
    if not os.path.exists(path):
        return np.zeros(fs_target, dtype=np.float32)
    rir, fs = sf.read(path)
    if fs != fs_target:
        rir = librosa.resample(rir, orig_sr=fs, target_sr=fs_target)
    return rir.astype(np.float32)

def convolve_audio(x, h):
    return fftconvolve(x, h, mode="full")[: len(x)]

def normalize(x):
    peak = np.max(np.abs(x))
    return x / peak if peak > 0 else x

def apply_tdoa(sig1, sig2, delta):
    L = len(sig1)
    b1, b2 = np.zeros(L, dtype=sig1.dtype), np.zeros(L, dtype=sig2.dtype)
    b1[:] = sig1
    if delta >= 0:
        b2[delta:] = sig2[: L - delta]
    else:
        d = -delta
        b1[d:] = sig1[: L - d]
        b2[:] = sig2
    return b1, b2

# -------------------- MAIN --------------------
def main():
    os.makedirs(csv_output_dir, exist_ok=True)

    flacs = [os.path.join(dp, f)
             for dp, _, files in os.walk(speech_root_dir)
             for f in files if f.endswith(".flac")]
    if not flacs:
        raise FileNotFoundError("Nenhum .flac encontrado em speech_root_dir")

    salas = sorted(
        d for d in os.listdir(rir_speech_root)
        if os.path.isdir(os.path.join(rir_speech_root, d))
    )
    last = read_checkpoint()
    if last in salas:
        salas = salas[salas.index(last) + 1:]

    primeira = True
    for sala in tqdm(salas, desc="Salas"):
        in_sp = os.path.join(rir_speech_root, sala)
        in_no = os.path.join(rir_noise_root, sala)
        out_s = os.path.join(output_raw_root, sala)
        os.makedirs(out_s, exist_ok=True)
        csv_path = os.path.join(csv_output_dir, f"{sala}_metrics.csv")

        room_noises    = noises_df[noises_df.room_key == sala]
        room_receivers = receivers_df[receivers_df.room_key == sala]
        room_sources   = sources_df[sources_df.room_key == sala]

        records = []
        for mic1 in sorted(os.listdir(in_sp)):
            if not mic1.endswith("_mic1.wav"):
                continue
            base = mic1[:-len("_mic1.wav")]  # room_0_FULL_srcX_recY

            speech_path = random.choice(flacs)
            speech = load_audio(speech_path, "speech")

            src_i, rec_i = map(int, re.search(r"src(\d+)_rec(\d+)", base).groups())

            rec_row = room_receivers[room_receivers.receiver_index == rec_i].iloc[0]
            src_row = room_sources[room_sources.source_index == src_i].iloc[0]
            p1, p2  = np.array(rec_row.mic_pos_1), np.array(rec_row.mic_pos_2)

            raw_delta_sp = (np.linalg.norm(src_row.position - p2)
                           - np.linalg.norm(src_row.position - p1)) / speed_of_sound * fs_target
            delta_sp = int(round(raw_delta_sp))
            print(f"[TDOA fala] raw={raw_delta_sp:.4f} ▶ int={delta_sp} ▶ {raw_delta_sp/fs_target:.7f} s")

            y1 = convolve_audio(speech, load_rir(os.path.join(in_sp, mic1)))
            y2 = convolve_audio(speech, load_rir(os.path.join(in_sp, f"{base}_mic2.wav")))
            y1, y2 = apply_tdoa(y1, y2, delta_sp)

            total1 = np.zeros_like(y1)
            total2 = np.zeros_like(y2)
            noise_intervals = {}

            for nidx, nfile in noise_files.items():
                npos = np.array(room_noises[room_noises.noise_index == nidx].position.iloc[0])
                raw_delta_no = (np.linalg.norm(npos - p2) - np.linalg.norm(npos - p1)) \
                               / speed_of_sound * fs_target
                delta_no = int(round(raw_delta_no))
                print(f"[TDOA ruído {nidx}] raw={raw_delta_no:.4f} ▶ int={delta_no} ▶ {raw_delta_no/fs_target:.7f} s")

                if nidx > 0:
                    i_sec = random.uniform(0, audio_duration / 2)
                    e_sec = random.uniform(i_sec + 0.1, audio_duration)
                else:
                    i_sec, e_sec = 0.0, audio_duration
                noise_intervals[nidx] = (i_sec, e_sec)

                Lsig = len(y1)
                s1, e1s = int(i_sec * fs_target), int(e_sec * fs_target)
                s2, e2s = np.clip(s1 + delta_no, 0, Lsig), np.clip(e1s + delta_no, 0, Lsig)
                m1, m2 = np.zeros(Lsig), np.zeros(Lsig)
                m1[s1:e1s], m2[s2:e2s] = 1, 1

                noise = load_audio(nfile, "noise")
                n1 = convolve_audio(noise, load_rir(os.path.join(
                    in_no, base.replace(f"src{src_i}", f"src{nidx}") + "_mic1.wav")))
                n2 = convolve_audio(noise, load_rir(os.path.join(
                    in_no, base.replace(f"src{src_i}", f"src{nidx}") + "_mic2.wav")))
                n1, n2 = apply_tdoa(n1, n2, delta_no)

                total1 += normalize(n1) * noise_gain[nidx] * m1
                total2 += normalize(n2) * noise_gain[nidx] * m2

            snr_target = random.uniform(0, 20)
            p1_pow, p2_pow = np.sum(y1**2), np.sum(y2**2)
            lin = 10 ** (snr_target / 10)
            g1 = np.sqrt((p1_pow / lin) / (np.sum(total1**2) + 1e-10))
            g2 = np.sqrt((p2_pow / lin) / (np.sum(total2**2) + 1e-10))
            total1 *= g1
            total2 *= g2
            real1 = 10 * np.log10(p1_pow / (np.sum(total1**2) + 1e-10))
            real2 = 10 * np.log10(p2_pow / (np.sum(total2**2) + 1e-10))

            mix1 = normalize(y1 + total1)
            mix2 = normalize(y2 + total2)

            f1_name = f"{base}_mic1.wav"
            f2_name = f"{base}_mic2.wav"
            sf.write(os.path.join(out_s, f1_name), mix1, fs_target)
            sf.write(os.path.join(out_s, f2_name), mix2, fs_target)

            for mic_label, real in [("mic1", real1), ("mic2", real2)]:
                rec = {
                    "Sala": sala,
                    "Nome do Arquivo": f"{base}_{mic_label}",
                    "Fonte": src_i,
                    "Receptor": rec_i,
                    "Audio_fala": speech_path,
                    "SNR_target_dB": round(snr_target, 2),
                    "SNR_real": round(real, 2),
                }
                for idx, (i_sec, e_sec) in noise_intervals.items():
                    rec[f"Início_ruído_{idx}"] = round(i_sec, 6)
                    rec[f"Fim_ruído_{idx}"]    = round(e_sec, 6)
                records.append(rec)

        pd.DataFrame(records).to_csv(csv_path, index=False)
        write_checkpoint(sala)

        if primeira:
            print(f"\n=== Primeira sala: {sala} ({len(records)//2} registros) ===")
            for fn in sorted(os.listdir(out_s)):
                if fn.endswith(".wav"):
                    y, sr = sf.read(os.path.join(out_s, fn))
                    t = np.arange(len(y)) / sr
                    plt.figure(figsize=(8, 2))
                    plt.plot(t, y, linewidth=0.5)
                    plt.title(fn)
                    plt.tight_layout()
                    plt.show()
                    display(Audio(y, rate=sr))
            primeira = False

    print("\nProcessamento concluído para todas as salas.")

if __name__ == "__main__":
    main()

"""# ANÁLISE ESPECTRAL DOS ÁUDIOS SELECIONADOS EM GERAÇÃO_DE_INFOS_ESPECTRAIS.ipynb

# GERANDO OS ESPECTROGRAMAS
"""

from google.colab import drive
drive.mount('/content/drive')

pip install Pywavelets

"""## LOGMEL/STFT/QCT

### SEM RUÍDO
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
batch_spectrograms_rooms.py
────────────────────────────────────────────────────────────
✓ Gera log-Mel, STFT e CQT em PNG 224×224
✓ Salva em subpastas homônimas *com prefixo room_XX_ no nome do arquivo*
✓ Checkpoint por sala (room_X) para retomar sem repetir trabalho
✓ Exibe espectrogramas da primeira sala processada
"""

import os, re, glob
import numpy as np
import soundfile as sf
import matplotlib.pyplot as plt
import librosa, librosa.display
from scipy.signal import get_window
from scipy.fft import rfft
from scipy.ndimage import zoom
from tqdm.auto import tqdm

# ╭────────────────── Funções utilitárias ──────────────────╮
def dual_pre_emphasis(x, a_h: float = 0.97, a_l: float = 0.5) -> np.ndarray:
    """Pré-ênfase em alta (a_h) seguida de correção em baixa (a_l)."""
    y = np.empty_like(x)
    y[0] = x[0]
    y[1:] = x[1:] - a_h * x[:-1]
    z = np.empty_like(y)
    z[0] = y[0]
    z[1:] = y[1:] + a_l * y[:-1]
    return z

def resize224(S: np.ndarray) -> np.ndarray:
    """Redimensiona um mapa espectral para 224 × 224 com interpolação bicúbica."""
    return zoom(S, (224 / S.shape[0], 224 / S.shape[1]), order=3)[:, :224]

def compute_logmel(
    y: np.ndarray,
    sr: int,
    frame_ms: int = 25,
    tgt: int = 224,
    n_fft: int = 2048,
    n_mels: int = 224,
    fmin: int = 0,
    fmax: int | None = None,
    eps: float = 1e-6,
) -> np.ndarray:
    """Calcula espectrograma log-Mel com exatamente `tgt` quadros."""
    if fmax is None:
        fmax = sr / 2
    y = dual_pre_emphasis(y)

    L = int(sr * frame_ms / 1000)
    hop = max(1, int(np.floor((len(y) - L) / (tgt - 1))))
    pad = (tgt - 1) * hop + L
    y = np.pad(y, (0, max(0, pad - len(y))))

    frames = np.lib.stride_tricks.sliding_window_view(y, L)[::hop][:tgt]
    S = np.abs(rfft(frames * get_window("hann", L)[None, :], n=n_fft, axis=1))

    mel_fb = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels, fmin=fmin, fmax=fmax)
    return resize224(np.log10(mel_fb @ S.T + eps))

def save_png(M: np.ndarray, path: str, cmap: str = "viridis") -> None:
    """Salva `M` como PNG 224 × 224 sem bordas."""
    plt.figure(figsize=(2.24, 2.24), dpi=100)
    plt.imshow(M, origin="lower", aspect="auto", cmap=cmap)
    plt.axis("off")
    plt.margins(0, 0)
    plt.subplots_adjust(0, 0, 1, 1, 0, 0)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    plt.savefig(path, bbox_inches="tight", pad_inches=0)
    plt.close()
# ╰──────────────────────────────────────────────────────────╯


# ───────────── Configurações ─────────────
IN_ROOT  = "/content/drive/MyDrive/PREPROCESSING_1s/CONV/MONO_SR_sem_trunc_mod"
OUT_ROOT = "/content/drive/MyDrive/PREPROCESSING_1s/CONV/MONO_SR_sem_trunc_mod_ESPEC"
DIRS = {
    t: f"{OUT_ROOT}/{t if t != 'log-Mel' else 'log_mel'}"
    for t in ["log-Mel", "STFT", "CQT"]
}

CHECK_FILE = f"{OUT_ROOT}/checkpoint_rooms.txt"
rooms_done: set[str] = set()
if os.path.exists(CHECK_FILE):
    rooms_done = {ln.strip() for ln in open(CHECK_FILE) if ln.strip()}

# Agrupa WAVs por sala
room_dict: dict[str, list[str]] = {}
for wav in glob.glob(os.path.join(IN_ROOT, "**/*.wav"), recursive=True):
    m = re.search(r"/(room_\d+)/", wav)
    if m:
        room = m.group(1)
        room_dict.setdefault(room, []).append(wav)

primeira_sala = None
figs: list[tuple[str, np.ndarray]] = []

# ───────────── Loop por sala ─────────────
for room, wavs in sorted(room_dict.items(), key=lambda x: int(x[0].split("_")[1])):
    if room in rooms_done:
        continue  # sala já processada

    print(f"\n▶ Processando {room} ({len(wavs)} arquivos)")
    for wav_path in tqdm(wavs, desc=room, leave=False):
        # nome base (sem extensão) do WAV
        base_name = os.path.splitext(os.path.basename(wav_path))[0]

        # garante que base_name não tenha prefixo repetido
        base_name = re.sub(rf"^{room}_", "", base_name)

        # → agora cria o nome *com* prefixo room_XX_
        prefixed_name = f"{room}_{base_name}"

        # caminhos de saída
        outs = {t: f"{DIRS[t]}/{room}/{prefixed_name}.png" for t in DIRS}

        # se já existem os 3 espectrogramas, pula
        if all(os.path.exists(p) for p in outs.values()):
            continue

        audio, sr = sf.read(wav_path)
        y = audio.mean(axis=1) if audio.ndim > 1 else audio

        # log-Mel
        logmel = compute_logmel(y, sr)
        save_png(logmel, outs["log-Mel"], "viridis")

        # STFT
        hop = int(sr * 25 / 1000)  # 25 ms
        stft = resize224(
            librosa.amplitude_to_db(np.abs(librosa.stft(y, n_fft=2048, hop_length=hop)), ref=np.max)
        )
        save_png(stft, outs["STFT"], "magma")

        # CQT
        cqt = resize224(
            librosa.amplitude_to_db(
                np.abs(librosa.cqt(y, sr=sr, hop_length=hop, n_bins=84, bins_per_octave=12)),
                ref=np.max,
            )
        )
        save_png(cqt, outs["CQT"], "inferno")

        # coleta figuras da primeira sala
        if primeira_sala is None:
            primeira_sala = room
        if room == primeira_sala:
            figs.extend(
                [
                    (f"{prefixed_name} (log-Mel)", logmel),
                    (f"{prefixed_name} (STFT)", stft),
                    (f"{prefixed_name} (CQT)", cqt),
                ]
            )

    # marca sala como concluída
    with open(CHECK_FILE, "a") as ck:
        ck.write(room + "\n")
    rooms_done.add(room)
    print(f"✔ {room} concluída e registrada em checkpoint.")

# ───────────── Visualização da primeira sala ─────────────
if figs:
    cols = 3
    rows = int(np.ceil(len(figs) / cols))
    fig, ax = plt.subplots(rows, cols, figsize=(cols * 2.5, rows * 2.5))
    ax = ax.flatten()
    for a, (title, M) in zip(ax, figs):
        a.imshow(M, origin="lower", aspect="auto")
        a.set_title(title, fontsize=7)
        a.axis("off")
    for a in ax[len(figs):]:
        a.axis("off")
    plt.tight_layout()
    plt.show()

print("\nProcessamento global concluído!")

"""### COM 1 RUÍDO"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
batch_spectrograms_rooms.py
────────────────────────────────────────────────────────────
✓ Gera log-Mel, STFT e CQT em PNG 224×224
✓ Salva em subpastas homônimas *com prefixo room_XX_ no nome do arquivo*
✓ Checkpoint por sala (room_X) para retomar sem repetir trabalho
✓ Exibe espectrogramas da primeira sala processada
"""

import os, re, glob
import numpy as np
import soundfile as sf
import matplotlib.pyplot as plt
import librosa, librosa.display
from scipy.signal import get_window
from scipy.fft import rfft
from scipy.ndimage import zoom
from tqdm.auto import tqdm

# ╭────────────────── Funções utilitárias ──────────────────╮
def dual_pre_emphasis(x, a_h: float = 0.97, a_l: float = 0.5) -> np.ndarray:
    """Pré-ênfase em alta (a_h) seguida de correção em baixa (a_l)."""
    y = np.empty_like(x)
    y[0] = x[0]
    y[1:] = x[1:] - a_h * x[:-1]
    z = np.empty_like(y)
    z[0] = y[0]
    z[1:] = y[1:] + a_l * y[:-1]
    return z

def resize224(S: np.ndarray) -> np.ndarray:
    """Redimensiona um mapa espectral para 224 × 224 com interpolação bicúbica."""
    return zoom(S, (224 / S.shape[0], 224 / S.shape[1]), order=3)[:, :224]

def compute_logmel(
    y: np.ndarray,
    sr: int,
    frame_ms: int = 25,
    tgt: int = 224,
    n_fft: int = 2048,
    n_mels: int = 224,
    fmin: int = 0,
    fmax: int | None = None,
    eps: float = 1e-6,
) -> np.ndarray:
    """Calcula espectrograma log-Mel com exatamente `tgt` quadros."""
    if fmax is None:
        fmax = sr / 2
    y = dual_pre_emphasis(y)

    L = int(sr * frame_ms / 1000)
    hop = max(1, int(np.floor((len(y) - L) / (tgt - 1))))
    pad = (tgt - 1) * hop + L
    y = np.pad(y, (0, max(0, pad - len(y))))

    frames = np.lib.stride_tricks.sliding_window_view(y, L)[::hop][:tgt]
    S = np.abs(rfft(frames * get_window("hann", L)[None, :], n=n_fft, axis=1))

    mel_fb = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels, fmin=fmin, fmax=fmax)
    return resize224(np.log10(mel_fb @ S.T + eps))

def save_png(M: np.ndarray, path: str, cmap: str = "viridis") -> None:
    """Salva `M` como PNG 224 × 224 sem bordas."""
    plt.figure(figsize=(2.24, 2.24), dpi=100)
    plt.imshow(M, origin="lower", aspect="auto", cmap=cmap)
    plt.axis("off")
    plt.margins(0, 0)
    plt.subplots_adjust(0, 0, 1, 1, 0, 0)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    plt.savefig(path, bbox_inches="tight", pad_inches=0)
    plt.close()
# ╰──────────────────────────────────────────────────────────╯


# ───────────── Configurações ─────────────
IN_ROOT  = "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_1R_sem_trunc"
OUT_ROOT = "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_1R_sem_trunc_ESPEC"
DIRS = {
    t: f"{OUT_ROOT}/{t if t != 'log-Mel' else 'log_mel'}"
    for t in ["log-Mel", "STFT", "CQT"]
}

CHECK_FILE = f"{OUT_ROOT}/checkpoint_rooms.txt"
rooms_done: set[str] = set()
if os.path.exists(CHECK_FILE):
    rooms_done = {ln.strip() for ln in open(CHECK_FILE) if ln.strip()}

# Agrupa WAVs por sala
room_dict: dict[str, list[str]] = {}
for wav in glob.glob(os.path.join(IN_ROOT, "**/*.wav"), recursive=True):
    m = re.search(r"/(room_\d+)/", wav)
    if m:
        room = m.group(1)
        room_dict.setdefault(room, []).append(wav)

primeira_sala = None
figs: list[tuple[str, np.ndarray]] = []

# ───────────── Loop por sala ─────────────
for room, wavs in sorted(room_dict.items(), key=lambda x: int(x[0].split("_")[1])):
    if room in rooms_done:
        continue  # sala já processada

    print(f"\n▶ Processando {room} ({len(wavs)} arquivos)")
    for wav_path in tqdm(wavs, desc=room, leave=False):
        # nome base (sem extensão) do WAV
        base_name = os.path.splitext(os.path.basename(wav_path))[0]

        # garante que base_name não tenha prefixo repetido
        base_name = re.sub(rf"^{room}_", "", base_name)

        # → agora cria o nome *com* prefixo room_XX_
        prefixed_name = f"{room}_{base_name}"

        # caminhos de saída
        outs = {t: f"{DIRS[t]}/{room}/{prefixed_name}.png" for t in DIRS}

        # se já existem os 3 espectrogramas, pula
        if all(os.path.exists(p) for p in outs.values()):
            continue

        audio, sr = sf.read(wav_path)
        y = audio.mean(axis=1) if audio.ndim > 1 else audio

        # log-Mel
        logmel = compute_logmel(y, sr)
        save_png(logmel, outs["log-Mel"], "viridis")

        # STFT
        hop = int(sr * 25 / 1000)  # 25 ms
        stft = resize224(
            librosa.amplitude_to_db(np.abs(librosa.stft(y, n_fft=2048, hop_length=hop)), ref=np.max)
        )
        save_png(stft, outs["STFT"], "magma")

        # CQT
        cqt = resize224(
            librosa.amplitude_to_db(
                np.abs(librosa.cqt(y, sr=sr, hop_length=hop, n_bins=84, bins_per_octave=12)),
                ref=np.max,
            )
        )
        save_png(cqt, outs["CQT"], "inferno")

        # coleta figuras da primeira sala
        if primeira_sala is None:
            primeira_sala = room
        if room == primeira_sala:
            figs.extend(
                [
                    (f"{prefixed_name} (log-Mel)", logmel),
                    (f"{prefixed_name} (STFT)", stft),
                    (f"{prefixed_name} (CQT)", cqt),
                ]
            )

    # marca sala como concluída
    with open(CHECK_FILE, "a") as ck:
        ck.write(room + "\n")
    rooms_done.add(room)
    print(f"✔ {room} concluída e registrada em checkpoint.")

# ───────────── Visualização da primeira sala ─────────────
if figs:
    cols = 3
    rows = int(np.ceil(len(figs) / cols))
    fig, ax = plt.subplots(rows, cols, figsize=(cols * 2.5, rows * 2.5))
    ax = ax.flatten()
    for a, (title, M) in zip(ax, figs):
        a.imshow(M, origin="lower", aspect="auto")
        a.set_title(title, fontsize=7)
        a.axis("off")
    for a in ax[len(figs):]:
        a.axis("off")
    plt.tight_layout()
    plt.show()

print("\nProcessamento global concluído!")

"""### COM 5 RUÍDOS"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
batch_spectrograms_rooms.py
────────────────────────────────────────────────────────────
✓ Gera log-Mel, STFT e CQT em PNG 224×224
✓ Salva em subpastas homônimas *com prefixo room_XX_ no nome do arquivo*
✓ Checkpoint por sala (room_X) para retomar sem repetir trabalho
✓ Exibe espectrogramas da primeira sala processada
✗ Pula arquivos corrompidos e salva nomes em CSV
"""

import os
import re
import glob
import csv          # para salvar CSV de corrompidos
import numpy as np
import soundfile as sf
import matplotlib.pyplot as plt
import librosa
import librosa.display
from scipy.signal import get_window
from scipy.fft import rfft
from scipy.ndimage import zoom
from tqdm.auto import tqdm

# ╭────────────────── Funções utilitárias ──────────────────╮
def dual_pre_emphasis(x, a_h: float = 0.97, a_l: float = 0.5) -> np.ndarray:
    """Pré-ênfase em alta (a_h) seguida de correção em baixa (a_l)."""
    y = np.empty_like(x)
    y[0] = x[0]
    y[1:] = x[1:] - a_h * x[:-1]
    z = np.empty_like(y)
    z[0] = y[0]
    z[1:] = y[1:] + a_l * y[:-1]
    return z

def resize224(S: np.ndarray) -> np.ndarray:
    """Redimensiona um mapa espectral para 224 × 224 com interpolação bicúbica."""
    return zoom(S, (224 / S.shape[0], 224 / S.shape[1]), order=3)[:, :224]

def compute_logmel(
    y: np.ndarray,
    sr: int,
    frame_ms: int = 25,
    tgt: int = 224,
    n_fft: int = 2048,
    n_mels: int = 224,
    fmin: int = 0,
    fmax: int | None = None,
    eps: float = 1e-6,
) -> np.ndarray:
    """Calcula espectrograma log-Mel com exatamente `tgt` quadros."""
    if fmax is None:
        fmax = sr / 2
    y = dual_pre_emphasis(y)

    L = int(sr * frame_ms / 1000)
    hop = max(1, int(np.floor((len(y) - L) / (tgt - 1))))
    pad = (tgt - 1) * hop + L
    y = np.pad(y, (0, max(0, pad - len(y))))

    frames = np.lib.stride_tricks.sliding_window_view(y, L)[::hop][:tgt]
    S = np.abs(rfft(frames * get_window("hann", L)[None, :], n=n_fft, axis=1))

    mel_fb = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels, fmin=fmin, fmax=fmax)
    return resize224(np.log10(mel_fb @ S.T + eps))

def save_png(M: np.ndarray, path: str, cmap: str = "viridis") -> None:
    """Salva `M` como PNG 224 × 224 sem bordas."""
    plt.figure(figsize=(2.24, 2.24), dpi=100)
    plt.imshow(M, origin="lower", aspect="auto", cmap=cmap)
    plt.axis("off")
    plt.margins(0, 0)
    plt.subplots_adjust(0, 0, 1, 1, 0, 0)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    plt.savefig(path, bbox_inches="tight", pad_inches=0)
    plt.close()
# ╰──────────────────────────────────────────────────────────╯

# ───────────── Configurações ─────────────
IN_ROOT  = "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_5R_sem_trunc_mod"
OUT_ROOT = "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_5R_sem_trunc_mod_ESPEC"
DIRS = {
    t: f"{OUT_ROOT}/{t if t != 'log-Mel' else 'log_mel'}"
    for t in ["log-Mel", "STFT", "CQT"]
}

CHECK_FILE = f"{OUT_ROOT}/checkpoint_rooms.txt"
rooms_done: set[str] = set()
if os.path.exists(CHECK_FILE):
    rooms_done = {ln.strip() for ln in open(CHECK_FILE) if ln.strip()}

# Lista para armazenar caminhos de arquivos corrompidos
corrupted_files: list[str] = []

# Agrupa WAVs por sala
room_dict: dict[str, list[str]] = {}
for wav in glob.glob(os.path.join(IN_ROOT, "**/*.wav"), recursive=True):
    m = re.search(r"/(room_\d+)/", wav)
    if m:
        room = m.group(1)
        room_dict.setdefault(room, []).append(wav)

primeira_sala = None
figs: list[tuple[str, np.ndarray]] = []

# ───────────── Loop por sala ─────────────
for room, wavs in sorted(room_dict.items(), key=lambda x: int(x[0].split("_")[1])):
    if room in rooms_done:
        continue  # sala já processada

    print(f"\n▶ Processando {room} ({len(wavs)} arquivos)")
    for wav_path in tqdm(wavs, desc=room, leave=False):
        # tenta ler o arquivo; se corrompido, registra e pula
        try:
            audio, sr = sf.read(wav_path)
        except Exception as e:
            print(f"⚠ Não foi possível ler: {wav_path} — pulando")
            corrupted_files.append(wav_path)
            continue

        # nome base (sem extensão) do WAV
        base_name = os.path.splitext(os.path.basename(wav_path))[0]
        # garante que base_name não tenha prefixo repetido
        base_name = re.sub(rf"^{room}_", "", base_name)
        # agora cria o nome *com* prefixo room_XX_
        prefixed_name = f"{room}_{base_name}"

        # caminhos de saída
        outs = {t: f"{DIRS[t]}/{room}/{prefixed_name}.png" for t in DIRS}
        # se já existem os 3 espectrogramas, pula
        if all(os.path.exists(p) for p in outs.values()):
            continue

        # se for estéreo, converte para mono
        y = audio.mean(axis=1) if audio.ndim > 1 else audio

        # log-Mel
        logmel = compute_logmel(y, sr)
        save_png(logmel, outs["log-Mel"], "viridis")

        # STFT
        hop = int(sr * 25 / 1000)  # 25 ms
        stft = resize224(
            librosa.amplitude_to_db(np.abs(librosa.stft(y, n_fft=2048, hop_length=hop)), ref=np.max)
        )
        save_png(stft, outs["STFT"], "magma")

        # CQT
        cqt = resize224(
            librosa.amplitude_to_db(
                np.abs(librosa.cqt(y, sr=sr, hop_length=hop, n_bins=84, bins_per_octave=12)),
                ref=np.max,
            )
        )
        save_png(cqt, outs["CQT"], "inferno")

        # coleta figuras da primeira sala
        if primeira_sala is None:
            primeira_sala = room
        if room == primeira_sala:
            figs.extend([
                (f"{prefixed_name} (log-Mel)", logmel),
                (f"{prefixed_name} (STFT)", stft),
                (f"{prefixed_name} (CQT)", cqt),
            ])

    # marca sala como concluída
    with open(CHECK_FILE, "a") as ck:
        ck.write(room + "\n")
    rooms_done.add(room)
    print(f"✔ {room} concluída e registrada em checkpoint.")

# ────────── Grava CSV de corrompidos ──────────
if corrupted_files:
    csv_path = os.path.join(OUT_ROOT, "corrupted_files.csv")
    os.makedirs(OUT_ROOT, exist_ok=True)
    with open(csv_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["filepath"])
        for fp in corrupted_files:
            writer.writerow([fp])
    print(f"\n Foram encontrados {len(corrupted_files)} arquivos corrompidos.")
    print(f"    Lista salva em: {csv_path}")

# ───────────── Visualização da primeira sala ─────────────
if figs:
    cols = 3
    rows = int(np.ceil(len(figs) / cols))
    fig, ax = plt.subplots(rows, cols, figsize=(cols * 2.5, rows * 2.5))
    ax = ax.flatten()
    for a, (title, M) in zip(ax, figs):
        a.imshow(M, origin="lower", aspect="auto")
        a.set_title(title, fontsize=7)
        a.axis("off")
    for a in ax[len(figs):]:
        a.axis("off")
    plt.tight_layout()
    plt.show()

print("\nProcessamento global concluído!")

"""## SUPERLETS"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# cat << 'EOF' > /content/superlets.py
# import numpy as np
# from scipy.signal import fftconvolve
# 
# MORLET_SD_SPREAD = 6
# MORLET_SD_FACTOR = 2.5
# 
# def computeWaveletSize(fc, nc, fs):
#     sd = (nc / 2) * (1 / np.abs(fc)) / MORLET_SD_FACTOR
#     return int(2 * np.floor(np.round(sd * fs * MORLET_SD_SPREAD) / 2) + 1)
# 
# def gausswin(size, alpha):
#     halfSize = size // 2
#     idiv     = alpha / halfSize
#     t        = (np.arange(size) - halfSize) * idiv
#     return np.exp(-0.5 * t*t)
# 
# def morlet(fc, nc, fs):
#     size  = computeWaveletSize(fc, nc, fs)
#     half  = size // 2
#     gauss = gausswin(size, MORLET_SD_SPREAD/2)
#     igsum = 1/gauss.sum()
#     t     = (np.arange(size) - half)/fs
#     return gauss * np.exp(2j*np.pi*fc*t) * igsum
# 
# def fractional(x):
#     return x - int(x)
# 
# class SuperletTransform:
#     def __init__(self, inputSize, samplingRate, frequencyRange,
#                  frequencyBins, baseCycles, superletOrders, frequencies=None):
#         if frequencies is not None:
#             self.frequencies = np.array(frequencies)
#         else:
#             self.frequencies = np.linspace(frequencyRange[0], frequencyRange[1], frequencyBins)
#         self.inputSize = inputSize
#         self.orders    = np.linspace(superletOrders[0], superletOrders[1], len(self.frequencies))
#         self.superlets = []
#         for i, f in enumerate(self.frequencies):
#             nW   = int(np.ceil(self.orders[i]))
#             waves = [morlet(f, (j+1)*baseCycles, samplingRate) for j in range(nW)]
#             self.superlets.append(waves)
# 
#     def longestWaveletSize(self):
#         return max(w.shape[0] for s in self.superlets for w in s)
# 
#     def transform(self, data):
#         if data.ndim != 1 or data.shape[0] != self.inputSize:
#             raise ValueError("Input size mismatch.")
#         result = np.zeros((len(self.frequencies), self.inputSize))
#         for i, waves in enumerate(self.superlets):
#             order = self.orders[i]
#             nW    = int(np.floor(order))
#             pool  = np.ones(self.inputSize)
#             for j in range(nW):
#                 conv = fftconvolve(data, waves[j], mode="same")
#                 pool *= 2 * np.abs(conv)**2
#             frac = fractional(order)
#             if frac and len(waves) == nW+1:
#                 conv = fftconvolve(data, waves[nW], mode="same")
#                 pool *= (2 * np.abs(conv)**2)**frac
#             result[i,:] = pool**(1/order)
#         return result
# 
# def cropSpectrum(spectrum, paddingSize):
#     return spectrum[:, paddingSize:-paddingSize]
# 
# def superlets(data, fs, foi, c1, ord):
#     buf = data.shape[-1]
#     st  = SuperletTransform(buf, fs, None, None, c1, ord, frequencies=foi)
#     S   = st.transform(data)
#     pad = st.longestWaveletSize()//2
#     return cropSpectrum(S, pad)
# EOF
#

!ls /content | grep superlets.py

from superlets import superlets, SuperletTransform, cropSpectrum

print("Import bem-sucedido!")

"""testando"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
compute_and_plot_superlet.py

Loads a mono WAV file, computes its Superlet time–frequency spectrum,
and plots the result.

Usage:
    python compute_and_plot_superlet.py
"""

import os
import numpy as np
import soundfile as sf
import matplotlib.pyplot as plt

# Se o módulo superlets.py estiver no mesmo diretório:
from superlets import superlets

def main():
    # ---- Path to your WAV ----
    wav_path = "/content/drive/MyDrive/PREPROCESSING/convolucoes/MONO_1R_sem_trunc/room_0/room_0_FULL_src0_rec0_mic1.wav"
    if not os.path.exists(wav_path):
        raise FileNotFoundError(f"WAV not found: {wav_path}")

    # ---- Load audio ----
    data, fs = sf.read(wav_path)
    # if stereo, take first channel
    if data.ndim > 1:
        data = data[:, 0]

    # ---- Superlet parameters ----
    foi       = np.linspace(1, fs/2, 128)  # 128 freq bins from 1 Hz to Nyquist
    c1        = 3                          # base number of cycles
    ord_range = (1, 5)                     # order range for adaptive superlets

    # ---- Compute superlet spectrum ----
    # superlets() returns a 2D array: shape = (len(foi), len(data) - 2*pad)
    S = superlets(data, fs, foi, c1, ord_range)

    # ---- Time & Frequency axes ----
    n_time = S.shape[1]
    t = np.arange(n_time) / fs
    f = foi

    # ---- Plot ----
    plt.figure(figsize=(10, 6))
    plt.imshow(
        S,
        aspect='auto',
        origin='lower',
        extent=[t[0], t[-1], f[0], f[-1]]
    )
    plt.xlabel('Time (s)')
    plt.ylabel('Frequency (Hz)')
    plt.title(f"Superlet Spectrum: {os.path.basename(wav_path)}")
    plt.colorbar(label='Power')
    plt.tight_layout()

    # ---- Save figure ----
    out_png = os.path.splitext(wav_path)[0] + "_superlet.png"
    plt.savefig(out_png, dpi=300)
    print(f"Saved plot to {out_png}")

    plt.show()

if __name__ == "__main__":
    main()

"""aplicando para todos"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
batch_compute_and_save_superlet_spectrograms.py

Walks through all mono WAV files in `input_root`, computes each
Superlet time–frequency spectrum, and saves just the spectrogram
as a 224×224 PNG (no borders) in a parallel `output_root` directory,
preserving the relative path and filename.

Usage:
    python batch_compute_and_save_superlet_spectrograms.py
"""

import os
import numpy as np
import soundfile as sf
from superlets import superlets
import matplotlib.pyplot as plt

# ─────────── PARAMETERS ────────────
input_root  = "/content/drive/MyDrive/PREPROCESSING/convolucoes/MONO_1R_sem_trunc"
output_root = input_root + "_ESPEC_SUPERLET_mod"

# Superlet parameters
c1        = 3
ord_range = (1, 5)
freq_bins = 128

# Spectrogram PNG size: 2.24 in × 2.24 in at 100 dpi → 224×224 px
FIGSIZE = (2.24, 2.24)
DPI     = 100
CMAP    = "viridis"

# ─────────── helper ────────────
def save_png(M: np.ndarray, path: str, cmap: str = CMAP) -> None:
    """Saves matrix M as a borderless 224×224 PNG."""
    plt.figure(figsize=FIGSIZE, dpi=DPI)
    plt.imshow(M, origin="lower", aspect="auto", cmap=cmap)
    plt.axis("off")
    plt.margins(0, 0)
    plt.subplots_adjust(0, 0, 1, 1, 0, 0)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    plt.savefig(path, bbox_inches="tight", pad_inches=0)
    plt.close()

# ─────────── processing ────────────
def process_file(wav_path: str):
    # read audio (mono)
    data, fs = sf.read(wav_path)
    if data.ndim > 1:
        data = data[:, 0]

    # frequencies of interest
    foi = np.linspace(1, fs/2, freq_bins)

    # compute superlet spectrogram
    S = superlets(data, fs, foi, c1, ord_range)

    # build output path: replace input_root with output_root, .wav→.png
    rel = os.path.relpath(wav_path, input_root)
    out_png = os.path.join(output_root, os.path.splitext(rel)[0] + ".png")

    # save only the spectrogram
    save_png(S, out_png)

    print(f"Saved spectrogram to {out_png}")

# ─────────── main ────────────
def main():
    for root, _, files in os.walk(input_root):
        for fname in files:
            if not fname.lower().endswith(".wav"):
                continue
            wav_path = os.path.join(root, fname)
            try:
                process_file(wav_path)
            except Exception as e:
                print(f"[ERROR] {wav_path}: {e}")

if __name__ == "__main__":
    main()

"""## STFT ORIGINAL"""

from google.colab import drive
drive.mount('/content/drive')

"""### SEM RUÍDO"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
gera_spectrogramas_com_ruido.py
───────────────────────────────────────────────────────────────────────────────
Percorre recursivamente todos os .wav em
  /content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/NOVA_RIRs_filtradas_somadas_convoluidas
gera um espectrograma log-amplitude de cada um (em dB), redimensiona para
224×224 e salva o tensor RGB normalizado em
  /content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/ESPECTROGRAMAS_TENSORES_COM_RUIDO
mantendo a mesma estrutura de subpastas (room_0, room_1, …).

Configurações:
    fs_target      = 16000      # Hz
    audio_duration = 5          # segundos
    skip_time      = 0.1        # segundos a descartar do início
    img_size       = (224,224)  # rede ResNet-50
    n_fft          = 512
    hop_length     = n_fft//4   # 128
    noverlap       = n_fft - hop_length  # 384
"""
import os
from pathlib import Path

import librosa
import numpy as np
import torch
from PIL import Image

# ─────────────────────────────────────────────────────────────────────────────
# CONFIGURAÇÕES
# ─────────────────────────────────────────────────────────────────────────────
fs_target      = 16000
audio_duration = 5
skip_time      = 0.1
img_size       = (224, 224)
n_fft          = 512
hop_length     = n_fft // 4
noverlap       = n_fft - hop_length

base_dataset_path = Path(
    "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_SR_sem_trunc_mod"
)
target_base = Path(
    "/content/drive/MyDrive/PREPROCESSING/ESPECTROGRAMA_ORIGINAL_R_MAX/MONO_SR"
)

# ─────────────────────────────────────────────────────────────────────────────
# percorre todos os subdiretórios
# ─────────────────────────────────────────────────────────────────────────────
for wav_path in base_dataset_path.rglob("*.wav"):
    # caminho relativo, ex: room_0/room_0_FULL_src0_rec0_mic1.wav
    rel = wav_path.relative_to(base_dataset_path)
    out_dir = target_base / rel.parent
    out_dir.mkdir(parents=True, exist_ok=True)

    # nome sem extensão
    name = rel.stem  # e.g. "room_0_FULL_src0_rec0_mic1"
    out_path = out_dir / (name + ".pt")

    # carrega áudio
    y, sr = librosa.load(str(wav_path), sr=None)
    # descarta começo
    start = int(skip_time * sr)
    y = y[start:]
    # pad/truncate para duração fixa
    max_samples = int(audio_duration * sr)
    if y.shape[0] < max_samples:
        y = np.pad(y, (0, max_samples - y.shape[0]), mode="constant")
    else:
        y = y[:max_samples]
    # resample se necessário
    if sr != fs_target:
        y = librosa.resample(y, orig_sr=sr, target_sr=fs_target)
        sr = fs_target

    # computa STFT
    S = librosa.stft(y,
                     n_fft=n_fft,
                     hop_length=hop_length,
                     win_length=n_fft,
                     window="hann")
    # magnitude em dB
    S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)

    # normaliza para [0,255]
    S_min, S_max = S_db.min(), S_db.max()
    S_norm = (S_db - S_min) / (S_max - S_min) * 255.0
    S_uint8 = S_norm.astype(np.uint8)

    # converte em imagem RGB e redimensiona
    img = Image.fromarray(S_uint8).convert("RGB")
    img = img.resize(img_size, resample=Image.BILINEAR)

    # tensor float32 normalizado [0,1], formato (C,H,W)
    img_tensor = torch.tensor(
        np.array(img), dtype=torch.float32
    ).permute(2, 0, 1) / 255.0

    # salva tensor em .pt
    torch.save(img_tensor, str(out_path))

print("Espectrogramas gerados em:", target_base)

"""### COM 1 RUÍDO"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
gera_spectrogramas_com_ruido.py
───────────────────────────────────────────────────────────────────────────────
Percorre recursivamente todos os .wav em
  /content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/NOVA_RIRs_filtradas_somadas_convoluidas
gera um espectrograma log-amplitude de cada um (em dB), redimensiona para
224×224 e salva o tensor RGB normalizado em
  /content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/ESPECTROGRAMAS_TENSORES_COM_RUIDO
mantendo a mesma estrutura de subpastas (room_0, room_1, …).

Configurações:
    fs_target      = 16000      # Hz
    audio_duration = 5          # segundos
    skip_time      = 0.1        # segundos a descartar do início
    img_size       = (224,224)  # rede ResNet-50
    n_fft          = 512
    hop_length     = n_fft//4   # 128
    noverlap       = n_fft - hop_length  # 384
"""
import os
from pathlib import Path

import librosa
import numpy as np
import torch
from PIL import Image

# ─────────────────────────────────────────────────────────────────────────────
# CONFIGURAÇÕES
# ─────────────────────────────────────────────────────────────────────────────
fs_target      = 16000
audio_duration = 5
skip_time      = 0.1
img_size       = (224, 224)
n_fft          = 512
hop_length     = n_fft // 4
noverlap       = n_fft - hop_length

base_dataset_path = Path(
    "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_1R_sem_trunc"
)
target_base = Path(
    "/content/drive/MyDrive/PREPROCESSING/ESPECTROGRAMA_ORIGINAL_R_MAX/MONO_1R"
)

# ─────────────────────────────────────────────────────────────────────────────
# percorre todos os subdiretórios
# ─────────────────────────────────────────────────────────────────────────────
for wav_path in base_dataset_path.rglob("*.wav"):
    # caminho relativo, ex: room_0/room_0_FULL_src0_rec0_mic1.wav
    rel = wav_path.relative_to(base_dataset_path)
    out_dir = target_base / rel.parent
    out_dir.mkdir(parents=True, exist_ok=True)

    # nome sem extensão
    name = rel.stem  # e.g. "room_0_FULL_src0_rec0_mic1"
    out_path = out_dir / (name + ".pt")

    # carrega áudio
    y, sr = librosa.load(str(wav_path), sr=None)
    # descarta começo
    start = int(skip_time * sr)
    y = y[start:]
    # pad/truncate para duração fixa
    max_samples = int(audio_duration * sr)
    if y.shape[0] < max_samples:
        y = np.pad(y, (0, max_samples - y.shape[0]), mode="constant")
    else:
        y = y[:max_samples]
    # resample se necessário
    if sr != fs_target:
        y = librosa.resample(y, orig_sr=sr, target_sr=fs_target)
        sr = fs_target

    # computa STFT
    S = librosa.stft(y,
                     n_fft=n_fft,
                     hop_length=hop_length,
                     win_length=n_fft,
                     window="hann")
    # magnitude em dB
    S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)

    # normaliza para [0,255]
    S_min, S_max = S_db.min(), S_db.max()
    S_norm = (S_db - S_min) / (S_max - S_min) * 255.0
    S_uint8 = S_norm.astype(np.uint8)

    # converte em imagem RGB e redimensiona
    img = Image.fromarray(S_uint8).convert("RGB")
    img = img.resize(img_size, resample=Image.BILINEAR)

    # tensor float32 normalizado [0,1], formato (C,H,W)
    img_tensor = torch.tensor(
        np.array(img), dtype=torch.float32
    ).permute(2, 0, 1) / 255.0

    # salva tensor em .pt
    torch.save(img_tensor, str(out_path))

print("Espectrogramas gerados em:", target_base)

"""### COM 5 RUIDOS"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
gera_spectrogramas_com_ruido.py  (versão “pulando já feitos” e arquivos WAV corrompidos)
───────────────────────────────────────────────────────────────────────────────
Varre recursivamente todos os .wav em
  /content/drive/MyDrive/PREPROCESSING/CONV/MONO_5R_sem_trunc_mod
gera um espectrograma STFT em dB, redimensiona para 224×224
e salva o tensor RGB normalizado em
  /content/drive/MyDrive/PREPROCESSING/ESPECTROGRAMA_ORIGINAL_R_MAX/MONO_5R
mantendo a hierarquia original (room_0, room_1, …).

Ao reexecutar, o script **pula** qualquer arquivo cujo .pt de destino já exista,
e **registra** arquivos WAV com falha de leitura para relatório ao final.
"""

import os
from pathlib import Path
import librosa
import numpy as np
import torch
from PIL import Image
from tqdm.auto import tqdm

# ─────────────────────────────────────────────────────────────────────────────
# CONFIGURAÇÕES
# ─────────────────────────────────────────────────────────────────────────────
fs_target      = 16000        # Hz
audio_duration = 5            # segundos
skip_time      = 0.1          # segundos descartados no início
img_size       = (224, 224)   # entrada típica de ResNet-50
n_fft          = 512
hop_length     = n_fft // 4   # 128
# note: noverlap não é usado diretamente em librosa.stft
# but we can compute it if needed: noverlap = n_fft - hop_length

base_dataset_path = Path(
    "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_5R_sem_trunc_mod"
)
target_base = Path(
    "/content/drive/MyDrive/PREPROCESSING/ESPECTROGRAMA_ORIGINAL_R_MAX/MONO_5R"
)

# Lista para registrar arquivos WAV que falharam ao carregar
corrupted_wavs = []

# ─────────────────────────────────────────────────────────────────────────────
# LOOP PRINCIPAL
# ─────────────────────────────────────────────────────────────────────────────
wav_files = list(base_dataset_path.rglob("*.wav"))
print(f"Arquivos .wav encontrados: {len(wav_files)}")

for wav_path in tqdm(wav_files, desc="Gerando espectrogramas"):
    # caminhos relativos / absolutos de saída
    rel      = wav_path.relative_to(base_dataset_path)
    out_dir  = target_base / rel.parent
    out_path = out_dir / f"{rel.stem}.pt"

    # ─── 1) Pula se já existe ───────────────────────────────────────────────
    if out_path.exists():
        continue

    # ─── 2) Tenta carregar áudio, pulando em caso de erro ──────────────────
    try:
        y, sr = librosa.load(str(wav_path), sr=None)
    except Exception as e:
        corrupted_wavs.append(str(wav_path))
        continue

    # ─── 3) Pré-processa áudio ─────────────────────────────────────────────
    # descarta início
    start_sample = int(skip_time * sr)
    y = y[start_sample:]

    # pad/truncate para duração fixa
    max_len = int(audio_duration * sr)
    if y.shape[0] < max_len:
        y = np.pad(y, (0, max_len - y.shape[0]), mode="constant")
    else:
        y = y[:max_len]

    # resample se necessário
    if sr != fs_target:
        y = librosa.resample(y, orig_sr=sr, target_sr=fs_target)
        sr = fs_target

    # ─── 4) Calcula STFT em dB ──────────────────────────────────────────────
    S = librosa.stft(
        y,
        n_fft=n_fft,
        hop_length=hop_length,
        win_length=n_fft,
        window="hann"
    )
    S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)

    # ─── 5) Normaliza para imagem [0–255] ───────────────────────────────────
    S_min, S_max = S_db.min(), S_db.max()
    S_img = ((S_db - S_min) / (S_max - S_min) * 255.0).astype(np.uint8)

    img = Image.fromarray(S_img).convert("RGB")
    img = img.resize(img_size, resample=Image.BILINEAR)

    tensor = torch.tensor(np.array(img), dtype=torch.float32)\
                  .permute(2, 0, 1) / 255.0  # formato (C,H,W) em [0,1]

    # ─── 6) Salva tensor ────────────────────────────────────────────────────
    out_dir.mkdir(parents=True, exist_ok=True)
    torch.save(tensor, str(out_path))

print("\nProcesso concluído! Tensores em:", target_base)

# ───────────── RELATÓRIO DE ERROS ──────────────────────────────────────────
if corrupted_wavs:
    print(f"\n⚠ Falha ao carregar {len(corrupted_wavs)} arquivos WAV:")
    for p in corrupted_wavs:
        print("  -", p)
    # opcional: salvar relatório em disco
    report_path = target_base / "corrupted_wavs.txt"
    with open(report_path, "w", encoding="utf-8") as f:
        for p in corrupted_wavs:
            f.write(p + "\n")
    print("Lista de WAV corrompidos salva em:", report_path)
else:
    print("\nNenhum arquivo WAV corrompido encontrado.")

"""CONTABILIZANDO ESPECTROGRAMAS"""

import os

output_spec_root = "/content/drive/MyDrive/PREPROCESSING/CONV/MONO_SR_ESPEC_STFT_ORIGINAL_mod_1"

# percorre todas as subpastas e soma os arquivos
total_files = sum(len(files) for _, _, files in os.walk(output_spec_root))

print(f"Total de arquivos em '{output_spec_root}': {total_files}")

"""JUNTANDO SR EM UMA ÚNICA PASTA:

- PARA 1R E 5R SOMENTE TROCAR CAMINHO
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
flatten_pt_tensors.py
────────────────────────────────────────────────────────────
Varre recursivamente os .pt de origem e coloca todos em uma
única pasta de destino, preservando apenas o nome-base do
arquivo (sem subpastas).

• SRC_DIR  = diretório raiz onde estão os tensores (.pt)    (busca recursiva)
• DEST_DIR = pasta única onde todos serão copiados/movidos  (sem subdiretórios)

Se um nome já existir na pasta de destino, o script adiciona
um sufixo _1, _2, … para evitar sobrescrita.
---------------------------------------------------------------------------
Dependências:
  pip install tqdm
"""

import shutil
from pathlib import Path
from tqdm.auto import tqdm

# ───────────── 1) CONFIGURAÇÕES ───────────────────────────
SRC_DIR  = Path("/content/drive/MyDrive/PREPROCESSING/ESPECTROGRAMA_ORIGINAL_R_MAX/MONO_SR")
DEST_DIR = Path("/content/drive/MyDrive/PREPROCESSING/ESPECTROGRAMA_ORIGINAL_R_MAX/MONO_SR_PASTA_UNICA")
MOVE_FILES = False   # False = copia; True = move (remove da origem)

DEST_DIR.mkdir(parents=True, exist_ok=True)

# ───────────── 2) COLETA DE ARQUIVOS ──────────────────────
pt_files = list(SRC_DIR.rglob("*.pt"))
if not pt_files:
    raise RuntimeError(f"Nenhum .pt encontrado em {SRC_DIR}")

print(f" Encontrados {len(pt_files)} arquivos .pt para processar.")

# ───────────── 3) CÓPIA/MOVIMENTAÇÃO ──────────────────────
for src_path in tqdm(pt_files, desc="Processando"):
    base_name = src_path.name
    dest_path = DEST_DIR / base_name

    # evita colisão de nomes
    if dest_path.exists():
        stem, suffix = dest_path.stem, dest_path.suffix
        idx = 1
        while True:
            new_name = f"{stem}_{idx}{suffix}"
            dest_path = DEST_DIR / new_name
            if not dest_path.exists():
                break
            idx += 1

    # copia ou move
    if MOVE_FILES:
        shutil.move(src_path, dest_path)
    else:
        shutil.copy2(src_path, dest_path)

print(f" Concluído! Arquivos disponíveis em: {DEST_DIR}")

"""- DIVIDINDO A PASTA ÚNICA EM TREINO/VALID E TESTE"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
split_train_test_flat.py
────────────────────────────────────────────────────────────
Divide .pt em 80 % treino / 20 % teste, mantendo o balance-
amento dentro de cada room_X.  Os arquivos são copiados ou
movidos diretamente para as pastas-destino (sem subpastas).

Estrutura final:
  …/TENSORES_TREINO_TREINO/room_0_FULL_src0_rec0_mic1.pt
  …/TENSORES_TREINO_TESTE/ room_0_FULL_src0_rec0_mic2.pt
---------------------------------------------------------------------------
"""

import random, shutil, re
from pathlib import Path
from tqdm.auto import tqdm

# ───────────── CONFIGURAÇÕES ──────────────────────────────
SRC_DIR   = Path("/content/drive/MyDrive/PREPROCESSING/ESPECTROGRAMA_ORIGINAL_R_MAX/MONO_SR_PASTA_UNICA")
TRAIN_DIR = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/STFT_ORIGINAL_TREINO_VALID")
TEST_DIR  = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/STFT_ORIGINAL_TREINO_TESTE")
TRAIN_RATIO = 0.8
MOVE_FILES  = True          # False = copia, True = move

TRAIN_DIR.mkdir(parents=True, exist_ok=True)
TEST_DIR.mkdir(parents=True,  exist_ok=True)

# ───────────── AGRUPA POR SALA ────────────────────────────
room_pat = re.compile(r"(room_\d+)")
pt_files = list(SRC_DIR.glob("*.pt"))
if not pt_files:
    raise RuntimeError(f"Nenhum .pt encontrado em {SRC_DIR}")

rooms = {}
for f in pt_files:
    room = room_pat.search(f.name).group(1) if room_pat.search(f.name) else "room_unknown"
    rooms.setdefault(room, []).append(f)

# ───────────── SPLIT / MOVIMENTAÇÃO ───────────────────────
random.seed(42)
for room, files in rooms.items():
    random.shuffle(files)
    k_train = int(len(files) * TRAIN_RATIO)
    train_files, test_files = files[:k_train], files[k_train:]

    for src_path, dest_root in tqdm(
        [(f, TRAIN_DIR) for f in train_files] + [(f, TEST_DIR) for f in test_files],
        desc=f"{room}", leave=False):

        dest_path = dest_root / src_path.name
        if dest_path.exists():                # resolve colisão eventual
            stem, suf = dest_path.stem, dest_path.suffix
            idx = 1
            while (dest_root / f"{stem}_{idx}{suf}").exists():
                idx += 1
            dest_path = dest_root / f"{stem}_{idx}{suf}"

        if MOVE_FILES:
            shutil.move(src_path, dest_path)
        else:
            shutil.copy2(src_path, dest_path)

    print(f"{room}: {len(train_files)} treino | {len(test_files)} teste")

print("\n Split concluído:")
print(f"• Treino → {TRAIN_DIR}")
print(f"• Teste  → {TEST_DIR}")

"""# DATASET SEM RUÍDO - SALVANDO ESPECTROGRAMAS EM TENSORES .pt E DIVIDINDO O DATASET TREINO/VALID/TESTE

COMEÇAR AQUI CODIGO PARA DIVIDIR CONJUNTO.ipynb

### LOG-MEL
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
png_to_tensor_logmel.py
────────────────────────────────────────────────────────────
Converte espectrogramas PNG (log-Mel) em tensores PyTorch
compatíveis com ResNet-50 (224×224×3, RGB, float32).

Entrada:
  /content/drive/MyDrive/PREPROCESSING/convolucoes/MONO_SR_ESPEC/log_mel
Saída:
  /content/drive/MyDrive/PREPROCESSING/convolucoes/Tensores_para_teste_log_mel

Para cada arquivo:
  .../room_X/YYY.png  →  .../room_X/YYY.pt
---------------------------------------------------------------------------
Dependências:
  pip install pillow torch torchvision tqdm
"""

import os
import sys
from pathlib import Path

import torch
from PIL import Image
from torchvision import transforms
from tqdm.auto import tqdm

# ───────────── 1) CONFIGURAÇÕES ───────────────────────────
INPUT_DIR  = Path("/content/drive/MyDrive/PREPROCESSING_1s/CONV/MONO_SR_sem_trunc_mod_ESPEC/log_mel")
OUTPUT_DIR = Path("/content/drive/MyDrive/PREPROCESSING_1s/TENSORES_DATASET/SR_mod/log_mel")
EXT_IN     = ".png"
EXT_OUT    = ".pt"

# Transformação: garante 224×224, 3 canais, float32 [0,1]
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),            # converte para [0,1] float32, C×H×W
])

# ───────────── 2) BUSCA E PROCESSAMENTO ───────────────────
png_files = list(INPUT_DIR.rglob(f"*{EXT_IN}"))
if len(png_files) == 0:
    sys.exit(f"Nenhum arquivo {EXT_IN} encontrado em {INPUT_DIR}")

print(f" Imagens encontradas: {len(png_files)}")
for img_path in tqdm(png_files, desc="Convertendo PNG → tensor"):
    # 2.1) Carrega imagem
    img = Image.open(img_path).convert("RGB")  # remove canal alfa, se houver
    tensor = transform(img)                    # C=3, H=224, W=224

    # 2.2) Define caminho de saída
    rel_path = img_path.relative_to(INPUT_DIR).with_suffix(EXT_OUT)
    out_path = OUTPUT_DIR / rel_path
    out_path.parent.mkdir(parents=True, exist_ok=True)

    # 2.3) Salva tensor
    torch.save(tensor, out_path)

print(" Conversão finalizada!")
print(f"Tensores gravados em: {OUTPUT_DIR}")

import os

# Caminho raiz
root_dir = '/content/drive/MyDrive/PREPROCESSING_1s/TENSORES_DATASET/SR_mod/log_mel'

# Contadores
total_pt_files = 0
subdir_counts = {}

# Percorre todos os subdiretórios
for subdir, _, files in os.walk(root_dir):
    pt_files = [f for f in files if f.endswith('.pt')]
    count = len(pt_files)
    if count > 0:
        subdir_counts[subdir] = count
        total_pt_files += count

# Imprime contagem por subdiretório
for path, count in subdir_counts.items():
    print(f'{path}: {count} arquivos .pt')

print(f'\nTotal geral: {total_pt_files} arquivos .pt')

"""COPIANDO PARA UM UNICO DIRETORIO"""

from google.colab import drive
drive.mount('/content/drive')

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
flatten_pt_tensors.py
────────────────────────────────────────────────────────────
Varre recursivamente os .pt de origem e coloca todos em uma
única pasta de destino, preservando apenas o nome-base do
arquivo (sem subpastas).

• SRC_DIR  = diretório raiz onde estão os tensores (.pt)    (busca recursiva)
• DEST_DIR = pasta única onde todos serão copiados/movidos  (sem subdiretórios)

Se um nome já existir na pasta de destino, o script adiciona
um sufixo _1, _2, … para evitar sobrescrita.
---------------------------------------------------------------------------
Dependências:
  pip install tqdm
"""

import shutil
from pathlib import Path
from tqdm.auto import tqdm

# ───────────── 1) CONFIGURAÇÕES ───────────────────────────
SRC_DIR  = Path("/content/drive/MyDrive/PREPROCESSING_1s/TENSORES_DATASET/SR_mod/log_mel")
DEST_DIR = Path("/content/drive/MyDrive/PREPROCESSING_1s/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA")
MOVE_FILES = False   # False = copia; True = move (remove da origem)

DEST_DIR.mkdir(parents=True, exist_ok=True)

# ───────────── 2) COLETA DE ARQUIVOS ──────────────────────
pt_files = list(SRC_DIR.rglob("*.pt"))
if not pt_files:
    raise RuntimeError(f"Nenhum .pt encontrado em {SRC_DIR}")

print(f" Encontrados {len(pt_files)} arquivos .pt para processar.")

# ───────────── 3) CÓPIA/MOVIMENTAÇÃO ──────────────────────
for src_path in tqdm(pt_files, desc="Processando"):
    base_name = src_path.name
    dest_path = DEST_DIR / base_name

    # evita colisão de nomes
    if dest_path.exists():
        stem, suffix = dest_path.stem, dest_path.suffix
        idx = 1
        while True:
            new_name = f"{stem}_{idx}{suffix}"
            dest_path = DEST_DIR / new_name
            if not dest_path.exists():
                break
            idx += 1

    # copia ou move
    if MOVE_FILES:
        shutil.move(src_path, dest_path)
    else:
        shutil.copy2(src_path, dest_path)

print(f" Concluído! Arquivos disponíveis em: {DEST_DIR}")

"""DIVIDINDO O CONJUNTO:"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
split_train_test_flat.py
────────────────────────────────────────────────────────────
Divide .pt em 80 % treino / 20 % teste, mantendo o balance-
amento dentro de cada room_X.  Os arquivos são copiados ou
movidos diretamente para as pastas-destino (sem subpastas).

Estrutura final:
  …/TENSORES_TREINO_TREINO/room_0_FULL_src0_rec0_mic1.pt
  …/TENSORES_TREINO_TESTE/ room_0_FULL_src0_rec0_mic2.pt
---------------------------------------------------------------------------
"""

import random, shutil, re
from pathlib import Path
from tqdm.auto import tqdm

# ───────────── CONFIGURAÇÕES ──────────────────────────────
SRC_DIR   = Path("/content/drive/MyDrive/PREPROCESSING_1s/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA")
TRAIN_DIR = Path("/content/drive/MyDrive/PREPROCESSING_1s/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TREINO_VALID")
TEST_DIR  = Path("/content/drive/MyDrive/PREPROCESSING_1s/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE")
TRAIN_RATIO = 0.8
MOVE_FILES  = True          # False = copia, True = move

TRAIN_DIR.mkdir(parents=True, exist_ok=True)
TEST_DIR.mkdir(parents=True,  exist_ok=True)

# ───────────── AGRUPA POR SALA ────────────────────────────
room_pat = re.compile(r"(room_\d+)")
pt_files = list(SRC_DIR.glob("*.pt"))
if not pt_files:
    raise RuntimeError(f"Nenhum .pt encontrado em {SRC_DIR}")

rooms = {}
for f in pt_files:
    room = room_pat.search(f.name).group(1) if room_pat.search(f.name) else "room_unknown"
    rooms.setdefault(room, []).append(f)

# ───────────── SPLIT / MOVIMENTAÇÃO ───────────────────────
random.seed(42)
for room, files in rooms.items():
    random.shuffle(files)
    k_train = int(len(files) * TRAIN_RATIO)
    train_files, test_files = files[:k_train], files[k_train:]

    for src_path, dest_root in tqdm(
        [(f, TRAIN_DIR) for f in train_files] + [(f, TEST_DIR) for f in test_files],
        desc=f"{room}", leave=False):

        dest_path = dest_root / src_path.name
        if dest_path.exists():                # resolve colisão eventual
            stem, suf = dest_path.stem, dest_path.suffix
            idx = 1
            while (dest_root / f"{stem}_{idx}{suf}").exists():
                idx += 1
            dest_path = dest_root / f"{stem}_{idx}{suf}"

        if MOVE_FILES:
            shutil.move(src_path, dest_path)
        else:
            shutil.copy2(src_path, dest_path)

    print(f"{room}: {len(train_files)} treino | {len(test_files)} teste")

print("\n Split concluído:")
print(f"• Treino → {TRAIN_DIR}")
print(f"• Teste  → {TEST_DIR}")

import os, glob

dirs = {
    "Treino/Validação": "/content/drive/MyDrive/PREPROCESSING_1s/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TREINO_VALID",
    "Teste"            : "/content/drive/MyDrive/PREPROCESSING_1s/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE"
}

for label, path in dirs.items():
    # padrão "**/*" → todos os arquivos em subpastas; ajuste para "*.pt" se quiser filtrar
    n_files = len(glob.glob(os.path.join(path, "**", "*"), recursive=True))
    print(f"{label}: {n_files} arquivos")

"""### STFT"""

import os

# Caminho raiz
root_dir = '/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/STFT'

# Contadores
total_pt_files = 0
subdir_counts = {}

# Percorre todos os subdiretórios
for subdir, _, files in os.walk(root_dir):
    pt_files = [f for f in files if f.endswith('.pt')]
    count = len(pt_files)
    if count > 0:
        subdir_counts[subdir] = count
        total_pt_files += count

# Imprime contagem por subdiretório
for path, count in subdir_counts.items():
    print(f'{path}: {count} arquivos .pt')

print(f'\nTotal geral: {total_pt_files} arquivos .pt')

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
flatten_pt_tensors.py
────────────────────────────────────────────────────────────
Varre recursivamente os .pt de origem e coloca todos em uma
única pasta de destino, preservando apenas o nome-base do
arquivo (sem subpastas).

• SRC_DIR  = diretório raiz onde estão os tensores (.pt)    (busca recursiva)
• DEST_DIR = pasta única onde todos serão copiados/movidos  (sem subdiretórios)

Se um nome já existir na pasta de destino, o script adiciona
um sufixo _1, _2, … para evitar sobrescrita.
---------------------------------------------------------------------------
Dependências:
  pip install tqdm
"""

import shutil
from pathlib import Path
from tqdm.auto import tqdm

# ───────────── 1) CONFIGURAÇÕES ───────────────────────────
SRC_DIR  = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/STFT")
DEST_DIR = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/STFT_PASTA_UNICA")
MOVE_FILES = False   # False = copia; True = move (remove da origem)

DEST_DIR.mkdir(parents=True, exist_ok=True)

# ───────────── 2) COLETA DE ARQUIVOS ──────────────────────
pt_files = list(SRC_DIR.rglob("*.pt"))
if not pt_files:
    raise RuntimeError(f"Nenhum .pt encontrado em {SRC_DIR}")

print(f" Encontrados {len(pt_files)} arquivos .pt para processar.")

# ───────────── 3) CÓPIA/MOVIMENTAÇÃO ──────────────────────
for src_path in tqdm(pt_files, desc="Processando"):
    base_name = src_path.name
    dest_path = DEST_DIR / base_name

    # evita colisão de nomes
    if dest_path.exists():
        stem, suffix = dest_path.stem, dest_path.suffix
        idx = 1
        while True:
            new_name = f"{stem}_{idx}{suffix}"
            dest_path = DEST_DIR / new_name
            if not dest_path.exists():
                break
            idx += 1

    # copia ou move
    if MOVE_FILES:
        shutil.move(src_path, dest_path)
    else:
        shutil.copy2(src_path, dest_path)

print(f" Concluído! Arquivos disponíveis em: {DEST_DIR}")

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
split_train_test_flat.py
────────────────────────────────────────────────────────────
Divide .pt em 80 % treino / 20 % teste, mantendo o balance-
amento dentro de cada room_X.  Os arquivos são copiados ou
movidos diretamente para as pastas-destino (sem subpastas).

Estrutura final:
  …/TENSORES_TREINO_TREINO/room_0_FULL_src0_rec0_mic1.pt
  …/TENSORES_TREINO_TESTE/ room_0_FULL_src0_rec0_mic2.pt
---------------------------------------------------------------------------
"""

import random, shutil, re
from pathlib import Path
from tqdm.auto import tqdm

# ───────────── CONFIGURAÇÕES ──────────────────────────────
SRC_DIR   = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/STFT_PASTA_UNICA")
TRAIN_DIR = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/STFT_PASTA_UNICA_TREINO_VALID")
TEST_DIR  = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/STFT_PASTA_UNICA_TESTE")
TRAIN_RATIO = 0.8
MOVE_FILES  = True          # False = copia, True = move

TRAIN_DIR.mkdir(parents=True, exist_ok=True)
TEST_DIR.mkdir(parents=True,  exist_ok=True)

# ───────────── AGRUPA POR SALA ────────────────────────────
room_pat = re.compile(r"(room_\d+)")
pt_files = list(SRC_DIR.glob("*.pt"))
if not pt_files:
    raise RuntimeError(f"Nenhum .pt encontrado em {SRC_DIR}")

rooms = {}
for f in pt_files:
    room = room_pat.search(f.name).group(1) if room_pat.search(f.name) else "room_unknown"
    rooms.setdefault(room, []).append(f)

# ───────────── SPLIT / MOVIMENTAÇÃO ───────────────────────
random.seed(42)
for room, files in rooms.items():
    random.shuffle(files)
    k_train = int(len(files) * TRAIN_RATIO)
    train_files, test_files = files[:k_train], files[k_train:]

    for src_path, dest_root in tqdm(
        [(f, TRAIN_DIR) for f in train_files] + [(f, TEST_DIR) for f in test_files],
        desc=f"{room}", leave=False):

        dest_path = dest_root / src_path.name
        if dest_path.exists():                # resolve colisão eventual
            stem, suf = dest_path.stem, dest_path.suffix
            idx = 1
            while (dest_root / f"{stem}_{idx}{suf}").exists():
                idx += 1
            dest_path = dest_root / f"{stem}_{idx}{suf}"

        if MOVE_FILES:
            shutil.move(src_path, dest_path)
        else:
            shutil.copy2(src_path, dest_path)

    print(f"{room}: {len(train_files)} treino | {len(test_files)} teste")

print("\n Split concluído:")
print(f"• Treino → {TRAIN_DIR}")
print(f"• Teste  → {TEST_DIR}")

"""### QCT"""







"""# DATASET COM UM RUÍDO - SALVANDO ESPECTROGRAMAS EM TENSORES .pt

### LOG-MEL
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
png_to_tensor_logmel.py (updated)
────────────────────────────────────────────────────────────
Converte espectrogramas PNG (log-Mel) em tensores PyTorch,
pulando arquivos corrompidos e listando-os ao final.
"""

import os
import sys
from pathlib import Path

import torch
from PIL import Image, UnidentifiedImageError
from torchvision import transforms
from tqdm.auto import tqdm

# ───────────── 1) CONFIGURAÇÕES ───────────────────────────
INPUT_DIR  = Path("/content/drive/MyDrive/PREPROCESSING/CONV/MONO_1R_sem_trunc_ESPEC/log_mel")
OUTPUT_DIR = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/1R/log_mel_MOD")
EXT_IN     = ".png"
EXT_OUT    = ".pt"

# Transformação: garante 224×224, 3 canais, float32 [0,1]
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),            # converte para [0,1] float32, C×H×W
])

# Lista para armazenar caminhos de arquivos corrompidos
corrupted = []

# ───────────── 2) BUSCA E PROCESSAMENTO ───────────────────
png_files = list(INPUT_DIR.rglob(f"*{EXT_IN}"))
if not png_files:
    sys.exit(f"Nenhum arquivo {EXT_IN} encontrado em {INPUT_DIR}")

print(f"Imagens encontradas: {len(png_files)}")
for img_path in tqdm(png_files, desc="Convertendo PNG → tensor"):
    try:
        # 2.1) Carrega imagem
        img = Image.open(img_path).convert("RGB")
        tensor = transform(img)
    except (UnidentifiedImageError, OSError) as e:
        # registra e pula arquivo corrompido
        corrupted.append(str(img_path))
        continue

    # 2.2) Define caminho de saída
    rel_path = img_path.relative_to(INPUT_DIR).with_suffix(EXT_OUT)
    out_path = OUTPUT_DIR / rel_path
    out_path.parent.mkdir(parents=True, exist_ok=True)

    # 2.3) Salva tensor
    torch.save(tensor, out_path)

print("\nConversão finalizada!")
print(f"Tensores gravados em: {OUTPUT_DIR}")

# ───────────── 3) RELATÓRIO DE CORROMPIDOS ─────────────
if corrupted:
    print(f"\n⚠ Foram encontrados {len(corrupted)} arquivos corrompidos:")
    for p in corrupted:
        print(f"  - {p}")
    # opcional: salvar lista em arquivo
    report_path = OUTPUT_DIR / "corrupted_images.txt"
    with open(report_path, "w", encoding="utf-8") as f:
        for p in corrupted:
            f.write(p + "\n")
    print(f"Lista de corrompidos salva em: {report_path}")
else:
    print("\nNenhum arquivo corrompido encontrado.")

"""# DATASET COM CINCO RUÍDOS - SALVANDO ESPECTROGRAMAS EM TENSORES .pt

## LOG-MEL

# IMPLEMENTANDO O MODELO RESNET-50 PARA TREINAMENTO

ler rotulos
"""

import pandas as pd

# Caminho para o arquivo CSV
labels_path = '/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv'

# Leitura do CSV em um DataFrame
df_merged = pd.read_csv(labels_path)

# Exibe as primeiras linhas para conferência
print(df_merged.head())

df_merged.info()

import os

TENSOR_DIR = '/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/ESPECTROGRAMAS_TENSORES'

# Conta recursivamente todos os arquivos no diretório e subdiretórios
total_files = sum(len(files) for _, _, files in os.walk(TENSOR_DIR))

print(f"Total de arquivos em '{TENSOR_DIR}': {total_files}")

from google.colab import drive
drive.mount('/content/drive')

SRC_DIR   = Path("/content/drive/MyDrive/PREPROCESSING/CONV/MONO_SR_ESPEC_STFT_ORIGINAL_PASTA_UNICA")
TRAIN_DIR = Path("/content/drive/MyDrive/PREPROCESSING/CONV/MONO_SR_ESPEC_STFT_ORIGINAL_PASTA_UNICA_TREINO_VALID")
TEST_DIR  = Path("/content/drive/MyDrive/PREPROCESSING/CONV/MONO_SR_ESPEC_STFT_ORIGINAL_PASTA_UNICA_TESTE")

"""# MODELO 1 - 6 HEADS (125, 250, 500, 1000, 2000, 4000)

## TREINANDO LOG-MEL - SR
"""

from google.colab import drive
import os

# Monta o Google Drive
drive.mount('/content/drive')

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_multihead_frequency_kfold.py
──────────────────────────────────
• Treina um ResNet-50 multitarefa com cabeças por banda de frequência
  para estimar C50 e T60 em 6 bandas (125-4000 Hz).
• Validação cruzada K-Fold (K=5) com retomada de checkpoint por fold.
• Salva scalers e checkpoints por fold-época.
• Imprime RMSE, MAE, R² e PCC por banda (treino/validação).
• Acumula todas as métricas em CSV sem nunca sobrescrevê-lo.
"""

import os, random, pickle, math
from pathlib import Path
from typing import Dict, Tuple, List

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

# ────────────── caminhos principais ──────────────
TRAIN_DIR = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TREINO_VALID")
LABELS_PATH = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR   = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_mod")
os.makedirs(MODEL_DIR, exist_ok=True)

# ─────────── CSV de métricas (append-only) ───────────
metrics_path = MODEL_DIR / "all_metrics.csv"
header = "fold,epoch,band,var,rmse_t,mae_t,r2_t,pcc_t,rmse_v,mae_v,r2_v,pcc_v\n"
if not metrics_path.exists():          # só cria se ainda não existir
    with open(metrics_path, "w", encoding="utf-8") as f:
        f.write(header)

# ─────────── hiperparâmetros globais ───────────
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQUENCIES = [str(b) for b in FREQ_BANDS]
C50_VARS    = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS    = [f"T60_{b}" for b in FREQ_BANDS]

BATCH_SIZE  = 16
EPOCHS      = 100
NUM_FOLDS   = 5
SEED        = 42

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ──────────────── dataset ────────────────
class SpectroDataset(Dataset):
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir

    def __len__(self): return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])          # tensor [C,H,W]
        labels = [[row[v] for v in C50_VARS], [row[v] for v in T60_VARS]]  # shape (2,6)
        y = torch.tensor(list(zip(*labels)), dtype=torch.float32)          # (6,2)
        return x, y

# ──────────────── modelo ────────────────
HEAD_CONFIGS = {f: {"hidden_dim": 64, "lr": 1e-3} for f in FREQUENCIES}

class MultiHeadModel(nn.Module):
    def __init__(self, head_configs=HEAD_CONFIGS):
        super().__init__()
        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
        self.backbone = nn.Sequential(*list(backbone.children())[:-1])     # remove FC
        feat_dim = backbone.fc.in_features
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                    nn.Linear(feat_dim, cfg["hidden_dim"]),
                    nn.ReLU(inplace=True),
                    nn.Linear(cfg["hidden_dim"], 2)   # 2 saídas: C50 e T60
               ) for f, cfg in head_configs.items()
        })

    def forward(self, x):
        feats = self.backbone(x).view(x.size(0), -1)
        return {f: head(feats) for f, head in self.heads.items()}

# ──────────────── leitura de labels ────────────────
print("▶ Lendo labels …")
df = pd.read_csv(LABELS_PATH)
TENSOR_COL = "name"
df["tensor_filename"] = df[TENSOR_COL].str.replace(r"\.wav$", "", regex=True) + ".pt"

existing = {p.name for p in TRAIN_DIR.rglob("*.pt")}
df = df[df["tensor_filename"].isin(existing)].reset_index(drop=True)

before = len(df)
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(subset=C50_VARS + T60_VARS, inplace=True)
print(f"⌦ Removidas {before - len(df)} linhas com targets inválidos")

kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)

# ──────────────── K-Fold ────────────────
for fold, (train_idx, val_idx) in enumerate(kf.split(df), start=1):
    print(f"\n══════════ FOLD {fold}/{NUM_FOLDS} ══════════")
    fold_dir   = MODEL_DIR / f"fold_{fold}"
    ckpt_dir   = fold_dir / "checkpoints"
    scaler_dir = fold_dir / "scalers"
    ckpt_dir.mkdir(parents=True, exist_ok=True)
    scaler_dir.mkdir(parents=True, exist_ok=True)

    train_df, val_df = df.iloc[train_idx].copy(), df.iloc[val_idx].copy()

    # -------- escalonamento --------
    scalers_c50, scalers_t60 = {}, {}
    for var in C50_VARS + T60_VARS:
        scaler = StandardScaler().fit(train_df[[var]])
        pickle.dump(scaler, open(scaler_dir / f"scaler_{var}.pkl", "wb"))
        train_df[var] = scaler.transform(train_df[[var]])
        val_df[var]   = scaler.transform(val_df[[var]])
        band = var.split("_")[1]
        (scalers_c50 if var.startswith("C50") else scalers_t60)[band] = scaler

    train_loader = DataLoader(SpectroDataset(train_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader   = DataLoader(SpectroDataset(val_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    model = MultiHeadModel().to(device)
    criterion = nn.MSELoss()

    param_groups = [{"params": model.backbone.parameters(), "lr": 1e-5, "weight_decay": 1e-4}]
    for f in FREQUENCIES:
        param_groups.append({
            "params": model.heads[f].parameters(),
            "lr": HEAD_CONFIGS[f]["lr"], "weight_decay": 1e-4
        })
    optimizer = optim.Adam(param_groups)

    # -------- retomada --------
    start_epoch = 1
    ckpts = list(ckpt_dir.glob(f"fold{fold}_epoch*.pth"))
    if ckpts:
        last = max(int(p.stem.split("epoch")[1]) for p in ckpts)
        print(f"⇒ Retomando fold {fold} a partir do epoch {last} …")
        model.load_state_dict(torch.load(ckpt_dir / f"fold{fold}_epoch{last}.pth", map_location=device))
        opt_path = ckpt_dir / f"fold{fold}_optim_latest.pth"
        if opt_path.exists():
            optimizer.load_state_dict(torch.load(opt_path, map_location=device))
        start_epoch = last + 1

    # -------- laço de épocas --------
    for epoch in range(start_epoch, EPOCHS + 1):
        # === treino ===
        model.train()
        pred_t, true_t = {f: [] for f in FREQUENCIES}, {f: [] for f in FREQUENCIES}
        loss_sum = 0.0
        for x, y in tqdm(train_loader, desc=f"[Fold {fold}] Train {epoch}/{EPOCHS}", leave=False):
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            outs = model(x)
            for i, f in enumerate(FREQUENCIES):
                pred_t[f].append(outs[f].detach().cpu().numpy())
                true_t[f].append(y[:, i, :].cpu().numpy())
            loss = sum(criterion(outs[f], y[:, i, :]) for i, f in enumerate(FREQUENCIES))
            loss.backward()
            optimizer.step()
            loss_sum += loss.item() * x.size(0)
        train_loss = loss_sum / len(train_loader.dataset)

        # === validação ===
        model.eval()
        pred_v, true_v = {f: [] for f in FREQUENCIES}, {f: [] for f in FREQUENCIES}
        val_loss_sum = 0.0
        with torch.no_grad():
            for x, y in tqdm(val_loader, desc=f"[Fold {fold}] Val {epoch}/{EPOCHS}", leave=False):
                x, y = x.to(device), y.to(device)
                outs = model(x)
                for i, f in enumerate(FREQUENCIES):
                    pred_v[f].append(outs[f].cpu().numpy())
                    true_v[f].append(y[:, i, :].cpu().numpy())
                val_loss_sum += sum(
                    criterion(outs[f], y[:, i, :]).item() * x.size(0)
                    for i, f in enumerate(FREQUENCIES)
                )
        val_loss = val_loss_sum / len(val_loader.dataset)

        # === métricas ===
        def compute_metrics(pred, true, s_c, s_t):
            out = {}
            for f in FREQUENCIES:
                p = np.vstack(pred[f]); t = np.vstack(true[f])
                p_c = s_c[f].inverse_transform(p[:, [0]]).ravel()
                t_c = s_c[f].inverse_transform(t[:, [0]]).ravel()
                p_t = s_t[f].inverse_transform(p[:, [1]]).ravel()
                t_t = s_t[f].inverse_transform(t[:, [1]]).ravel()

                def stats(a, b):
                    return (math.sqrt(mean_squared_error(a, b)),
                            mean_absolute_error(a, b),
                            r2_score(a, b),
                            np.corrcoef(a, b)[0, 1])

                out[f] = {"C50": stats(t_c, p_c), "T60": stats(t_t, p_t)}
            return out

        train_m = compute_metrics(pred_t, true_t, scalers_c50, scalers_t60)
        val_m   = compute_metrics(pred_v, true_v, scalers_c50, scalers_t60)

        # === salvar checkpoints ===
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_epoch{epoch}.pth")
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_latest.pth")
        torch.save(optimizer.state_dict(), ckpt_dir / f"fold{fold}_optim_latest.pth")

        # === logging no terminal ===
        print(f"\n[Fold {fold}] Epoch {epoch}/{EPOCHS} — Train L={train_loss:.4f} | Val L={val_loss:.4f}")
        hdr = "Band | RMSE_t | MAE_t | R2_t  | PCC_t | RMSE_v | MAE_v | R2_v  | PCC_v"
        for var in ("C50", "T60"):
            print(f"─── {var} ───"); print(hdr); print("-" * len(hdr))
            for f in FREQUENCIES:
                rt, mt, r2t, pcct = train_m[f][var]
                rv, mv, r2v, pccv = val_m[f][var]
                print(f"{f:>4} | {rt:6.3f} | {mt:6.3f} | {r2t:6.3f} | {pcct:6.3f} | "
                      f"{rv:6.3f} | {mv:6.3f} | {r2v:6.3f} | {pccv:6.3f}")
        print("=" * 80)

        # === append no CSV ===
        with open(metrics_path, "a", encoding="utf-8") as f_csv:
            for band in FREQUENCIES:
                for var in ("C50", "T60"):
                    rt, mt, r2t, pcct = train_m[band][var]
                    rv, mv, r2v, pccv = val_m[band][var]
                    f_csv.write(f"{fold},{epoch},{band},{var},"
                                f"{rt:.6f},{mt:.6f},{r2t:.6f},{pcct:.6f},"
                                f"{rv:.6f},{mv:.6f},{r2v:.6f},{pccv:.6f}\n")

print("\nTreinamento K-Fold concluído!")

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_multihead_frequency_kfold.py
──────────────────────────────────
• Treina um ResNet-50 multitarefa com cabeças por banda de frequência
  para estimar C50 e T60 em 6 bandas (125-4000 Hz).
• Validação cruzada K-Fold (K=5) com retomada de checkpoint por fold.
• Salva scalers e checkpoints por fold-época.
• Imprime RMSE, MAE, R² e PCC por banda (treino/validação).
• Acumula todas as métricas em CSV sem nunca sobrescrevê-lo.
"""

import os, random, pickle, math
from pathlib import Path
from typing import Dict, Tuple, List

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

# ────────────── caminhos principais ──────────────
TRAIN_DIR = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TREINO_VALID")
LABELS_PATH = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR   = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_mod")
os.makedirs(MODEL_DIR, exist_ok=True)

# ─────────── CSV de métricas (append-only) ───────────
metrics_path = MODEL_DIR / "all_metrics.csv"
header = "fold,epoch,band,var,rmse_t,mae_t,r2_t,pcc_t,rmse_v,mae_v,r2_v,pcc_v\n"
if not metrics_path.exists():          # só cria se ainda não existir
    with open(metrics_path, "w", encoding="utf-8") as f:
        f.write(header)

# ─────────── hiperparâmetros globais ───────────
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQUENCIES = [str(b) for b in FREQ_BANDS]
C50_VARS    = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS    = [f"T60_{b}" for b in FREQ_BANDS]

BATCH_SIZE  = 16
EPOCHS      = 100
NUM_FOLDS   = 5
SEED        = 42

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ──────────────── dataset ────────────────
class SpectroDataset(Dataset):
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir

    def __len__(self): return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])          # tensor [C,H,W]
        labels = [[row[v] for v in C50_VARS], [row[v] for v in T60_VARS]]  # shape (2,6)
        y = torch.tensor(list(zip(*labels)), dtype=torch.float32)          # (6,2)
        return x, y

# ──────────────── modelo ────────────────
HEAD_CONFIGS = {f: {"hidden_dim": 64, "lr": 1e-3} for f in FREQUENCIES}

class MultiHeadModel(nn.Module):
    def __init__(self, head_configs=HEAD_CONFIGS):
        super().__init__()
        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
        self.backbone = nn.Sequential(*list(backbone.children())[:-1])     # remove FC
        feat_dim = backbone.fc.in_features
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                    nn.Linear(feat_dim, cfg["hidden_dim"]),
                    nn.ReLU(inplace=True),
                    nn.Linear(cfg["hidden_dim"], 2)   # 2 saídas: C50 e T60
               ) for f, cfg in head_configs.items()
        })

    def forward(self, x):
        feats = self.backbone(x).view(x.size(0), -1)
        return {f: head(feats) for f, head in self.heads.items()}

# ──────────────── leitura de labels ────────────────
print("▶ Lendo labels …")
df = pd.read_csv(LABELS_PATH)
TENSOR_COL = "name"
df["tensor_filename"] = df[TENSOR_COL].str.replace(r"\.wav$", "", regex=True) + ".pt"

existing = {p.name for p in TRAIN_DIR.rglob("*.pt")}
df = df[df["tensor_filename"].isin(existing)].reset_index(drop=True)

before = len(df)
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(subset=C50_VARS + T60_VARS, inplace=True)
print(f"⌦ Removidas {before - len(df)} linhas com targets inválidos")

kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)

# ──────────────── K-Fold ────────────────
for fold, (train_idx, val_idx) in enumerate(kf.split(df), start=1):
    print(f"\n══════════ FOLD {fold}/{NUM_FOLDS} ══════════")
    fold_dir   = MODEL_DIR / f"fold_{fold}"
    ckpt_dir   = fold_dir / "checkpoints"
    scaler_dir = fold_dir / "scalers"
    ckpt_dir.mkdir(parents=True, exist_ok=True)
    scaler_dir.mkdir(parents=True, exist_ok=True)

    train_df, val_df = df.iloc[train_idx].copy(), df.iloc[val_idx].copy()

    # -------- escalonamento --------
    scalers_c50, scalers_t60 = {}, {}
    for var in C50_VARS + T60_VARS:
        scaler = StandardScaler().fit(train_df[[var]])
        pickle.dump(scaler, open(scaler_dir / f"scaler_{var}.pkl", "wb"))
        train_df[var] = scaler.transform(train_df[[var]])
        val_df[var]   = scaler.transform(val_df[[var]])
        band = var.split("_")[1]
        (scalers_c50 if var.startswith("C50") else scalers_t60)[band] = scaler

    train_loader = DataLoader(SpectroDataset(train_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader   = DataLoader(SpectroDataset(val_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    model = MultiHeadModel().to(device)
    criterion = nn.MSELoss()

    param_groups = [{"params": model.backbone.parameters(), "lr": 1e-5, "weight_decay": 1e-4}]
    for f in FREQUENCIES:
        param_groups.append({
            "params": model.heads[f].parameters(),
            "lr": HEAD_CONFIGS[f]["lr"], "weight_decay": 1e-4
        })
    optimizer = optim.Adam(param_groups)

    # -------- retomada --------
    start_epoch = 1
    ckpts = list(ckpt_dir.glob(f"fold{fold}_epoch*.pth"))
    if ckpts:
        last = max(int(p.stem.split("epoch")[1]) for p in ckpts)
        print(f"⇒ Retomando fold {fold} a partir do epoch {last} …")
        model.load_state_dict(torch.load(ckpt_dir / f"fold{fold}_epoch{last}.pth", map_location=device))
        opt_path = ckpt_dir / f"fold{fold}_optim_latest.pth"
        if opt_path.exists():
            optimizer.load_state_dict(torch.load(opt_path, map_location=device))
        start_epoch = last + 1

    # -------- laço de épocas --------
    for epoch in range(start_epoch, EPOCHS + 1):
        # === treino ===
        model.train()
        pred_t, true_t = {f: [] for f in FREQUENCIES}, {f: [] for f in FREQUENCIES}
        loss_sum = 0.0
        for x, y in tqdm(train_loader, desc=f"[Fold {fold}] Train {epoch}/{EPOCHS}", leave=False):
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            outs = model(x)
            for i, f in enumerate(FREQUENCIES):
                pred_t[f].append(outs[f].detach().cpu().numpy())
                true_t[f].append(y[:, i, :].cpu().numpy())
            loss = sum(criterion(outs[f], y[:, i, :]) for i, f in enumerate(FREQUENCIES))
            loss.backward()
            optimizer.step()
            loss_sum += loss.item() * x.size(0)
        train_loss = loss_sum / len(train_loader.dataset)

        # === validação ===
        model.eval()
        pred_v, true_v = {f: [] for f in FREQUENCIES}, {f: [] for f in FREQUENCIES}
        val_loss_sum = 0.0
        with torch.no_grad():
            for x, y in tqdm(val_loader, desc=f"[Fold {fold}] Val {epoch}/{EPOCHS}", leave=False):
                x, y = x.to(device), y.to(device)
                outs = model(x)
                for i, f in enumerate(FREQUENCIES):
                    pred_v[f].append(outs[f].cpu().numpy())
                    true_v[f].append(y[:, i, :].cpu().numpy())
                val_loss_sum += sum(
                    criterion(outs[f], y[:, i, :]).item() * x.size(0)
                    for i, f in enumerate(FREQUENCIES)
                )
        val_loss = val_loss_sum / len(val_loader.dataset)

        # === métricas ===
        def compute_metrics(pred, true, s_c, s_t):
            out = {}
            for f in FREQUENCIES:
                p = np.vstack(pred[f]); t = np.vstack(true[f])
                p_c = s_c[f].inverse_transform(p[:, [0]]).ravel()
                t_c = s_c[f].inverse_transform(t[:, [0]]).ravel()
                p_t = s_t[f].inverse_transform(p[:, [1]]).ravel()
                t_t = s_t[f].inverse_transform(t[:, [1]]).ravel()

                def stats(a, b):
                    return (math.sqrt(mean_squared_error(a, b)),
                            mean_absolute_error(a, b),
                            r2_score(a, b),
                            np.corrcoef(a, b)[0, 1])

                out[f] = {"C50": stats(t_c, p_c), "T60": stats(t_t, p_t)}
            return out

        train_m = compute_metrics(pred_t, true_t, scalers_c50, scalers_t60)
        val_m   = compute_metrics(pred_v, true_v, scalers_c50, scalers_t60)

        # === salvar checkpoints ===
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_epoch{epoch}.pth")
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_latest.pth")
        torch.save(optimizer.state_dict(), ckpt_dir / f"fold{fold}_optim_latest.pth")

        # === logging no terminal ===
        print(f"\n[Fold {fold}] Epoch {epoch}/{EPOCHS} — Train L={train_loss:.4f} | Val L={val_loss:.4f}")
        hdr = "Band | RMSE_t | MAE_t | R2_t  | PCC_t | RMSE_v | MAE_v | R2_v  | PCC_v"
        for var in ("C50", "T60"):
            print(f"─── {var} ───"); print(hdr); print("-" * len(hdr))
            for f in FREQUENCIES:
                rt, mt, r2t, pcct = train_m[f][var]
                rv, mv, r2v, pccv = val_m[f][var]
                print(f"{f:>4} | {rt:6.3f} | {mt:6.3f} | {r2t:6.3f} | {pcct:6.3f} | "
                      f"{rv:6.3f} | {mv:6.3f} | {r2v:6.3f} | {pccv:6.3f}")
        print("=" * 80)

        # === append no CSV ===
        with open(metrics_path, "a", encoding="utf-8") as f_csv:
            for band in FREQUENCIES:
                for var in ("C50", "T60"):
                    rt, mt, r2t, pcct = train_m[band][var]
                    rv, mv, r2v, pccv = val_m[band][var]
                    f_csv.write(f"{fold},{epoch},{band},{var},"
                                f"{rt:.6f},{mt:.6f},{r2t:.6f},{pcct:.6f},"
                                f"{rv:.6f},{mv:.6f},{r2v:.6f},{pccv:.6f}\n")

print("\nTreinamento K-Fold concluído!")

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_multihead_frequency_kfold.py
─────────────────────────────────
Avalia os 5 modelos (1 por fold) treinados com validação cruzada,
gera métricas (RMSE, MAE, R², PCC) por fold e ensemble,
e grava CSVs de previsões e métricas.
"""
import os, math, pickle
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from tqdm.auto import tqdm
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import scipy.stats as st

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import models

# ────────────────────────── CONFIGURAÇÕES ──────────────────────────
TEST_DIR    = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE")
LABELS_PATH = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR   = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_mod")

NUM_FOLDS   = 5
BATCH_SIZE  = 16
NUM_WORKERS = 0   # evita bug do QueueFeederThread em Python 3.11
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQS       = [str(b) for b in FREQ_BANDS]
C50_VARS    = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS    = [f"T60_{b}" for b in FREQ_BANDS]

RESULTS_FOLD_CSV      = MODEL_DIR / "test_results_por_fold.csv"
RESULTS_ENSEMBLE_CSV  = MODEL_DIR / "test_results_ensemble.csv"
METRICS_FOLD_CSV      = MODEL_DIR / "test_metrics_por_fold.csv"
METRICS_ENSEMBLE_CSV  = MODEL_DIR / "test_metrics_ensemble.csv"

# ─────────────────────────── DATASET ───────────────────────────────
class SpectroTestDataset(Dataset):
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir
    def __len__(self): return len(self.df)
    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])
        return x, row["tensor_filename"]

# ─────────────────────────── MODELO ────────────────────────────────
HEAD_CONFIGS = {f: {"hidden_dim": 64} for f in FREQS}
class MultiHeadModel(nn.Module):
    def __init__(self, head_configs=HEAD_CONFIGS):
        super().__init__()
        backbone = models.resnet50(weights=None)
        self.backbone = nn.Sequential(*list(backbone.children())[:-1])
        feat_dim = backbone.fc.in_features
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, cfg["hidden_dim"]),
                nn.ReLU(inplace=True),
                nn.Linear(cfg["hidden_dim"], 2)
            ) for f, cfg in head_configs.items()
        })
    def forward(self, x):
        feats = self.backbone(x).view(x.size(0), -1)
        return {f: head(feats) for f, head in self.heads.items()}

# ───────────────────────── FUNÇÕES AUXILIARES ──────────────────────
def load_scalers(scaler_dir: Path) -> Tuple[Dict[str, object], Dict[str, object]]:
    sc_c50, sc_t60 = {}, {}
    for b in FREQS:
        sc_c50[b] = pickle.load(open(scaler_dir / f"scaler_C50_{b}.pkl", "rb"))
        sc_t60[b] = pickle.load(open(scaler_dir / f"scaler_T60_{b}.pkl", "rb"))
    return sc_c50, sc_t60

def inverse_scale(preds, scalers):
    """Preds (np.ndarray shape [N,2]) → tuple(C50,T60) já des-normalizados"""
    c50 = scalers[0].inverse_transform(preds[:, [0]]).ravel()
    t60 = scalers[1].inverse_transform(preds[:, [1]]).ravel()
    return c50, t60

def metrics(y_true, y_pred):
    rmse = math.sqrt(mean_squared_error(y_true, y_pred))
    mae  = mean_absolute_error(y_true, y_pred)
    r2   = r2_score(y_true, y_pred)
    pcc  = st.pearsonr(y_true, y_pred)[0] if len(y_true) > 1 else np.nan
    return rmse, mae, r2, pcc

# ─────────────────────────── MAIN ──────────────────────────────────
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    MODEL_DIR.mkdir(parents=True, exist_ok=True)

    # cabeçalhos CSV se ainda não existem
    if not METRICS_FOLD_CSV.exists():
        METRICS_FOLD_CSV.write_text("fold,band,var,rmse,mae,r2,pcc\n")
    if not METRICS_ENSEMBLE_CSV.exists():
        METRICS_ENSEMBLE_CSV.write_text("band,var,rmse,mae,r2,pcc\n")

    # ----- carregar labels -----
    df = pd.read_csv(LABELS_PATH)
    df["tensor_filename"] = df["name"].str.replace(r"\.wav$", "", regex=True) + ".pt"
    test_pt = {p.name for p in TEST_DIR.rglob("*.pt")}
    df = df[df["tensor_filename"].isin(test_pt)].reset_index(drop=True)
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.dropna(subset=C50_VARS + T60_VARS, inplace=True)
    print(f"→ {len(df)} amostras de teste encontradas.")

    loader = DataLoader(SpectroTestDataset(df, TEST_DIR),
                        batch_size=BATCH_SIZE,
                        shuffle=False,
                        num_workers=NUM_WORKERS)

    # containers [fold][band][var] -> list
    preds_fold = [
        {b: {"C50": [], "T60": []} for b in FREQS}
        for _ in range(NUM_FOLDS)
    ]

    # ----- loop pelos folds -----
    for fold in range(1, NUM_FOLDS + 1):
        print(f"\n════ Avaliando FOLD {fold}/{NUM_FOLDS} ════")
        fold_dir   = MODEL_DIR / f"fold_{fold}"
        ckpt_dir   = fold_dir / "checkpoints"
        scaler_dir = fold_dir / "scalers"

        # carregamento de scalers
        sc_c50, sc_t60 = load_scalers(scaler_dir)

        # carregamento de modelo
        model = MultiHeadModel().to(device)
        ckpt_path = ckpt_dir / f"fold{fold}_latest.pth"
        if not ckpt_path.exists():
            all_ckpt = list(ckpt_dir.glob(f"fold{fold}_epoch*.pth"))
            if not all_ckpt:
                raise FileNotFoundError(f"Nenhum checkpoint em {ckpt_dir}")
            ckpt_path = max(all_ckpt, key=lambda p: int(p.stem.split("epoch")[1]))
        model.load_state_dict(torch.load(ckpt_path, map_location=device))
        model.eval()
        print(f"  Checkpoint carregado: {ckpt_path.name}")

        # inferência
        pointer = 0
        with torch.no_grad():
            for x, _ in tqdm(loader, desc=f"Inferência Fold {fold}", leave=False):
                bs = x.size(0)
                x = x.to(device)
                outs = model(x)                     # dict banda→(bs,2)
                for i, b in enumerate(FREQS):
                    preds = outs[b].cpu().numpy()
                    p_c50, p_t60 = inverse_scale(preds, (sc_c50[b], sc_t60[b]))
                    preds_fold[fold-1][b]["C50"].extend(p_c50.tolist())
                    preds_fold[fold-1][b]["T60"].extend(p_t60.tolist())
                pointer += bs

        # métricas do fold
        print("→ Métricas por banda (RMSE | MAE | R² | PCC):")
        with open(METRICS_FOLD_CSV, "a") as f_csv:
            for b in FREQS:
                for var in ("C50", "T60"):
                    y_true = df[f"{var}_{b}"].values
                    y_pred = preds_fold[fold-1][b][var]
                    rmse, mae, r2, pcc = metrics(y_true, y_pred)
                    print(f" {var}_{b}: {rmse:.4f} | {mae:.4f} | {r2:.4f} | {pcc:.4f}")
                    f_csv.write(f"{fold},{b},{var},{rmse:.6f},{mae:.6f},{r2:.6f},{pcc:.6f}\n")

    # ---------- ensemble (média dos 5 folds) ----------
    print("\n════ Métricas do ENSEMBLE (média simples) ════")
    ensemble_preds = {b: {"C50": [], "T60": []} for b in FREQS}
    for idx in range(len(df)):  # amostra a amostra
        for b in FREQS:
            ensemble_preds[b]["C50"].append(np.mean([preds_fold[f][b]["C50"][idx] for f in range(NUM_FOLDS)]))
            ensemble_preds[b]["T60"].append(np.mean([preds_fold[f][b]["T60"][idx] for f in range(NUM_FOLDS)]))

    with open(METRICS_ENSEMBLE_CSV, "a") as f_csv:
        for b in FREQS:
            for var in ("C50", "T60"):
                y_true = df[f"{var}_{b}"].values
                y_pred = ensemble_preds[b][var]
                rmse, mae, r2, pcc = metrics(y_true, y_pred)
                print(f" {var}_{b}: {rmse:.4f} | {mae:.4f} | {r2:.4f} | {pcc:.4f}")
                f_csv.write(f"{b},{var},{rmse:.6f},{mae:.6f},{r2:.6f},{pcc:.6f}\n")

    # ---------- salvar CSVs de previsões ----------
    # por fold
    results_fold = {"name": df["tensor_filename"]}
    for fold in range(NUM_FOLDS):
        for b in FREQS:
            results_fold[f"C50_{b}_pred_fold{fold+1}"] = preds_fold[fold][b]["C50"]
            results_fold[f"T60_{b}_pred_fold{fold+1}"] = preds_fold[fold][b]["T60"]
    pd.DataFrame(results_fold).to_csv(RESULTS_FOLD_CSV, index=False)
    print(f"\nCSV por-fold salvo em: {RESULTS_FOLD_CSV}")

    # ensemble
    results_ens = {"name": df["tensor_filename"]}
    for b in FREQS:
        results_ens[f"C50_{b}_REAL"] = df[f"C50_{b}"]
        results_ens[f"T60_{b}_REAL"] = df[f"T60_{b}"]
        results_ens[f"C50_{b}_PRED"] = ensemble_preds[b]["C50"]
        results_ens[f"T60_{b}_PRED"] = ensemble_preds[b]["T60"]
    pd.DataFrame(results_ens).to_csv(RESULTS_ENSEMBLE_CSV, index=False)
    print(f"CSV ensemble salvo em: {RESULTS_ENSEMBLE_CSV}\n")

if __name__ == "__main__":
    main()

"""TESTANDO COM MÉTRICAS DE DESEMPENHO"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_multihead_frequency_kfold.py
─────────────────────────────────
Avalia os 5 modelos (1 por fold) treinados com validação cruzada,
gera métricas (RMSE, MAE, R², PCC) por fold e ensemble,
grava CSVs de previsões e métricas e mede performance.
"""
import os
import time
import tracemalloc
import psutil
import math
import pickle
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from tqdm.auto import tqdm
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import scipy.stats as st

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import models

# ────────────────────────── CONFIGURAÇÕES ──────────────────────────
TEST_DIR    = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE")
LABELS_PATH = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR   = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_mod")

NUM_FOLDS   = 5
BATCH_SIZE  = 16
NUM_WORKERS = 0   # evita bug do QueueFeederThread em Python 3.11
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQS       = [str(b) for b in FREQ_BANDS]
C50_VARS    = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS    = [f"T60_{b}" for b in FREQ_BANDS]

RESULTS_FOLD_CSV     = MODEL_DIR / "test_results_por_fold.csv"
RESULTS_ENSEMBLE_CSV = MODEL_DIR / "test_results_ensemble.csv"
METRICS_FOLD_CSV     = MODEL_DIR / "test_metrics_por_fold.csv"
METRICS_ENSEMBLE_CSV = MODEL_DIR / "test_metrics_ensemble.csv"

# ─────────────────────────── DATASET ───────────────────────────────
class SpectroTestDataset(Dataset):
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir
    def __len__(self):
        return len(self.df)
    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])
        return x, row["tensor_filename"]

# ─────────────────────────── MODELO ────────────────────────────────
HEAD_CONFIGS = {f: {"hidden_dim": 64} for f in FREQS}
class MultiHeadModel(nn.Module):
    def __init__(self, head_configs=HEAD_CONFIGS):
        super().__init__()
        backbone = models.resnet50(weights=None)
        self.backbone = nn.Sequential(*list(backbone.children())[:-1])
        feat_dim = backbone.fc.in_features
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, cfg["hidden_dim"]),
                nn.ReLU(inplace=True),
                nn.Linear(cfg["hidden_dim"], 2)
            ) for f, cfg in head_configs.items()
        })
    def forward(self, x):
        feats = self.backbone(x).view(x.size(0), -1)
        return {f: head(feats) for f, head in self.heads.items()}

# ───────────────────────── FUNÇÕES AUXILIARES ──────────────────────
def load_scalers(scaler_dir: Path) -> Tuple[Dict[str, object], Dict[str, object]]:
    sc_c50, sc_t60 = {}, {}
    for b in FREQS:
        sc_c50[b] = pickle.load(open(scaler_dir / f"scaler_C50_{b}.pkl", "rb"))
        sc_t60[b] = pickle.load(open(scaler_dir / f"scaler_T60_{b}.pkl", "rb"))
    return sc_c50, sc_t60

def inverse_scale(preds: np.ndarray, scalers):
    """Preds (np.ndarray shape [N,2]) → tuple(C50,T60) já des-normalizados"""
    c50 = scalers[0].inverse_transform(preds[:, [0]]).ravel()
    t60 = scalers[1].inverse_transform(preds[:, [1]]).ravel()
    return c50, t60

def metrics(y_true, y_pred):
    rmse = math.sqrt(mean_squared_error(y_true, y_pred))
    mae  = mean_absolute_error(y_true, y_pred)
    r2   = r2_score(y_true, y_pred)
    pcc  = st.pearsonr(y_true, y_pred)[0] if len(y_true) > 1 else np.nan
    return rmse, mae, r2, pcc

# ─────────────────────────── MAIN ──────────────────────────────────
def main():
    # 1) Inicia medições de performance
    start_time        = time.time()
    tracemalloc.start()
    process           = psutil.Process(os.getpid())
    cpu_percent_start = psutil.cpu_percent(interval=None)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    MODEL_DIR.mkdir(parents=True, exist_ok=True)

    # cabeçalhos CSV
    if not METRICS_FOLD_CSV.exists():
        METRICS_FOLD_CSV.write_text("fold,band,var,rmse,mae,r2,pcc\n")
    if not METRICS_ENSEMBLE_CSV.exists():
        METRICS_ENSEMBLE_CSV.write_text("band,var,rmse,mae,r2,pcc\n")

    # carregar labels e filtrar tensores
    df = pd.read_csv(LABELS_PATH)
    df["tensor_filename"] = df["name"].str.replace(r"\.wav$", "", regex=True) + ".pt"
    test_pt = {p.name for p in TEST_DIR.rglob("*.pt")}
    df = df[df["tensor_filename"].isin(test_pt)].reset_index(drop=True)
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.dropna(subset=C50_VARS + T60_VARS, inplace=True)
    print(f"→ {len(df)} amostras de teste encontradas.")

    loader = DataLoader(
        SpectroTestDataset(df, TEST_DIR),
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=NUM_WORKERS
    )

    # prepara container de previsões
    preds_fold = [
        {b: {"C50": [], "T60": []} for b in FREQS}
        for _ in range(NUM_FOLDS)
    ]

    # loop folds
    for fold in range(1, NUM_FOLDS + 1):
        print(f"\n════ Avaliando FOLD {fold}/{NUM_FOLDS} ════")
        fold_dir   = MODEL_DIR / f"fold_{fold}"
        ckpt_dir   = fold_dir / "checkpoints"
        scaler_dir = fold_dir / "scalers"

        sc_c50, sc_t60 = load_scalers(scaler_dir)

        model = MultiHeadModel().to(device)
        ckpt_path = ckpt_dir / f"fold{fold}_latest.pth"
        if not ckpt_path.exists():
            all_ckpt = sorted(ckpt_dir.glob(f"fold{fold}_epoch*.pth"),
                              key=lambda p: int(p.stem.split("epoch")[1]))
            if not all_ckpt:
                raise FileNotFoundError(f"Nenhum checkpoint em {ckpt_dir}")
            ckpt_path = all_ckpt[-1]
        model.load_state_dict(torch.load(ckpt_path, map_location=device))
        model.eval()
        print(f"  Checkpoint carregado: {ckpt_path.name}")

        # inferência
        with torch.no_grad():
            for x, _ in tqdm(loader, desc=f"Inferência Fold {fold}", leave=False):
                x = x.to(device)
                outs = model(x)  # dict banda->(bs,2)
                for i, b in enumerate(FREQS):
                    preds = outs[b].cpu().numpy()
                    p_c50, p_t60 = inverse_scale(preds, (sc_c50[b], sc_t60[b]))
                    preds_fold[fold-1][b]["C50"].extend(p_c50.tolist())
                    preds_fold[fold-1][b]["T60"].extend(p_t60.tolist())

        # métricas por banda
        with open(METRICS_FOLD_CSV, "a") as f_csv:
            for b in FREQS:
                for var in ("C50", "T60"):
                    y_true = df[f"{var}_{b}"].values
                    y_pred = preds_fold[fold-1][b][var]
                    rmse, mae, r2, pcc = metrics(y_true, y_pred)
                    print(f" {var}_{b}: {rmse:.4f} | {mae:.4f} | {r2:.4f} | {pcc:.4f}")
                    f_csv.write(f"{fold},{b},{var},{rmse:.6f},{mae:.6f},{r2:.6f},{pcc:.6f}\n")

    # ensemble (média dos 5 folds)
    print("\n════ Métricas do ENSEMBLE (média simples) ════")
    ensemble_preds = {b: {"C50": [], "T60": []} for b in FREQS}
    for idx in range(len(df)):
        for b in FREQS:
            ensemble_preds[b]["C50"].append(
                np.mean([preds_fold[f][b]["C50"][idx] for f in range(NUM_FOLDS)])
            )
            ensemble_preds[b]["T60"].append(
                np.mean([preds_fold[f][b]["T60"][idx] for f in range(NUM_FOLDS)])
            )

    with open(METRICS_ENSEMBLE_CSV, "a") as f_csv:
        for b in FREQS:
            for var in ("C50", "T60"):
                y_true = df[f"{var}_{b}"].values
                y_pred = ensemble_preds[b][var]
                rmse, mae, r2, pcc = metrics(y_true, y_pred)
                print(f" {var}_{b}: {rmse:.4f} | {mae:.4f} | {r2:.4f} | {pcc:.4f}")
                f_csv.write(f"{b},{var},{rmse:.6f},{mae:.6f},{r2:.6f},{pcc:.6f}\n")

    # grava CSVs de previsões
    results_fold = {"name": df["tensor_filename"]}
    for fold in range(NUM_FOLDS):
        for b in FREQS:
            results_fold[f"C50_{b}_pred_fold{fold+1}"] = preds_fold[fold][b]["C50"]
            results_fold[f"T60_{b}_pred_fold{fold+1}"] = preds_fold[fold][b]["T60"]
    pd.DataFrame(results_fold).to_csv(RESULTS_FOLD_CSV, index=False)
    print(f"\nCSV por-fold salvo em: {RESULTS_FOLD_CSV}")

    results_ens = {"name": df["tensor_filename"]}
    for b in FREQS:
        results_ens[f"C50_{b}_REAL"] = df[f"C50_{b}"]
        results_ens[f"T60_{b}_REAL"] = df[f"T60_{b}"]
        results_ens[f"C50_{b}_PRED"] = ensemble_preds[b]["C50"]
        results_ens[f"T60_{b}_PRED"] = ensemble_preds[b]["T60"]
    pd.DataFrame(results_ens).to_csv(RESULTS_ENSEMBLE_CSV, index=False)
    print(f"CSV ensemble salvo em: {RESULTS_ENSEMBLE_CSV}\n")

    # 2) Finaliza medições de performance
    cpu_percent_end = psutil.cpu_percent(interval=None)
    _, peak_memory  = tracemalloc.get_traced_memory()
    tracemalloc.stop()
    end_time        = time.time()

    # 3) Tamanho do arquivo do último checkpoint
    last_ckpt = MODEL_DIR / f"fold_{NUM_FOLDS}/checkpoints/fold{NUM_FOLDS}_latest.pth"
    if not last_ckpt.exists():
        raise FileNotFoundError(f"Checkpoint não encontrado: {last_ckpt}")
    model_file_size_kb = os.path.getsize(last_ckpt) / 1024

    # 4) Impressão final
    print("\n–––––––––––––––––––––––––––––––––––––––––––––")
    print(f"Evaluation Time:        {end_time - start_time:.4f} seconds")
    print(f"Peak Memory Usage:      {peak_memory / (1024 * 1024):.2f} MB")
    print(f"Average CPU Usage:      {(cpu_percent_start + cpu_percent_end) / 2:.2f}%")
    print(f"Model File Size:        {model_file_size_kb:.2f} KB")
    print("–––––––––––––––––––––––––––––––––––––––––––––\n")

if __name__ == "__main__":
    main()

"""## TREINANDO LOG-MEL - 1R"""

from google.colab import drive
drive.mount('/content/drive')

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_multihead_frequency_kfold.py
──────────────────────────────────
• Treina um ResNet-50 multitarefa com cabeças por banda de frequência
  para estimar C50 e T60 em 6 bandas (125-4000 Hz).
• Validação cruzada K-Fold (K=5) com retomada de checkpoint por fold.
• Salva scalers e checkpoints por fold-época.
• Imprime RMSE, MAE, R² e PCC por banda (treino/validação).
• Acumula todas as métricas em CSV sem nunca sobrescrevê-lo.
"""

import os, random, pickle, math
from pathlib import Path
from typing import Dict, Tuple, List

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

# ────────────── caminhos principais ──────────────
TRAIN_DIR = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/1R/log_mel_MOD_PASTA_UNICA_TREINO_VALID")
LABELS_PATH = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR   = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_1R_mod")
os.makedirs(MODEL_DIR, exist_ok=True)

# ─────────── CSV de métricas (append-only) ───────────
metrics_path = MODEL_DIR / "all_metrics.csv"
header = "fold,epoch,band,var,rmse_t,mae_t,r2_t,pcc_t,rmse_v,mae_v,r2_v,pcc_v\n"
if not metrics_path.exists():          # só cria se ainda não existir
    with open(metrics_path, "w", encoding="utf-8") as f:
        f.write(header)

# ─────────── hiperparâmetros globais ───────────
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQUENCIES = [str(b) for b in FREQ_BANDS]
C50_VARS    = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS    = [f"T60_{b}" for b in FREQ_BANDS]

BATCH_SIZE  = 16
EPOCHS      = 100
NUM_FOLDS   = 5
SEED        = 42

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ──────────────── dataset ────────────────
class SpectroDataset(Dataset):
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir

    def __len__(self): return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])          # tensor [C,H,W]
        labels = [[row[v] for v in C50_VARS], [row[v] for v in T60_VARS]]  # shape (2,6)
        y = torch.tensor(list(zip(*labels)), dtype=torch.float32)          # (6,2)
        return x, y

# ──────────────── modelo ────────────────
HEAD_CONFIGS = {f: {"hidden_dim": 64, "lr": 1e-3} for f in FREQUENCIES}

class MultiHeadModel(nn.Module):
    def __init__(self, head_configs=HEAD_CONFIGS):
        super().__init__()
        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
        self.backbone = nn.Sequential(*list(backbone.children())[:-1])     # remove FC
        feat_dim = backbone.fc.in_features
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                    nn.Linear(feat_dim, cfg["hidden_dim"]),
                    nn.ReLU(inplace=True),
                    nn.Linear(cfg["hidden_dim"], 2)   # 2 saídas: C50 e T60
               ) for f, cfg in head_configs.items()
        })

    def forward(self, x):
        feats = self.backbone(x).view(x.size(0), -1)
        return {f: head(feats) for f, head in self.heads.items()}

# ──────────────── leitura de labels ────────────────
print("▶ Lendo labels …")
df = pd.read_csv(LABELS_PATH)
TENSOR_COL = "name"
df["tensor_filename"] = df[TENSOR_COL].str.replace(r"\.wav$", "", regex=True) + ".pt"

existing = {p.name for p in TRAIN_DIR.rglob("*.pt")}
df = df[df["tensor_filename"].isin(existing)].reset_index(drop=True)

before = len(df)
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(subset=C50_VARS + T60_VARS, inplace=True)
print(f"⌦ Removidas {before - len(df)} linhas com targets inválidos")

kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)

# ──────────────── K-Fold ────────────────
for fold, (train_idx, val_idx) in enumerate(kf.split(df), start=1):
    print(f"\n══════════ FOLD {fold}/{NUM_FOLDS} ══════════")
    fold_dir   = MODEL_DIR / f"fold_{fold}"
    ckpt_dir   = fold_dir / "checkpoints"
    scaler_dir = fold_dir / "scalers"
    ckpt_dir.mkdir(parents=True, exist_ok=True)
    scaler_dir.mkdir(parents=True, exist_ok=True)

    train_df, val_df = df.iloc[train_idx].copy(), df.iloc[val_idx].copy()

    # -------- escalonamento --------
    scalers_c50, scalers_t60 = {}, {}
    for var in C50_VARS + T60_VARS:
        scaler = StandardScaler().fit(train_df[[var]])
        pickle.dump(scaler, open(scaler_dir / f"scaler_{var}.pkl", "wb"))
        train_df[var] = scaler.transform(train_df[[var]])
        val_df[var]   = scaler.transform(val_df[[var]])
        band = var.split("_")[1]
        (scalers_c50 if var.startswith("C50") else scalers_t60)[band] = scaler

    train_loader = DataLoader(SpectroDataset(train_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader   = DataLoader(SpectroDataset(val_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    model = MultiHeadModel().to(device)
    criterion = nn.MSELoss()

    param_groups = [{"params": model.backbone.parameters(), "lr": 1e-5, "weight_decay": 1e-4}]
    for f in FREQUENCIES:
        param_groups.append({
            "params": model.heads[f].parameters(),
            "lr": HEAD_CONFIGS[f]["lr"], "weight_decay": 1e-4
        })
    optimizer = optim.Adam(param_groups)

    # -------- retomada --------
    start_epoch = 1
    ckpts = list(ckpt_dir.glob(f"fold{fold}_epoch*.pth"))
    if ckpts:
        last = max(int(p.stem.split("epoch")[1]) for p in ckpts)
        print(f"⇒ Retomando fold {fold} a partir do epoch {last} …")
        model.load_state_dict(torch.load(ckpt_dir / f"fold{fold}_epoch{last}.pth", map_location=device))
        opt_path = ckpt_dir / f"fold{fold}_optim_latest.pth"
        if opt_path.exists():
            optimizer.load_state_dict(torch.load(opt_path, map_location=device))
        start_epoch = last + 1

    # -------- laço de épocas --------
    for epoch in range(start_epoch, EPOCHS + 1):
        # === treino ===
        model.train()
        pred_t, true_t = {f: [] for f in FREQUENCIES}, {f: [] for f in FREQUENCIES}
        loss_sum = 0.0
        for x, y in tqdm(train_loader, desc=f"[Fold {fold}] Train {epoch}/{EPOCHS}", leave=False):
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            outs = model(x)
            for i, f in enumerate(FREQUENCIES):
                pred_t[f].append(outs[f].detach().cpu().numpy())
                true_t[f].append(y[:, i, :].cpu().numpy())
            loss = sum(criterion(outs[f], y[:, i, :]) for i, f in enumerate(FREQUENCIES))
            loss.backward()
            optimizer.step()
            loss_sum += loss.item() * x.size(0)
        train_loss = loss_sum / len(train_loader.dataset)

        # === validação ===
        model.eval()
        pred_v, true_v = {f: [] for f in FREQUENCIES}, {f: [] for f in FREQUENCIES}
        val_loss_sum = 0.0
        with torch.no_grad():
            for x, y in tqdm(val_loader, desc=f"[Fold {fold}] Val {epoch}/{EPOCHS}", leave=False):
                x, y = x.to(device), y.to(device)
                outs = model(x)
                for i, f in enumerate(FREQUENCIES):
                    pred_v[f].append(outs[f].cpu().numpy())
                    true_v[f].append(y[:, i, :].cpu().numpy())
                val_loss_sum += sum(
                    criterion(outs[f], y[:, i, :]).item() * x.size(0)
                    for i, f in enumerate(FREQUENCIES)
                )
        val_loss = val_loss_sum / len(val_loader.dataset)

        # === métricas ===
        def compute_metrics(pred, true, s_c, s_t):
            out = {}
            for f in FREQUENCIES:
                p = np.vstack(pred[f]); t = np.vstack(true[f])
                p_c = s_c[f].inverse_transform(p[:, [0]]).ravel()
                t_c = s_c[f].inverse_transform(t[:, [0]]).ravel()
                p_t = s_t[f].inverse_transform(p[:, [1]]).ravel()
                t_t = s_t[f].inverse_transform(t[:, [1]]).ravel()

                def stats(a, b):
                    return (math.sqrt(mean_squared_error(a, b)),
                            mean_absolute_error(a, b),
                            r2_score(a, b),
                            np.corrcoef(a, b)[0, 1])

                out[f] = {"C50": stats(t_c, p_c), "T60": stats(t_t, p_t)}
            return out

        train_m = compute_metrics(pred_t, true_t, scalers_c50, scalers_t60)
        val_m   = compute_metrics(pred_v, true_v, scalers_c50, scalers_t60)

        # === salvar checkpoints ===
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_epoch{epoch}.pth")
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_latest.pth")
        torch.save(optimizer.state_dict(), ckpt_dir / f"fold{fold}_optim_latest.pth")

        # === logging no terminal ===
        print(f"\n[Fold {fold}] Epoch {epoch}/{EPOCHS} — Train L={train_loss:.4f} | Val L={val_loss:.4f}")
        hdr = "Band | RMSE_t | MAE_t | R2_t  | PCC_t | RMSE_v | MAE_v | R2_v  | PCC_v"
        for var in ("C50", "T60"):
            print(f"─── {var} ───"); print(hdr); print("-" * len(hdr))
            for f in FREQUENCIES:
                rt, mt, r2t, pcct = train_m[f][var]
                rv, mv, r2v, pccv = val_m[f][var]
                print(f"{f:>4} | {rt:6.3f} | {mt:6.3f} | {r2t:6.3f} | {pcct:6.3f} | "
                      f"{rv:6.3f} | {mv:6.3f} | {r2v:6.3f} | {pccv:6.3f}")
        print("=" * 80)

        # === append no CSV ===
        with open(metrics_path, "a", encoding="utf-8") as f_csv:
            for band in FREQUENCIES:
                for var in ("C50", "T60"):
                    rt, mt, r2t, pcct = train_m[band][var]
                    rv, mv, r2v, pccv = val_m[band][var]
                    f_csv.write(f"{fold},{epoch},{band},{var},"
                                f"{rt:.6f},{mt:.6f},{r2t:.6f},{pcct:.6f},"
                                f"{rv:.6f},{mv:.6f},{r2v:.6f},{pccv:.6f}\n")

print("\nTreinamento K-Fold concluído!")

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_multihead_frequency_kfold.py
─────────────────────────────────
Avalia os 5 modelos (1 por fold) treinados com validação cruzada,
gera métricas (RMSE, MAE, R², PCC) por fold e ensemble,
grava CSVs de previsões e métricas e mede performance.
"""
import os
import time
import tracemalloc
import psutil
import math
import pickle
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from tqdm.auto import tqdm
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import scipy.stats as st

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import models

# ────────────────────────── CONFIGURAÇÕES ──────────────────────────
TEST_DIR    = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/1R/log_mel_MOD_PASTA_UNICA_TESTE")
LABELS_PATH = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR   = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_1R_mod")

NUM_FOLDS   = 5
BATCH_SIZE  = 16
NUM_WORKERS = 0   # evita bug do QueueFeederThread em Python 3.11
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQS       = [str(b) for b in FREQ_BANDS]
C50_VARS    = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS    = [f"T60_{b}" for b in FREQ_BANDS]

RESULTS_FOLD_CSV     = MODEL_DIR / "test_results_por_fold.csv"
RESULTS_ENSEMBLE_CSV = MODEL_DIR / "test_results_ensemble.csv"
METRICS_FOLD_CSV     = MODEL_DIR / "test_metrics_por_fold.csv"
METRICS_ENSEMBLE_CSV = MODEL_DIR / "test_metrics_ensemble.csv"

# ─────────────────────────── DATASET ───────────────────────────────
class SpectroTestDataset(Dataset):
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir
    def __len__(self):
        return len(self.df)
    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])
        return x, row["tensor_filename"]

# ─────────────────────────── MODELO ────────────────────────────────
HEAD_CONFIGS = {f: {"hidden_dim": 64} for f in FREQS}
class MultiHeadModel(nn.Module):
    def __init__(self, head_configs=HEAD_CONFIGS):
        super().__init__()
        backbone = models.resnet50(weights=None)
        self.backbone = nn.Sequential(*list(backbone.children())[:-1])
        feat_dim = backbone.fc.in_features
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, cfg["hidden_dim"]),
                nn.ReLU(inplace=True),
                nn.Linear(cfg["hidden_dim"], 2)
            ) for f, cfg in head_configs.items()
        })
    def forward(self, x):
        feats = self.backbone(x).view(x.size(0), -1)
        return {f: head(feats) for f, head in self.heads.items()}

# ───────────────────────── FUNÇÕES AUXILIARES ──────────────────────
def load_scalers(scaler_dir: Path) -> Tuple[Dict[str, object], Dict[str, object]]:
    sc_c50, sc_t60 = {}, {}
    for b in FREQS:
        sc_c50[b] = pickle.load(open(scaler_dir / f"scaler_C50_{b}.pkl", "rb"))
        sc_t60[b] = pickle.load(open(scaler_dir / f"scaler_T60_{b}.pkl", "rb"))
    return sc_c50, sc_t60

def inverse_scale(preds: np.ndarray, scalers):
    """Preds (np.ndarray shape [N,2]) → tuple(C50,T60) já des-normalizados"""
    c50 = scalers[0].inverse_transform(preds[:, [0]]).ravel()
    t60 = scalers[1].inverse_transform(preds[:, [1]]).ravel()
    return c50, t60

def metrics(y_true, y_pred):
    rmse = math.sqrt(mean_squared_error(y_true, y_pred))
    mae  = mean_absolute_error(y_true, y_pred)
    r2   = r2_score(y_true, y_pred)
    pcc  = st.pearsonr(y_true, y_pred)[0] if len(y_true) > 1 else np.nan
    return rmse, mae, r2, pcc

# ─────────────────────────── MAIN ──────────────────────────────────
def main():
    # 1) Inicia medições de performance
    start_time        = time.time()
    tracemalloc.start()
    process           = psutil.Process(os.getpid())
    cpu_percent_start = psutil.cpu_percent(interval=None)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    MODEL_DIR.mkdir(parents=True, exist_ok=True)

    # cabeçalhos CSV
    if not METRICS_FOLD_CSV.exists():
        METRICS_FOLD_CSV.write_text("fold,band,var,rmse,mae,r2,pcc\n")
    if not METRICS_ENSEMBLE_CSV.exists():
        METRICS_ENSEMBLE_CSV.write_text("band,var,rmse,mae,r2,pcc\n")

    # carregar labels e filtrar tensores
    df = pd.read_csv(LABELS_PATH)
    df["tensor_filename"] = df["name"].str.replace(r"\.wav$", "", regex=True) + ".pt"
    test_pt = {p.name for p in TEST_DIR.rglob("*.pt")}
    df = df[df["tensor_filename"].isin(test_pt)].reset_index(drop=True)
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.dropna(subset=C50_VARS + T60_VARS, inplace=True)
    print(f"→ {len(df)} amostras de teste encontradas.")

    loader = DataLoader(
        SpectroTestDataset(df, TEST_DIR),
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=NUM_WORKERS
    )

    # prepara container de previsões
    preds_fold = [
        {b: {"C50": [], "T60": []} for b in FREQS}
        for _ in range(NUM_FOLDS)
    ]

    # loop folds
    for fold in range(1, NUM_FOLDS + 1):
        print(f"\n════ Avaliando FOLD {fold}/{NUM_FOLDS} ════")
        fold_dir   = MODEL_DIR / f"fold_{fold}"
        ckpt_dir   = fold_dir / "checkpoints"
        scaler_dir = fold_dir / "scalers"

        sc_c50, sc_t60 = load_scalers(scaler_dir)

        model = MultiHeadModel().to(device)
        ckpt_path = ckpt_dir / f"fold{fold}_latest.pth"
        if not ckpt_path.exists():
            all_ckpt = sorted(ckpt_dir.glob(f"fold{fold}_epoch*.pth"),
                              key=lambda p: int(p.stem.split("epoch")[1]))
            if not all_ckpt:
                raise FileNotFoundError(f"Nenhum checkpoint em {ckpt_dir}")
            ckpt_path = all_ckpt[-1]
        model.load_state_dict(torch.load(ckpt_path, map_location=device))
        model.eval()
        print(f"  Checkpoint carregado: {ckpt_path.name}")

        # inferência
        with torch.no_grad():
            for x, _ in tqdm(loader, desc=f"Inferência Fold {fold}", leave=False):
                x = x.to(device)
                outs = model(x)  # dict banda->(bs,2)
                for i, b in enumerate(FREQS):
                    preds = outs[b].cpu().numpy()
                    p_c50, p_t60 = inverse_scale(preds, (sc_c50[b], sc_t60[b]))
                    preds_fold[fold-1][b]["C50"].extend(p_c50.tolist())
                    preds_fold[fold-1][b]["T60"].extend(p_t60.tolist())

        # métricas por banda
        with open(METRICS_FOLD_CSV, "a") as f_csv:
            for b in FREQS:
                for var in ("C50", "T60"):
                    y_true = df[f"{var}_{b}"].values
                    y_pred = preds_fold[fold-1][b][var]
                    rmse, mae, r2, pcc = metrics(y_true, y_pred)
                    print(f" {var}_{b}: {rmse:.4f} | {mae:.4f} | {r2:.4f} | {pcc:.4f}")
                    f_csv.write(f"{fold},{b},{var},{rmse:.6f},{mae:.6f},{r2:.6f},{pcc:.6f}\n")

    # ensemble (média dos 5 folds)
    print("\n════ Métricas do ENSEMBLE (média simples) ════")
    ensemble_preds = {b: {"C50": [], "T60": []} for b in FREQS}
    for idx in range(len(df)):
        for b in FREQS:
            ensemble_preds[b]["C50"].append(
                np.mean([preds_fold[f][b]["C50"][idx] for f in range(NUM_FOLDS)])
            )
            ensemble_preds[b]["T60"].append(
                np.mean([preds_fold[f][b]["T60"][idx] for f in range(NUM_FOLDS)])
            )

    with open(METRICS_ENSEMBLE_CSV, "a") as f_csv:
        for b in FREQS:
            for var in ("C50", "T60"):
                y_true = df[f"{var}_{b}"].values
                y_pred = ensemble_preds[b][var]
                rmse, mae, r2, pcc = metrics(y_true, y_pred)
                print(f" {var}_{b}: {rmse:.4f} | {mae:.4f} | {r2:.4f} | {pcc:.4f}")
                f_csv.write(f"{b},{var},{rmse:.6f},{mae:.6f},{r2:.6f},{pcc:.6f}\n")

    # grava CSVs de previsões
    results_fold = {"name": df["tensor_filename"]}
    for fold in range(NUM_FOLDS):
        for b in FREQS:
            results_fold[f"C50_{b}_pred_fold{fold+1}"] = preds_fold[fold][b]["C50"]
            results_fold[f"T60_{b}_pred_fold{fold+1}"] = preds_fold[fold][b]["T60"]
    pd.DataFrame(results_fold).to_csv(RESULTS_FOLD_CSV, index=False)
    print(f"\nCSV por-fold salvo em: {RESULTS_FOLD_CSV}")

    results_ens = {"name": df["tensor_filename"]}
    for b in FREQS:
        results_ens[f"C50_{b}_REAL"] = df[f"C50_{b}"]
        results_ens[f"T60_{b}_REAL"] = df[f"T60_{b}"]
        results_ens[f"C50_{b}_PRED"] = ensemble_preds[b]["C50"]
        results_ens[f"T60_{b}_PRED"] = ensemble_preds[b]["T60"]
    pd.DataFrame(results_ens).to_csv(RESULTS_ENSEMBLE_CSV, index=False)
    print(f"CSV ensemble salvo em: {RESULTS_ENSEMBLE_CSV}\n")

    # 2) Finaliza medições de performance
    cpu_percent_end = psutil.cpu_percent(interval=None)
    _, peak_memory  = tracemalloc.get_traced_memory()
    tracemalloc.stop()
    end_time        = time.time()

    # 3) Tamanho do arquivo do último checkpoint
    last_ckpt = MODEL_DIR / f"fold_{NUM_FOLDS}/checkpoints/fold{NUM_FOLDS}_latest.pth"
    if not last_ckpt.exists():
        raise FileNotFoundError(f"Checkpoint não encontrado: {last_ckpt}")
    model_file_size_kb = os.path.getsize(last_ckpt) / 1024

    # 4) Impressão final
    print("\n–––––––––––––––––––––––––––––––––––––––––––––")
    print(f"Evaluation Time:        {end_time - start_time:.4f} seconds")
    print(f"Peak Memory Usage:      {peak_memory / (1024 * 1024):.2f} MB")
    print(f"Average CPU Usage:      {(cpu_percent_start + cpu_percent_end) / 2:.2f}%")
    print(f"Model File Size:        {model_file_size_kb:.2f} KB")
    print("–––––––––––––––––––––––––––––––––––––––––––––\n")

if __name__ == "__main__":
    main()

"""## TREINANDO LOG-MEL - 5R"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_multihead_frequency_kfold.py
──────────────────────────────────
• Treina um ResNet-50 multitarefa com cabeças por banda de frequência
  para estimar C50 e T60 em 6 bandas (125-4000 Hz).
• Validação cruzada K-Fold (K=5) com retomada de checkpoint por fold.
• Salva scalers e checkpoints por fold-época.
• Imprime RMSE, MAE, R² e PCC por banda (treino/validação).
• Acumula todas as métricas em CSV sem nunca sobrescrevê-lo.
"""

import os, random, pickle, math
from pathlib import Path
from typing import Dict, Tuple, List

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

# ────────────── caminhos principais ──────────────
TRAIN_DIR = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/5R/log_mel_PASTA_UNICA_TREINO_VALID")
LABELS_PATH = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR   = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_5R_mod")
os.makedirs(MODEL_DIR, exist_ok=True)

# ─────────── CSV de métricas (append-only) ───────────
metrics_path = MODEL_DIR / "all_metrics.csv"
header = "fold,epoch,band,var,rmse_t,mae_t,r2_t,pcc_t,rmse_v,mae_v,r2_v,pcc_v\n"
if not metrics_path.exists():          # só cria se ainda não existir
    with open(metrics_path, "w", encoding="utf-8") as f:
        f.write(header)

# ─────────── hiperparâmetros globais ───────────
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQUENCIES = [str(b) for b in FREQ_BANDS]
C50_VARS    = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS    = [f"T60_{b}" for b in FREQ_BANDS]

BATCH_SIZE  = 16
EPOCHS      = 100
NUM_FOLDS   = 5
SEED        = 42

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ──────────────── dataset ────────────────
class SpectroDataset(Dataset):
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir

    def __len__(self): return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])          # tensor [C,H,W]
        labels = [[row[v] for v in C50_VARS], [row[v] for v in T60_VARS]]  # shape (2,6)
        y = torch.tensor(list(zip(*labels)), dtype=torch.float32)          # (6,2)
        return x, y

# ──────────────── modelo ────────────────
HEAD_CONFIGS = {f: {"hidden_dim": 64, "lr": 1e-3} for f in FREQUENCIES}

class MultiHeadModel(nn.Module):
    def __init__(self, head_configs=HEAD_CONFIGS):
        super().__init__()
        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
        self.backbone = nn.Sequential(*list(backbone.children())[:-1])     # remove FC
        feat_dim = backbone.fc.in_features
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                    nn.Linear(feat_dim, cfg["hidden_dim"]),
                    nn.ReLU(inplace=True),
                    nn.Linear(cfg["hidden_dim"], 2)   # 2 saídas: C50 e T60
               ) for f, cfg in head_configs.items()
        })

    def forward(self, x):
        feats = self.backbone(x).view(x.size(0), -1)
        return {f: head(feats) for f, head in self.heads.items()}

# ──────────────── leitura de labels ────────────────
print("▶ Lendo labels …")
df = pd.read_csv(LABELS_PATH)
TENSOR_COL = "name"
df["tensor_filename"] = df[TENSOR_COL].str.replace(r"\.wav$", "", regex=True) + ".pt"

existing = {p.name for p in TRAIN_DIR.rglob("*.pt")}
df = df[df["tensor_filename"].isin(existing)].reset_index(drop=True)

before = len(df)
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(subset=C50_VARS + T60_VARS, inplace=True)
print(f"⌦ Removidas {before - len(df)} linhas com targets inválidos")

kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)

# ──────────────── K-Fold ────────────────
for fold, (train_idx, val_idx) in enumerate(kf.split(df), start=1):
    print(f"\n══════════ FOLD {fold}/{NUM_FOLDS} ══════════")
    fold_dir   = MODEL_DIR / f"fold_{fold}"
    ckpt_dir   = fold_dir / "checkpoints"
    scaler_dir = fold_dir / "scalers"
    ckpt_dir.mkdir(parents=True, exist_ok=True)
    scaler_dir.mkdir(parents=True, exist_ok=True)

    train_df, val_df = df.iloc[train_idx].copy(), df.iloc[val_idx].copy()

    # -------- escalonamento --------
    scalers_c50, scalers_t60 = {}, {}
    for var in C50_VARS + T60_VARS:
        scaler = StandardScaler().fit(train_df[[var]])
        pickle.dump(scaler, open(scaler_dir / f"scaler_{var}.pkl", "wb"))
        train_df[var] = scaler.transform(train_df[[var]])
        val_df[var]   = scaler.transform(val_df[[var]])
        band = var.split("_")[1]
        (scalers_c50 if var.startswith("C50") else scalers_t60)[band] = scaler

    train_loader = DataLoader(SpectroDataset(train_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader   = DataLoader(SpectroDataset(val_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    model = MultiHeadModel().to(device)
    criterion = nn.MSELoss()

    param_groups = [{"params": model.backbone.parameters(), "lr": 1e-5, "weight_decay": 1e-4}]
    for f in FREQUENCIES:
        param_groups.append({
            "params": model.heads[f].parameters(),
            "lr": HEAD_CONFIGS[f]["lr"], "weight_decay": 1e-4
        })
    optimizer = optim.Adam(param_groups)

    # -------- retomada --------
    start_epoch = 1
    ckpts = list(ckpt_dir.glob(f"fold{fold}_epoch*.pth"))
    if ckpts:
        last = max(int(p.stem.split("epoch")[1]) for p in ckpts)
        print(f"⇒ Retomando fold {fold} a partir do epoch {last} …")
        model.load_state_dict(torch.load(ckpt_dir / f"fold{fold}_epoch{last}.pth", map_location=device))
        opt_path = ckpt_dir / f"fold{fold}_optim_latest.pth"
        if opt_path.exists():
            optimizer.load_state_dict(torch.load(opt_path, map_location=device))
        start_epoch = last + 1

    # -------- laço de épocas --------
    for epoch in range(start_epoch, EPOCHS + 1):
        # === treino ===
        model.train()
        pred_t, true_t = {f: [] for f in FREQUENCIES}, {f: [] for f in FREQUENCIES}
        loss_sum = 0.0
        for x, y in tqdm(train_loader, desc=f"[Fold {fold}] Train {epoch}/{EPOCHS}", leave=False):
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            outs = model(x)
            for i, f in enumerate(FREQUENCIES):
                pred_t[f].append(outs[f].detach().cpu().numpy())
                true_t[f].append(y[:, i, :].cpu().numpy())
            loss = sum(criterion(outs[f], y[:, i, :]) for i, f in enumerate(FREQUENCIES))
            loss.backward()
            optimizer.step()
            loss_sum += loss.item() * x.size(0)
        train_loss = loss_sum / len(train_loader.dataset)

        # === validação ===
        model.eval()
        pred_v, true_v = {f: [] for f in FREQUENCIES}, {f: [] for f in FREQUENCIES}
        val_loss_sum = 0.0
        with torch.no_grad():
            for x, y in tqdm(val_loader, desc=f"[Fold {fold}] Val {epoch}/{EPOCHS}", leave=False):
                x, y = x.to(device), y.to(device)
                outs = model(x)
                for i, f in enumerate(FREQUENCIES):
                    pred_v[f].append(outs[f].cpu().numpy())
                    true_v[f].append(y[:, i, :].cpu().numpy())
                val_loss_sum += sum(
                    criterion(outs[f], y[:, i, :]).item() * x.size(0)
                    for i, f in enumerate(FREQUENCIES)
                )
        val_loss = val_loss_sum / len(val_loader.dataset)

        # === métricas ===
        def compute_metrics(pred, true, s_c, s_t):
            out = {}
            for f in FREQUENCIES:
                p = np.vstack(pred[f]); t = np.vstack(true[f])
                p_c = s_c[f].inverse_transform(p[:, [0]]).ravel()
                t_c = s_c[f].inverse_transform(t[:, [0]]).ravel()
                p_t = s_t[f].inverse_transform(p[:, [1]]).ravel()
                t_t = s_t[f].inverse_transform(t[:, [1]]).ravel()

                def stats(a, b):
                    return (math.sqrt(mean_squared_error(a, b)),
                            mean_absolute_error(a, b),
                            r2_score(a, b),
                            np.corrcoef(a, b)[0, 1])

                out[f] = {"C50": stats(t_c, p_c), "T60": stats(t_t, p_t)}
            return out

        train_m = compute_metrics(pred_t, true_t, scalers_c50, scalers_t60)
        val_m   = compute_metrics(pred_v, true_v, scalers_c50, scalers_t60)

        # === salvar checkpoints ===
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_epoch{epoch}.pth")
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_latest.pth")
        torch.save(optimizer.state_dict(), ckpt_dir / f"fold{fold}_optim_latest.pth")

        # === logging no terminal ===
        print(f"\n[Fold {fold}] Epoch {epoch}/{EPOCHS} — Train L={train_loss:.4f} | Val L={val_loss:.4f}")
        hdr = "Band | RMSE_t | MAE_t | R2_t  | PCC_t | RMSE_v | MAE_v | R2_v  | PCC_v"
        for var in ("C50", "T60"):
            print(f"─── {var} ───"); print(hdr); print("-" * len(hdr))
            for f in FREQUENCIES:
                rt, mt, r2t, pcct = train_m[f][var]
                rv, mv, r2v, pccv = val_m[f][var]
                print(f"{f:>4} | {rt:6.3f} | {mt:6.3f} | {r2t:6.3f} | {pcct:6.3f} | "
                      f"{rv:6.3f} | {mv:6.3f} | {r2v:6.3f} | {pccv:6.3f}")
        print("=" * 80)

        # === append no CSV ===
        with open(metrics_path, "a", encoding="utf-8") as f_csv:
            for band in FREQUENCIES:
                for var in ("C50", "T60"):
                    rt, mt, r2t, pcct = train_m[band][var]
                    rv, mv, r2v, pccv = val_m[band][var]
                    f_csv.write(f"{fold},{epoch},{band},{var},"
                                f"{rt:.6f},{mt:.6f},{r2t:.6f},{pcct:.6f},"
                                f"{rv:.6f},{mv:.6f},{r2v:.6f},{pccv:.6f}\n")

print("\nTreinamento K-Fold concluído!")

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_multihead_frequency_kfold.py
─────────────────────────────────
Avalia os 5 modelos (1 por fold) treinados com validação cruzada,
gera métricas (RMSE, MAE, R², PCC) por fold e ensemble,
grava CSVs de previsões e métricas e mede performance.
"""
import os
import time
import tracemalloc
import psutil
import math
import pickle
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from tqdm.auto import tqdm
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import scipy.stats as st

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import models

# ────────────────────────── CONFIGURAÇÕES ──────────────────────────
TEST_DIR    = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/5R/log_mel_PASTA_UNICA_TESTE")
LABELS_PATH = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR   = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_5R_mod")

NUM_FOLDS   = 5
BATCH_SIZE  = 16
NUM_WORKERS = 0   # evita bug do QueueFeederThread em Python 3.11
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQS       = [str(b) for b in FREQ_BANDS]
C50_VARS    = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS    = [f"T60_{b}" for b in FREQ_BANDS]

RESULTS_FOLD_CSV     = MODEL_DIR / "test_results_por_fold.csv"
RESULTS_ENSEMBLE_CSV = MODEL_DIR / "test_results_ensemble.csv"
METRICS_FOLD_CSV     = MODEL_DIR / "test_metrics_por_fold.csv"
METRICS_ENSEMBLE_CSV = MODEL_DIR / "test_metrics_ensemble.csv"

# ─────────────────────────── DATASET ───────────────────────────────
class SpectroTestDataset(Dataset):
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir
    def __len__(self):
        return len(self.df)
    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])
        return x, row["tensor_filename"]

# ─────────────────────────── MODELO ────────────────────────────────
HEAD_CONFIGS = {f: {"hidden_dim": 64} for f in FREQS}
class MultiHeadModel(nn.Module):
    def __init__(self, head_configs=HEAD_CONFIGS):
        super().__init__()
        backbone = models.resnet50(weights=None)
        self.backbone = nn.Sequential(*list(backbone.children())[:-1])
        feat_dim = backbone.fc.in_features
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, cfg["hidden_dim"]),
                nn.ReLU(inplace=True),
                nn.Linear(cfg["hidden_dim"], 2)
            ) for f, cfg in head_configs.items()
        })
    def forward(self, x):
        feats = self.backbone(x).view(x.size(0), -1)
        return {f: head(feats) for f, head in self.heads.items()}

# ───────────────────────── FUNÇÕES AUXILIARES ──────────────────────
def load_scalers(scaler_dir: Path) -> Tuple[Dict[str, object], Dict[str, object]]:
    sc_c50, sc_t60 = {}, {}
    for b in FREQS:
        sc_c50[b] = pickle.load(open(scaler_dir / f"scaler_C50_{b}.pkl", "rb"))
        sc_t60[b] = pickle.load(open(scaler_dir / f"scaler_T60_{b}.pkl", "rb"))
    return sc_c50, sc_t60

def inverse_scale(preds: np.ndarray, scalers):
    """Preds (np.ndarray shape [N,2]) → tuple(C50,T60) já des-normalizados"""
    c50 = scalers[0].inverse_transform(preds[:, [0]]).ravel()
    t60 = scalers[1].inverse_transform(preds[:, [1]]).ravel()
    return c50, t60

def metrics(y_true, y_pred):
    rmse = math.sqrt(mean_squared_error(y_true, y_pred))
    mae  = mean_absolute_error(y_true, y_pred)
    r2   = r2_score(y_true, y_pred)
    pcc  = st.pearsonr(y_true, y_pred)[0] if len(y_true) > 1 else np.nan
    return rmse, mae, r2, pcc

# ─────────────────────────── MAIN ──────────────────────────────────
def main():
    # 1) Inicia medições de performance
    start_time        = time.time()
    tracemalloc.start()
    process           = psutil.Process(os.getpid())
    cpu_percent_start = psutil.cpu_percent(interval=None)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    MODEL_DIR.mkdir(parents=True, exist_ok=True)

    # cabeçalhos CSV
    if not METRICS_FOLD_CSV.exists():
        METRICS_FOLD_CSV.write_text("fold,band,var,rmse,mae,r2,pcc\n")
    if not METRICS_ENSEMBLE_CSV.exists():
        METRICS_ENSEMBLE_CSV.write_text("band,var,rmse,mae,r2,pcc\n")

    # carregar labels e filtrar tensores
    df = pd.read_csv(LABELS_PATH)
    df["tensor_filename"] = df["name"].str.replace(r"\.wav$", "", regex=True) + ".pt"
    test_pt = {p.name for p in TEST_DIR.rglob("*.pt")}
    df = df[df["tensor_filename"].isin(test_pt)].reset_index(drop=True)
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.dropna(subset=C50_VARS + T60_VARS, inplace=True)
    print(f"→ {len(df)} amostras de teste encontradas.")

    loader = DataLoader(
        SpectroTestDataset(df, TEST_DIR),
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=NUM_WORKERS
    )

    # prepara container de previsões
    preds_fold = [
        {b: {"C50": [], "T60": []} for b in FREQS}
        for _ in range(NUM_FOLDS)
    ]

    # loop folds
    for fold in range(1, NUM_FOLDS + 1):
        print(f"\n════ Avaliando FOLD {fold}/{NUM_FOLDS} ════")
        fold_dir   = MODEL_DIR / f"fold_{fold}"
        ckpt_dir   = fold_dir / "checkpoints"
        scaler_dir = fold_dir / "scalers"

        sc_c50, sc_t60 = load_scalers(scaler_dir)

        model = MultiHeadModel().to(device)
        ckpt_path = ckpt_dir / f"fold{fold}_latest.pth"
        if not ckpt_path.exists():
            all_ckpt = sorted(ckpt_dir.glob(f"fold{fold}_epoch*.pth"),
                              key=lambda p: int(p.stem.split("epoch")[1]))
            if not all_ckpt:
                raise FileNotFoundError(f"Nenhum checkpoint em {ckpt_dir}")
            ckpt_path = all_ckpt[-1]
        model.load_state_dict(torch.load(ckpt_path, map_location=device))
        model.eval()
        print(f"  Checkpoint carregado: {ckpt_path.name}")

        # inferência
        with torch.no_grad():
            for x, _ in tqdm(loader, desc=f"Inferência Fold {fold}", leave=False):
                x = x.to(device)
                outs = model(x)  # dict banda->(bs,2)
                for i, b in enumerate(FREQS):
                    preds = outs[b].cpu().numpy()
                    p_c50, p_t60 = inverse_scale(preds, (sc_c50[b], sc_t60[b]))
                    preds_fold[fold-1][b]["C50"].extend(p_c50.tolist())
                    preds_fold[fold-1][b]["T60"].extend(p_t60.tolist())

        # métricas por banda
        with open(METRICS_FOLD_CSV, "a") as f_csv:
            for b in FREQS:
                for var in ("C50", "T60"):
                    y_true = df[f"{var}_{b}"].values
                    y_pred = preds_fold[fold-1][b][var]
                    rmse, mae, r2, pcc = metrics(y_true, y_pred)
                    print(f" {var}_{b}: {rmse:.4f} | {mae:.4f} | {r2:.4f} | {pcc:.4f}")
                    f_csv.write(f"{fold},{b},{var},{rmse:.6f},{mae:.6f},{r2:.6f},{pcc:.6f}\n")

    # ensemble (média dos 5 folds)
    print("\n════ Métricas do ENSEMBLE (média simples) ════")
    ensemble_preds = {b: {"C50": [], "T60": []} for b in FREQS}
    for idx in range(len(df)):
        for b in FREQS:
            ensemble_preds[b]["C50"].append(
                np.mean([preds_fold[f][b]["C50"][idx] for f in range(NUM_FOLDS)])
            )
            ensemble_preds[b]["T60"].append(
                np.mean([preds_fold[f][b]["T60"][idx] for f in range(NUM_FOLDS)])
            )

    with open(METRICS_ENSEMBLE_CSV, "a") as f_csv:
        for b in FREQS:
            for var in ("C50", "T60"):
                y_true = df[f"{var}_{b}"].values
                y_pred = ensemble_preds[b][var]
                rmse, mae, r2, pcc = metrics(y_true, y_pred)
                print(f" {var}_{b}: {rmse:.4f} | {mae:.4f} | {r2:.4f} | {pcc:.4f}")
                f_csv.write(f"{b},{var},{rmse:.6f},{mae:.6f},{r2:.6f},{pcc:.6f}\n")

    # grava CSVs de previsões
    results_fold = {"name": df["tensor_filename"]}
    for fold in range(NUM_FOLDS):
        for b in FREQS:
            results_fold[f"C50_{b}_pred_fold{fold+1}"] = preds_fold[fold][b]["C50"]
            results_fold[f"T60_{b}_pred_fold{fold+1}"] = preds_fold[fold][b]["T60"]
    pd.DataFrame(results_fold).to_csv(RESULTS_FOLD_CSV, index=False)
    print(f"\nCSV por-fold salvo em: {RESULTS_FOLD_CSV}")

    results_ens = {"name": df["tensor_filename"]}
    for b in FREQS:
        results_ens[f"C50_{b}_REAL"] = df[f"C50_{b}"]
        results_ens[f"T60_{b}_REAL"] = df[f"T60_{b}"]
        results_ens[f"C50_{b}_PRED"] = ensemble_preds[b]["C50"]
        results_ens[f"T60_{b}_PRED"] = ensemble_preds[b]["T60"]
    pd.DataFrame(results_ens).to_csv(RESULTS_ENSEMBLE_CSV, index=False)
    print(f"CSV ensemble salvo em: {RESULTS_ENSEMBLE_CSV}\n")

    # 2) Finaliza medições de performance
    cpu_percent_end = psutil.cpu_percent(interval=None)
    _, peak_memory  = tracemalloc.get_traced_memory()
    tracemalloc.stop()
    end_time        = time.time()

    # 3) Tamanho do arquivo do último checkpoint
    last_ckpt = MODEL_DIR / f"fold_{NUM_FOLDS}/checkpoints/fold{NUM_FOLDS}_latest.pth"
    if not last_ckpt.exists():
        raise FileNotFoundError(f"Checkpoint não encontrado: {last_ckpt}")
    model_file_size_kb = os.path.getsize(last_ckpt) / 1024

    # 4) Impressão final
    print("\n–––––––––––––––––––––––––––––––––––––––––––––")
    print(f"Evaluation Time:        {end_time - start_time:.4f} seconds")
    print(f"Peak Memory Usage:      {peak_memory / (1024 * 1024):.2f} MB")
    print(f"Average CPU Usage:      {(cpu_percent_start + cpu_percent_end) / 2:.2f}%")
    print(f"Model File Size:        {model_file_size_kb:.2f} KB")
    print("–––––––––––––––––––––––––––––––––––––––––––––\n")

if __name__ == "__main__":
    main()

"""## CALCULANDO O INTERVALO DE CONFIANÇA DO PCC"""

import pandas as pd
import numpy as np
from scipy.stats import norm

def pearson_ci(r, n, alpha=0.05):
    # transformação de Fisher
    z = np.arctanh(r)
    se = 1.0 / np.sqrt(n - 3)
    z_crit = norm.ppf(1 - alpha/2)
    lo_z, hi_z = z - z_crit*se, z + z_crit*se
    # volta para r
    return np.tanh(lo_z), np.tanh(hi_z)

# --- exemplo de leitura do CSV de métricas de ensemble ---
df = pd.read_csv("test_metrics_ensemble.csv")
# df tem colunas: band, var, rmse, mae, r2, pcc

# precisamos do n – use o número de amostras de teste
# por simplicidade, você pode fazer:
n = len(pd.read_csv("test_results_ensemble.csv"))

# agora aplica o CI
cis = df["pcc"].apply(lambda r: pearson_ci(r, n))
df["pcc_lo"], df["pcc_hi"] = zip(*cis)

# salva um novo CSV com intervalo de confiança
df.to_csv("test_metrics_ensemble_with_CI.csv", index=False)
print(df.head())

"""# MODELO 2 - 2 HEADS (T60, C50)

## TREINAMENTO LOG-MEL - SR
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_multihead_frequency_kfold.py
──────────────────────────────────
• Treina um ResNet-50 multitarefa com DUAS cabeças:
    – head_C50 → estima C50 para 6 bandas (125, 250, 500, 1000, 2000, 4000 Hz)
    – head_T60 → estima T60 para as mesmas bandas
• Validação cruzada K-Fold (K=5) com retomada de checkpoint por fold.
• Salva scalers e checkpoints por fold-época.
• Imprime RMSE, MAE, R² e PCC por banda (treino/validação).
• Acumula todas as métricas em CSV sem nunca sobrescrevê-lo.
"""

import os
import random
import pickle
import math
from pathlib import Path
from typing import Dict, Tuple, List

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

# ────────────── caminhos principais ──────────────
TRAIN_DIR    = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TREINO_VALID")
LABELS_PATH  = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR    = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_DUAS_CABECAS")
os.makedirs(MODEL_DIR, exist_ok=True)

# ─────────── CSV de métricas (append-only) ───────────
metrics_path = MODEL_DIR / "all_metrics.csv"
header = "fold,epoch,band,var,rmse_t,mae_t,r2_t,pcc_t,rmse_v,mae_v,r2_v,pcc_v\n"
if not metrics_path.exists():
    with open(metrics_path, "w", encoding="utf-8") as f:
        f.write(header)

# ─────────── hiperparâmetros globais ───────────
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQUENCIES = [str(b) for b in FREQ_BANDS]           # ['125','250',...]
C50_VARS    = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS    = [f"T60_{b}" for b in FREQ_BANDS]

BATCH_SIZE  = 16
EPOCHS      = 100
NUM_FOLDS   = 5
SEED        = 42

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ──────────────── dataset ────────────────
class SpectroDataset(Dataset):
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])  # tensor [C,H,W]
        y_c50 = torch.tensor([row[v] for v in C50_VARS], dtype=torch.float32)  # (6,)
        y_t60 = torch.tensor([row[v] for v in T60_VARS], dtype=torch.float32)  # (6,)
        return x, y_c50, y_t60

# ──────────────── modelo ────────────────
HEAD_CONFIGS = {
    "C50": {"hidden_dim": 64, "lr": 1e-3},
    "T60": {"hidden_dim": 64, "lr": 1e-3},
}

class MultiHeadModel(nn.Module):
    def __init__(self, head_configs=HEAD_CONFIGS):
        super().__init__()
        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
        self.backbone = nn.Sequential(*list(backbone.children())[:-1])  # remove FC
        feat_dim = backbone.fc.in_features

        # head que estima 6 valores de C50
        self.head_C50 = nn.Sequential(
            nn.Linear(feat_dim, head_configs["C50"]["hidden_dim"]),
            nn.ReLU(inplace=True),
            nn.Linear(head_configs["C50"]["hidden_dim"], len(FREQ_BANDS))
        )
        # head que estima 6 valores de T60
        self.head_T60 = nn.Sequential(
            nn.Linear(feat_dim, head_configs["T60"]["hidden_dim"]),
            nn.ReLU(inplace=True),
            nn.Linear(head_configs["T60"]["hidden_dim"], len(FREQ_BANDS))
        )

    def forward(self, x):
        feats = self.backbone(x).view(x.size(0), -1)
        return {
            "C50": self.head_C50(feats),   # (batch, 6)
            "T60": self.head_T60(feats),   # (batch, 6)
        }

# ──────────────── leitura de labels ────────────────
print("▶ Lendo labels …")
df = pd.read_csv(LABELS_PATH)
TENSOR_COL = "name"
df["tensor_filename"] = df[TENSOR_COL].str.replace(r"\.wav$", "", regex=True) + ".pt"

existing = {p.name for p in TRAIN_DIR.rglob("*.pt")}
df = df[df["tensor_filename"].isin(existing)].reset_index(drop=True)

before = len(df)
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(subset=C50_VARS + T60_VARS, inplace=True)
print(f"⌦ Removidas {before - len(df)} linhas com targets inválidos")

kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)

# ──────────────── K-Fold ────────────────
for fold, (train_idx, val_idx) in enumerate(kf.split(df), start=1):
    print(f"\n══════════ FOLD {fold}/{NUM_FOLDS} ══════════")
    fold_dir   = MODEL_DIR / f"fold_{fold}"
    ckpt_dir   = fold_dir / "checkpoints"
    scaler_dir = fold_dir / "scalers"
    ckpt_dir.mkdir(parents=True, exist_ok=True)
    scaler_dir.mkdir(parents=True, exist_ok=True)

    train_df, val_df = df.iloc[train_idx].copy(), df.iloc[val_idx].copy()

    # -------- escalonamento --------
    scalers_c50, scalers_t60 = {}, {}
    for var in C50_VARS + T60_VARS:
        scaler = StandardScaler().fit(train_df[[var]])
        pickle.dump(scaler, open(scaler_dir / f"scaler_{var}.pkl", "wb"))
        train_df[var] = scaler.transform(train_df[[var]])
        val_df[var]   = scaler.transform(val_df[[var]])
        band = var.split("_")[1]  # ex: "125"
        if var.startswith("C50"):
            scalers_c50[band] = scaler
        else:
            scalers_t60[band] = scaler

    train_loader = DataLoader(SpectroDataset(train_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader   = DataLoader(SpectroDataset(val_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    model = MultiHeadModel().to(device)
    criterion = nn.MSELoss()

    # otimização com lr diferentes
    param_groups = [
        {"params": model.backbone.parameters(), "lr": 1e-5, "weight_decay": 1e-4},
        {"params": model.head_C50.parameters(),
         "lr": HEAD_CONFIGS["C50"]["lr"], "weight_decay": 1e-4},
        {"params": model.head_T60.parameters(),
         "lr": HEAD_CONFIGS["T60"]["lr"], "weight_decay": 1e-4},
    ]
    optimizer = optim.Adam(param_groups)

    # -------- retomada --------
    start_epoch = 1
    ckpts = list(ckpt_dir.glob(f"fold{fold}_epoch*.pth"))
    if ckpts:
        last = max(int(p.stem.split("epoch")[1]) for p in ckpts)
        print(f"⇒ Retomando fold {fold} a partir do epoch {last} …")
        model.load_state_dict(torch.load(ckpt_dir / f"fold{fold}_epoch{last}.pth",
                                         map_location=device))
        opt_path = ckpt_dir / f"fold{fold}_optim_latest.pth"
        if opt_path.exists():
            optimizer.load_state_dict(torch.load(opt_path, map_location=device))
        start_epoch = last + 1

    # função auxiliar de métricas
    def compute_metrics(pred: np.ndarray,
                        true: np.ndarray,
                        scalers: Dict[str, StandardScaler]
                       ) -> Dict[str, Tuple[float, float, float, float]]:
        out = {}
        # pred, true: arrays shape (N,6)
        for i, band in enumerate(FREQUENCIES):
            p = scalers[band].inverse_transform(pred[:, [i]]).ravel()
            t = scalers[band].inverse_transform(true[:, [i]]).ravel()
            rmse = math.sqrt(mean_squared_error(t, p))
            mae  = mean_absolute_error(t, p)
            r2   = r2_score(t, p)
            pcc  = np.corrcoef(t, p)[0, 1]
            out[band] = (rmse, mae, r2, pcc)
        return out

    # -------- laço de épocas --------
    for epoch in range(start_epoch, EPOCHS + 1):
        # === treino ===
        model.train()
        train_preds_C50, train_trues_C50 = [], []
        train_preds_T60, train_trues_T60 = [], []
        loss_sum = 0.0

        for x, y_c50, y_t60 in tqdm(train_loader,
                                    desc=f"[Fold {fold}] Train {epoch}/{EPOCHS}",
                                    leave=False):
            x = x.to(device)
            y_c50 = y_c50.to(device)
            y_t60 = y_t60.to(device)

            optimizer.zero_grad()
            outs = model(x)
            loss = criterion(outs["C50"], y_c50) + criterion(outs["T60"], y_t60)
            loss.backward()
            optimizer.step()

            train_preds_C50.append(outs["C50"].detach().cpu().numpy())
            train_trues_C50.append(y_c50.cpu().numpy())
            train_preds_T60.append(outs["T60"].detach().cpu().numpy())
            train_trues_T60.append(y_t60.cpu().numpy())
            loss_sum += loss.item() * x.size(0)

        train_loss = loss_sum / len(train_loader.dataset)

        # === validação ===
        model.eval()
        val_preds_C50, val_trues_C50 = [], []
        val_preds_T60, val_trues_T60 = [], []
        val_loss_sum = 0.0

        with torch.no_grad():
            for x, y_c50, y_t60 in tqdm(val_loader,
                                        desc=f"[Fold {fold}] Val {epoch}/{EPOCHS}",
                                        leave=False):
                x = x.to(device)
                y_c50 = y_c50.to(device)
                y_t60 = y_t60.to(device)

                outs = model(x)
                val_preds_C50.append(outs["C50"].cpu().numpy())
                val_trues_C50.append(y_c50.cpu().numpy())
                val_preds_T60.append(outs["T60"].cpu().numpy())
                val_trues_T60.append(y_t60.cpu().numpy())

                val_loss_sum += (
                    criterion(outs["C50"], y_c50).item() +
                    criterion(outs["T60"], y_t60).item()
                ) * x.size(0)

        val_loss = val_loss_sum / len(val_loader.dataset)

        # === métricas ===
        pred_C50_t = np.vstack(train_preds_C50)
        true_C50_t = np.vstack(train_trues_C50)
        pred_T60_t = np.vstack(train_preds_T60)
        true_T60_t = np.vstack(train_trues_T60)

        pred_C50_v = np.vstack(val_preds_C50)
        true_C50_v = np.vstack(val_trues_C50)
        pred_T60_v = np.vstack(val_preds_T60)
        true_T60_v = np.vstack(val_trues_T60)

        train_m_C50 = compute_metrics(pred_C50_t, true_C50_t, scalers_c50)
        train_m_T60 = compute_metrics(pred_T60_t, true_T60_t, scalers_t60)
        val_m_C50   = compute_metrics(pred_C50_v, true_C50_v, scalers_c50)
        val_m_T60   = compute_metrics(pred_T60_v, true_T60_v, scalers_t60)

        # === salvar checkpoints ===
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_epoch{epoch}.pth")
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_latest.pth")
        torch.save(optimizer.state_dict(), ckpt_dir / f"fold{fold}_optim_latest.pth")

        # === logging no terminal ===
        print(f"\n[Fold {fold}] Epoch {epoch}/{EPOCHS} — Train L={train_loss:.4f} | Val L={val_loss:.4f}")
        hdr = "Band | RMSE_t | MAE_t | R2_t  | PCC_t | RMSE_v | MAE_v | R2_v  | PCC_v"
        for var, (m_tr, m_vl) in [
            ("C50", (train_m_C50, val_m_C50)),
            ("T60", (train_m_T60, val_m_T60))
        ]:
            print(f"─── {var} ───")
            print(hdr)
            print("-" * len(hdr))
            for band in FREQUENCIES:
                rt, mt, r2t, pcct = m_tr[band]
                rv, mv, r2v, pccv = m_vl[band]
                print(f"{band:>4} | {rt:6.3f} | {mt:6.3f} | {r2t:6.3f} | {pcct:6.3f} | "
                      f"{rv:6.3f} | {mv:6.3f} | {r2v:6.3f} | {pccv:6.3f}")
        print("=" * 80)

        # === append no CSV ===
        with open(metrics_path, "a", encoding="utf-8") as f_csv:
            for band in FREQUENCIES:
                for var, (m_tr, m_vl) in [
                    ("C50", (train_m_C50, val_m_C50)),
                    ("T60", (train_m_T60, val_m_T60))
                ]:
                    rt, mt, r2t, pcct = m_tr[band]
                    rv, mv, r2v, pccv = m_vl[band]
                    f_csv.write(f"{fold},{epoch},{band},{var},"
                                f"{rt:.6f},{mt:.6f},{r2t:.6f},{pcct:.6f},"
                                f"{rv:.6f},{mv:.6f},{r2v:.6f},{pccv:.6f}\n")

print("\nTreinamento K-Fold concluído!")

"""## TREINANDO LOG-MEL - 1R"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_multihead_frequency_kfold.py
──────────────────────────────────
• Treina um ResNet-50 multitarefa com DUAS cabeças:
    – head_C50 → estima C50 para 6 bandas (125, 250, 500, 1000, 2000, 4000 Hz)
    – head_T60 → estima T60 para as mesmas bandas
• Validação cruzada K-Fold (K=5) com retomada de checkpoint por fold.
• Salva scalers e checkpoints por fold-época.
• Imprime RMSE, MAE, R² e PCC por banda (treino/validação).
• Acumula todas as métricas em CSV sem nunca sobrescrevê-lo.
"""

import os
import random
import pickle
import math
from pathlib import Path
from typing import Dict, Tuple, List

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

# ────────────── caminhos principais ──────────────
TRAIN_DIR    = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/1R/log_mel_MOD_PASTA_UNICA_TREINO_VALID")
LABELS_PATH  = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR    = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_1R_DUAS_CABECAS")
os.makedirs(MODEL_DIR, exist_ok=True)

# ─────────── CSV de métricas (append-only) ───────────
metrics_path = MODEL_DIR / "all_metrics.csv"
header = "fold,epoch,band,var,rmse_t,mae_t,r2_t,pcc_t,rmse_v,mae_v,r2_v,pcc_v\n"
if not metrics_path.exists():
    with open(metrics_path, "w", encoding="utf-8") as f:
        f.write(header)

# ─────────── hiperparâmetros globais ───────────
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQUENCIES = [str(b) for b in FREQ_BANDS]           # ['125','250',...]
C50_VARS    = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS    = [f"T60_{b}" for b in FREQ_BANDS]

BATCH_SIZE  = 16
EPOCHS      = 100
NUM_FOLDS   = 5
SEED        = 42

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ──────────────── dataset ────────────────
class SpectroDataset(Dataset):
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])  # tensor [C,H,W]
        y_c50 = torch.tensor([row[v] for v in C50_VARS], dtype=torch.float32)  # (6,)
        y_t60 = torch.tensor([row[v] for v in T60_VARS], dtype=torch.float32)  # (6,)
        return x, y_c50, y_t60

# ──────────────── modelo ────────────────
HEAD_CONFIGS = {
    "C50": {"hidden_dim": 64, "lr": 1e-3},
    "T60": {"hidden_dim": 64, "lr": 1e-3},
}

class MultiHeadModel(nn.Module):
    def __init__(self, head_configs=HEAD_CONFIGS):
        super().__init__()
        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
        self.backbone = nn.Sequential(*list(backbone.children())[:-1])  # remove FC
        feat_dim = backbone.fc.in_features

        # head que estima 6 valores de C50
        self.head_C50 = nn.Sequential(
            nn.Linear(feat_dim, head_configs["C50"]["hidden_dim"]),
            nn.ReLU(inplace=True),
            nn.Linear(head_configs["C50"]["hidden_dim"], len(FREQ_BANDS))
        )
        # head que estima 6 valores de T60
        self.head_T60 = nn.Sequential(
            nn.Linear(feat_dim, head_configs["T60"]["hidden_dim"]),
            nn.ReLU(inplace=True),
            nn.Linear(head_configs["T60"]["hidden_dim"], len(FREQ_BANDS))
        )

    def forward(self, x):
        feats = self.backbone(x).view(x.size(0), -1)
        return {
            "C50": self.head_C50(feats),   # (batch, 6)
            "T60": self.head_T60(feats),   # (batch, 6)
        }

# ──────────────── leitura de labels ────────────────
print("▶ Lendo labels …")
df = pd.read_csv(LABELS_PATH)
TENSOR_COL = "name"
df["tensor_filename"] = df[TENSOR_COL].str.replace(r"\.wav$", "", regex=True) + ".pt"

existing = {p.name for p in TRAIN_DIR.rglob("*.pt")}
df = df[df["tensor_filename"].isin(existing)].reset_index(drop=True)

before = len(df)
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(subset=C50_VARS + T60_VARS, inplace=True)
print(f"⌦ Removidas {before - len(df)} linhas com targets inválidos")

kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)

# ──────────────── K-Fold ────────────────
for fold, (train_idx, val_idx) in enumerate(kf.split(df), start=1):
    print(f"\n══════════ FOLD {fold}/{NUM_FOLDS} ══════════")
    fold_dir   = MODEL_DIR / f"fold_{fold}"
    ckpt_dir   = fold_dir / "checkpoints"
    scaler_dir = fold_dir / "scalers"
    ckpt_dir.mkdir(parents=True, exist_ok=True)
    scaler_dir.mkdir(parents=True, exist_ok=True)

    train_df, val_df = df.iloc[train_idx].copy(), df.iloc[val_idx].copy()

    # -------- escalonamento --------
    scalers_c50, scalers_t60 = {}, {}
    for var in C50_VARS + T60_VARS:
        scaler = StandardScaler().fit(train_df[[var]])
        pickle.dump(scaler, open(scaler_dir / f"scaler_{var}.pkl", "wb"))
        train_df[var] = scaler.transform(train_df[[var]])
        val_df[var]   = scaler.transform(val_df[[var]])
        band = var.split("_")[1]  # ex: "125"
        if var.startswith("C50"):
            scalers_c50[band] = scaler
        else:
            scalers_t60[band] = scaler

    train_loader = DataLoader(SpectroDataset(train_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader   = DataLoader(SpectroDataset(val_df, TRAIN_DIR),
                              batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    model = MultiHeadModel().to(device)
    criterion = nn.MSELoss()

    # otimização com lr diferentes
    param_groups = [
        {"params": model.backbone.parameters(), "lr": 1e-5, "weight_decay": 1e-4},
        {"params": model.head_C50.parameters(),
         "lr": HEAD_CONFIGS["C50"]["lr"], "weight_decay": 1e-4},
        {"params": model.head_T60.parameters(),
         "lr": HEAD_CONFIGS["T60"]["lr"], "weight_decay": 1e-4},
    ]
    optimizer = optim.Adam(param_groups)

    # -------- retomada --------
    start_epoch = 1
    ckpts = list(ckpt_dir.glob(f"fold{fold}_epoch*.pth"))
    if ckpts:
        last = max(int(p.stem.split("epoch")[1]) for p in ckpts)
        print(f"⇒ Retomando fold {fold} a partir do epoch {last} …")
        model.load_state_dict(torch.load(ckpt_dir / f"fold{fold}_epoch{last}.pth",
                                         map_location=device))
        opt_path = ckpt_dir / f"fold{fold}_optim_latest.pth"
        if opt_path.exists():
            optimizer.load_state_dict(torch.load(opt_path, map_location=device))
        start_epoch = last + 1

    # função auxiliar de métricas
    def compute_metrics(pred: np.ndarray,
                        true: np.ndarray,
                        scalers: Dict[str, StandardScaler]
                       ) -> Dict[str, Tuple[float, float, float, float]]:
        out = {}
        # pred, true: arrays shape (N,6)
        for i, band in enumerate(FREQUENCIES):
            p = scalers[band].inverse_transform(pred[:, [i]]).ravel()
            t = scalers[band].inverse_transform(true[:, [i]]).ravel()
            rmse = math.sqrt(mean_squared_error(t, p))
            mae  = mean_absolute_error(t, p)
            r2   = r2_score(t, p)
            pcc  = np.corrcoef(t, p)[0, 1]
            out[band] = (rmse, mae, r2, pcc)
        return out

    # -------- laço de épocas --------
    for epoch in range(start_epoch, EPOCHS + 1):
        # === treino ===
        model.train()
        train_preds_C50, train_trues_C50 = [], []
        train_preds_T60, train_trues_T60 = [], []
        loss_sum = 0.0

        for x, y_c50, y_t60 in tqdm(train_loader,
                                    desc=f"[Fold {fold}] Train {epoch}/{EPOCHS}",
                                    leave=False):
            x = x.to(device)
            y_c50 = y_c50.to(device)
            y_t60 = y_t60.to(device)

            optimizer.zero_grad()
            outs = model(x)
            loss = criterion(outs["C50"], y_c50) + criterion(outs["T60"], y_t60)
            loss.backward()
            optimizer.step()

            train_preds_C50.append(outs["C50"].detach().cpu().numpy())
            train_trues_C50.append(y_c50.cpu().numpy())
            train_preds_T60.append(outs["T60"].detach().cpu().numpy())
            train_trues_T60.append(y_t60.cpu().numpy())
            loss_sum += loss.item() * x.size(0)

        train_loss = loss_sum / len(train_loader.dataset)

        # === validação ===
        model.eval()
        val_preds_C50, val_trues_C50 = [], []
        val_preds_T60, val_trues_T60 = [], []
        val_loss_sum = 0.0

        with torch.no_grad():
            for x, y_c50, y_t60 in tqdm(val_loader,
                                        desc=f"[Fold {fold}] Val {epoch}/{EPOCHS}",
                                        leave=False):
                x = x.to(device)
                y_c50 = y_c50.to(device)
                y_t60 = y_t60.to(device)

                outs = model(x)
                val_preds_C50.append(outs["C50"].cpu().numpy())
                val_trues_C50.append(y_c50.cpu().numpy())
                val_preds_T60.append(outs["T60"].cpu().numpy())
                val_trues_T60.append(y_t60.cpu().numpy())

                val_loss_sum += (
                    criterion(outs["C50"], y_c50).item() +
                    criterion(outs["T60"], y_t60).item()
                ) * x.size(0)

        val_loss = val_loss_sum / len(val_loader.dataset)

        # === métricas ===
        pred_C50_t = np.vstack(train_preds_C50)
        true_C50_t = np.vstack(train_trues_C50)
        pred_T60_t = np.vstack(train_preds_T60)
        true_T60_t = np.vstack(train_trues_T60)

        pred_C50_v = np.vstack(val_preds_C50)
        true_C50_v = np.vstack(val_trues_C50)
        pred_T60_v = np.vstack(val_preds_T60)
        true_T60_v = np.vstack(val_trues_T60)

        train_m_C50 = compute_metrics(pred_C50_t, true_C50_t, scalers_c50)
        train_m_T60 = compute_metrics(pred_T60_t, true_T60_t, scalers_t60)
        val_m_C50   = compute_metrics(pred_C50_v, true_C50_v, scalers_c50)
        val_m_T60   = compute_metrics(pred_T60_v, true_T60_v, scalers_t60)

        # === salvar checkpoints ===
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_epoch{epoch}.pth")
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_latest.pth")
        torch.save(optimizer.state_dict(), ckpt_dir / f"fold{fold}_optim_latest.pth")

        # === logging no terminal ===
        print(f"\n[Fold {fold}] Epoch {epoch}/{EPOCHS} — Train L={train_loss:.4f} | Val L={val_loss:.4f}")
        hdr = "Band | RMSE_t | MAE_t | R2_t  | PCC_t | RMSE_v | MAE_v | R2_v  | PCC_v"
        for var, (m_tr, m_vl) in [
            ("C50", (train_m_C50, val_m_C50)),
            ("T60", (train_m_T60, val_m_T60))
        ]:
            print(f"─── {var} ───")
            print(hdr)
            print("-" * len(hdr))
            for band in FREQUENCIES:
                rt, mt, r2t, pcct = m_tr[band]
                rv, mv, r2v, pccv = m_vl[band]
                print(f"{band:>4} | {rt:6.3f} | {mt:6.3f} | {r2t:6.3f} | {pcct:6.3f} | "
                      f"{rv:6.3f} | {mv:6.3f} | {r2v:6.3f} | {pccv:6.3f}")
        print("=" * 80)

        # === append no CSV ===
        with open(metrics_path, "a", encoding="utf-8") as f_csv:
            for band in FREQUENCIES:
                for var, (m_tr, m_vl) in [
                    ("C50", (train_m_C50, val_m_C50)),
                    ("T60", (train_m_T60, val_m_T60))
                ]:
                    rt, mt, r2t, pcct = m_tr[band]
                    rv, mv, r2v, pccv = m_vl[band]
                    f_csv.write(f"{fold},{epoch},{band},{var},"
                                f"{rt:.6f},{mt:.6f},{r2t:.6f},{pcct:.6f},"
                                f"{rv:.6f},{mv:.6f},{r2v:.6f},{pccv:.6f}\n")

print("\nTreinamento K-Fold concluído!")

"""## TREINANDO LOG-MEL - 5R

# MODELO 3 - 6 HEADS (125, 250, 500, 1000, 2000, 4000)

## TREINAMENTO LOG-MEL - SR
"""

from google.colab import drive
drive.mount('/content/drive')

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_multihead_frequency_kfold_vit.py
───────────────────────────────────────────────────────────────────────────────
• Treina (e agora também retoma) um ViT-B/16 multitarefa com cabeças por banda
  (125-4000 Hz) para estimar C50 e T60 em 6 bandas de oitava, usando validação
  K-Fold.
• Estrutura mantida:
    – checkpoints por fold-época + “best.pth” + “*_latest.pth”
    – scalers StandardScaler por fold
    – CSV global de métricas (RMSE, MAE, R², PCC) append-only
• Corrigido: One-CycleLR, gradient clipping, dropout leve nas cabeças.
• **Early-stopping removido** — o treino sempre percorre todas as épocas.
• **NOVO**: retomada automática a partir do último checkpoint existente.
"""

# ───────────────────────── Imports ──────────────────────────
import os, re, random, pickle, math, warnings
from pathlib import Path
from typing import List, Tuple

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

warnings.filterwarnings("ignore", category=FutureWarning)
torch.backends.cuda.matmul.allow_tf32 = True  # GPUs Ampere+

# ─────────────────── Caminhos principais ────────────────────
TRAIN_DIR   = Path("/content/drive/MyDrive/PREPROCESSING_1s/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TREINO_VALID")
LABELS_PATH = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR   = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS_1/logmel_SR_mod_vit_mod")
MODEL_DIR.mkdir(parents=True, exist_ok=True)

CSV_METRICS = MODEL_DIR / "all_metrics.csv"
if not CSV_METRICS.exists():
    CSV_METRICS.write_text(
        "fold,epoch,band,var,rmse_t,mae_t,r2_t,pcc_t,rmse_v,mae_v,r2_v,pcc_v\n",
        encoding="utf-8"
    )

# ────────────────── Hiperparâmetros ──────────────────
FREQ_BANDS   = (125, 250, 500, 1000, 2000, 4000)
FREQUENCIES  = [str(b) for b in FREQ_BANDS]
C50_VARS     = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS     = [f"T60_{b}" for b in FREQ_BANDS]

BATCH_SIZE   = 16
EPOCHS       = 100
NUM_FOLDS    = 5
SEED         = 42
CLIP_NORM    = 1.0
DROPOUT_P    = 0.2

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ───────────────────── Dataset ──────────────────────
class SpectroDataset(Dataset):
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir

    def __len__(self) -> int:
        return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])  # [C,H,W]
        if x.shape[0] == 1:
            x = x.repeat(3, 1, 1)
        if x.shape[-2:] != (224, 224):
            x = F.interpolate(x.unsqueeze(0), 224,
                              mode="bilinear", align_corners=False).squeeze(0)
        y = torch.tensor(
            list(zip([row[v] for v in C50_VARS],
                     [row[v] for v in T60_VARS])),
            dtype=torch.float32
        )  # shape (6,2)
        return x, y

# ─────────────── Modelo ViT multitarefa ───────────────
class MultiHeadViT(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads = nn.Identity()
        self.backbone = vit
        feat_dim = vit.hidden_dim  # 768
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(DROPOUT_P),
                nn.Linear(hidden_dim, 2)
            ) for f in FREQUENCIES
        })

    def forward(self, x):
        feats = self.backbone(x)  # CLS token
        return {f: head(feats) for f, head in self.heads.items()}

# ──────────── Carrega labels ────────────
print("Lendo labels …")
df = pd.read_csv(LABELS_PATH)
df["tensor_filename"] = df["name"].str.replace(r"\.wav$", "", regex=True) + ".pt"
existing = {p.name for p in TRAIN_DIR.rglob("*.pt")}
df = df[df["tensor_filename"].isin(existing)].reset_index(drop=True)
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(subset=C50_VARS + T60_VARS, inplace=True)

kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)

# ───────────────────── Funções ─────────────────────
def stats(a, b):
    return (math.sqrt(mean_squared_error(a, b)),
            mean_absolute_error(a, b),
            r2_score(a, b),
            np.corrcoef(a, b)[0, 1])

def compute_metrics(pred, true, sc_c50, sc_t60):
    out = {}
    for f in FREQUENCIES:
        p = torch.vstack(pred[f]).cpu().numpy()
        t = torch.vstack(true[f]).cpu().numpy()
        p_c = sc_c50[f].inverse_transform(p[:, [0]]).ravel()
        t_c = sc_c50[f].inverse_transform(t[:, [0]]).ravel()
        p_t = sc_t60[f].inverse_transform(p[:, [1]]).ravel()
        t_t = sc_t60[f].inverse_transform(t[:, [1]]).ravel()
        out[f] = {"C50": stats(t_c, p_c), "T60": stats(t_t, p_t)}
    return out

def find_last_epoch(ckpt_dir: Path, fold: int) -> Tuple[int, Path, Path]:
    """Retorna (última_época, path_ckpt, path_opt) ou (0, None, None) se não houver."""
    pattern = re.compile(rf"fold{fold}_epoch(\d+)\.pth$")
    epochs = [(int(m.group(1)), p) for p in ckpt_dir.glob(f"fold{fold}_epoch*.pth")
              if (m := pattern.search(p.name))]
    if not epochs:
        return 0, None, None
    last_epoch, ckpt_path = max(epochs, key=lambda x: x[0])
    opt_path = ckpt_dir / f"fold{fold}_optim_latest.pth"
    return last_epoch, ckpt_path, opt_path if opt_path.exists() else None

# ─────────────────────── Loop ───────────────────────
for fold, (tr_idx, v_idx) in enumerate(kf.split(df), 1):
    print(f"\n══════════ FOLD {fold}/{NUM_FOLDS} ══════════")
    fold_dir   = MODEL_DIR / f"fold_{fold}"
    ckpt_dir   = fold_dir / "checkpoints"
    scaler_dir = fold_dir / "scalers"
    ckpt_dir.mkdir(parents=True, exist_ok=True)
    scaler_dir.mkdir(parents=True, exist_ok=True)

    train_df, val_df = df.iloc[tr_idx].copy(), df.iloc[v_idx].copy()

    scalers_c50, scalers_t60 = {}, {}
    for var in C50_VARS + T60_VARS:
        sc = StandardScaler().fit(train_df[[var]])
        (scaler_dir / f"scaler_{var}.pkl").write_bytes(pickle.dumps(sc))
        train_df[var] = sc.transform(train_df[[var]])
        val_df[var]   = sc.transform(val_df[[var]])
        band = var.split("_")[1]
        (scalers_c50 if var.startswith("C50") else scalers_t60)[band] = sc

    train_loader = DataLoader(
        SpectroDataset(train_df, TRAIN_DIR),
        batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True
    )
    val_loader = DataLoader(
        SpectroDataset(val_df, TRAIN_DIR),
        batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True
    )

    model = MultiHeadViT().to(device)
    criterion = nn.MSELoss()

    param_groups = (
        [{"params": model.backbone.parameters(), "lr": 3e-6, "weight_decay": 1e-4}] +
        [{"params": model.heads[f].parameters(), "lr": 3e-4, "weight_decay": 1e-2}
         for f in FREQUENCIES]
    )
    optimizer = optim.AdamW(param_groups, betas=(0.9, 0.999))

    # ─── NOVO: tentativa de retomada ───
    start_epoch = 1
    last_epoch, ckpt_path, opt_path = find_last_epoch(ckpt_dir, fold)
    if ckpt_path is not None:
        model.load_state_dict(torch.load(ckpt_path, map_location=device))
        if opt_path is not None:
            optimizer.load_state_dict(torch.load(opt_path, map_location=device))
            # garante compatibilidade de device nos estados do otimizador
            for state in optimizer.state.values():
                for k, v in state.items():
                    if torch.is_tensor(v):
                        state[k] = v.to(device)
        start_epoch = last_epoch + 1
        print(f">>> Retomando a partir da época {last_epoch} (checkpoint: {ckpt_path.name})")
    else:
        print(">>> Nenhum checkpoint encontrado — iniciando do zero")

    total_steps = len(train_loader) * EPOCHS
    scheduler = optim.lr_scheduler.OneCycleLR(
        optimizer,
        max_lr=[1e-4] + [5e-4]*6,
        pct_start=3/EPOCHS,
        div_factor=25, final_div_factor=1e3,
        total_steps=total_steps,
        last_epoch=(start_epoch - 2)  # ajusta para continuação correta
    )

    best_r2 = -float("inf")  # pode manter independentemente da retomada

    for epoch in range(start_epoch, EPOCHS + 1):
        # ---------- treino ----------
        model.train()
        pred_t = {f: [] for f in FREQUENCIES}
        true_t = {f: [] for f in FREQUENCIES}
        loss_sum = 0.0

        for x, y in tqdm(train_loader, desc=f"[F{fold}] Train {epoch}", leave=False):
            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)
            optimizer.zero_grad()
            outs = model(x)
            loss = sum(criterion(outs[f], y[:, i, :])
                       for i, f in enumerate(FREQUENCIES))
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)
            optimizer.step()
            scheduler.step()

            loss_sum += loss.item() * x.size(0)
            for i, f in enumerate(FREQUENCIES):
                pred_t[f].append(outs[f].detach().cpu())
                true_t[f].append(y[:, i, :].cpu())

        train_loss = loss_sum / len(train_loader.dataset)

        # ---------- validação ----------
        model.eval()
        pred_v = {f: [] for f in FREQUENCIES}
        true_v = {f: [] for f in FREQUENCIES}
        val_loss_sum = 0.0
        with torch.no_grad():
            for x, y in tqdm(val_loader, desc=f"[F{fold}] Val {epoch}", leave=False):
                x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)
                outs = model(x)
                for i, f in enumerate(FREQUENCIES):
                    pred_v[f].append(outs[f].cpu())
                    true_v[f].append(y[:, i, :].cpu())
                    val_loss_sum += criterion(outs[f], y[:, i, :]).item() * x.size(0)

        val_loss = val_loss_sum / len(val_loader.dataset)

        # ---------- métricas ----------
        train_m = compute_metrics(pred_t, true_t, scalers_c50, scalers_t60)
        val_m   = compute_metrics(pred_v, true_v, scalers_c50, scalers_t60)
        val_r2_mean = np.mean([val_m[b][v][2] for b in FREQUENCIES for v in ("C50","T60")])

        # ---------- checkpoints ----------
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_epoch{epoch}.pth")
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_latest.pth")
        torch.save(optimizer.state_dict(), ckpt_dir / f"fold{fold}_optim_latest.pth")
        if val_r2_mean > best_r2:
            best_r2 = val_r2_mean
            torch.save(model.state_dict(), fold_dir / "best.pth")

        # ---------- log ----------
        print(f"\n[Fold {fold}] Epoch {epoch}/{EPOCHS} — Train L={train_loss:.4f} | Val L={val_loss:.4f}")
        hdr = "Band | RMSE_t | MAE_t | R2_t  | PCC_t | RMSE_v | MAE_v | R2_v  | PCC_v"
        for var in ("C50", "T60"):
            print(f"─── {var} ───")
            print(hdr)
            print("-" * len(hdr))
            for f in FREQUENCIES:
                rt, mt, r2t, pcct = train_m[f][var]
                rv, mv, r2v, pccv = val_m[f][var]
                print(f"{f:>4} | {rt:6.3f} | {mt:6.3f} | "
                      f"{r2t:6.3f} | {pcct:6.3f} | "
                      f"{rv:6.3f} | {mv:6.3f} | "
                      f"{r2v:6.3f} | {pccv:6.3f}")
        print("=" * 80)

        # ---------- grava CSV ----------
        with CSV_METRICS.open("a", encoding="utf-8") as f_csv:
            for band in FREQUENCIES:
                for var in ("C50", "T60"):
                    rt, mt, r2t, pcct = train_m[band][var]
                    rv, mv, r2v, pccv = val_m[band][var]
                    f_csv.write(f"{fold},{epoch},{band},{var},"
                                f"{rt:.6f},{mt:.6f},{r2t:.6f},{pcct:.6f},"
                                f"{rv:.6f},{mv:.6f},{r2v:.6f},{pccv:.6f}\n")

print("\nTreinamento K-Fold concluído!")

"""teste completo"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
eval_multihead_frequency_vit_folds.py
─────────────────────────────────────
Avalia todos os folds do ViT multitarefa (cabeças por banda) treinado,
gera métricas por fold e ensemble, salva CSVs completos.
"""

import re, pickle, warnings
from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

# ─────────── CONFIGURAÇÃO ───────────
MODEL_DIR  = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_mod_vit_mod")
TEST_DIR   = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE")
LABELS_CSV = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
BATCH_SIZE = 16
NUM_FOLDS  = 5

FREQS      = [str(b) for b in (125, 250, 500, 1000, 2000, 4000)]
C50_VARS   = [f"C50_{b}" for b in FREQS]
T60_VARS   = [f"T60_{b}" for b in FREQS]

METRICS_FOLD_CSV    = MODEL_DIR / "metrics_folds.csv"
METRICS_ENSEMBLE_CSV= MODEL_DIR / "metrics_ensemble.csv"
RESULTS_FOLD_CSV    = MODEL_DIR / "preds_folds.csv"
RESULTS_ENSEMBLE_CSV= MODEL_DIR / "preds_ensemble.csv"

rmse = lambda a, b: np.sqrt(mean_squared_error(a, b))

def metrics(a, b):
    a = np.array(a)
    b = np.array(b)
    return (
        rmse(a, b),
        mean_absolute_error(a, b),
        r2_score(a, b),
        np.corrcoef(a, b)[0, 1] if a.std() and b.std() else 0.0
    )

def load_scalers(scaler_dir):
    sc_c50, sc_t60 = {}, {}
    for var in C50_VARS + T60_VARS:
        band = var.split("_")[1]
        scaler = pickle.load(open(scaler_dir / f"scaler_{var}.pkl", "rb"))
        (sc_c50 if var.startswith("C50") else sc_t60)[band] = scaler
    return sc_c50, sc_t60

def inverse_scale(preds, scalers):
    sc_c50, sc_t60 = scalers
    c50 = sc_c50.inverse_transform(preds[:, [0]]).ravel()
    t60 = sc_t60.inverse_transform(preds[:, [1]]).ravel()
    return c50, t60

class SpectroDataset(Dataset):
    def __init__(self, df, root):
        self.df  = df.reset_index(drop=True)
        self.root = Path(root)
    def __len__(self): return len(self.df)
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        x   = torch.load(self.root / row.tensor_filename)
        if x.shape[0] == 1:
            x = x.repeat(3, 1, 1)
        if x.shape[-2:] != (224, 224):
            x = F.interpolate(x.unsqueeze(0), 224, mode="bilinear", align_corners=False).squeeze(0)
        return x, idx

class MultiHeadModel(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads = nn.Identity()
        self.backbone = vit
        feat_dim = vit.hidden_dim
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(0.2),
                nn.Linear(hidden_dim, 2)
            ) for f in FREQS
        })
    def forward(self, x):
        feats = self.backbone(x)
        return {f: head(feats) for f, head in self.heads.items()}

def main():
    # 1) dataframe
    df = pd.read_csv(LABELS_CSV)
    df["tensor_filename"] = df["name"].str.replace(r"\.wav$", "", regex=True) + ".pt"
    keep = {p.name for p in TEST_DIR.rglob("*.pt")}
    df = df[df.tensor_filename.isin(keep)].reset_index(drop=True)

    # 2) DataLoader
    loader = DataLoader(SpectroDataset(df, TEST_DIR), BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 3) Armazenadores de predições
    preds_fold = [{b: {"C50": [], "T60": []} for b in FREQS} for _ in range(NUM_FOLDS)]

    # ----- loop pelos folds -----
    for fold in range(1, NUM_FOLDS + 1):
        print(f"\n════ Avaliando FOLD {fold}/{NUM_FOLDS} ════")
        fold_dir   = MODEL_DIR / f"fold_{fold}"
        ckpt_dir   = fold_dir / "checkpoints"
        scaler_dir = fold_dir / "scalers"

        # carregamento de scalers
        sc_c50, sc_t60 = load_scalers(scaler_dir)

        # carregamento de modelo
        model = MultiHeadModel().to(device)
        ckpt_path = ckpt_dir / f"fold{fold}_latest.pth"
        if not ckpt_path.exists():
            all_ckpt = list(ckpt_dir.glob(f"fold{fold}_epoch*.pth"))
            if not all_ckpt:
                raise FileNotFoundError(f"Nenhum checkpoint em {ckpt_dir}")
            ckpt_path = max(all_ckpt, key=lambda p: int(p.stem.split("epoch")[1]))
        model.load_state_dict(torch.load(ckpt_path, map_location=device))
        model.eval()
        print(f"  Checkpoint carregado: {ckpt_path.name}")

        # inferência
        with torch.no_grad():
            for x, idxs in tqdm(loader, desc=f"Inferência Fold {fold}", leave=False):
                x = x.to(device)
                outs = model(x)  # dict banda→(bs,2)
                for i, b in enumerate(FREQS):
                    preds = outs[b].cpu().numpy()
                    p_c50, p_t60 = inverse_scale(preds, (sc_c50[b], sc_t60[b]))
                    preds_fold[fold-1][b]["C50"].extend(p_c50.tolist())
                    preds_fold[fold-1][b]["T60"].extend(p_t60.tolist())

        # métricas do fold
        print("→ Métricas por banda (RMSE | MAE | R² | PCC):")
        with open(METRICS_FOLD_CSV, "a") as f_csv:
            for b in FREQS:
                for var in ("C50", "T60"):
                    y_true = df[f"{var}_{b}"].values
                    y_pred = preds_fold[fold-1][b][var]
                    rmse_, mae_, r2_, pcc_ = metrics(y_true, y_pred)
                    print(f" {var}_{b}: {rmse_:.4f} | {mae_:.4f} | {r2_:.4f} | {pcc_:.4f}")
                    f_csv.write(f"{fold},{b},{var},{rmse_:.6f},{mae_:.6f},{r2_:.6f},{pcc_:.6f}\n")

    # ---------- ensemble (média dos 5 folds) ----------
    print("\n════ Métricas do ENSEMBLE (média simples) ════")
    ensemble_preds = {b: {"C50": [], "T60": []} for b in FREQS}
    for idx in range(len(df)):
        for b in FREQS:
            ensemble_preds[b]["C50"].append(np.mean([preds_fold[f][b]["C50"][idx] for f in range(NUM_FOLDS)]))
            ensemble_preds[b]["T60"].append(np.mean([preds_fold[f][b]["T60"][idx] for f in range(NUM_FOLDS)]))

    with open(METRICS_ENSEMBLE_CSV, "a") as f_csv:
        for b in FREQS:
            for var in ("C50", "T60"):
                y_true = df[f"{var}_{b}"].values
                y_pred = ensemble_preds[b][var]
                rmse_, mae_, r2_, pcc_ = metrics(y_true, y_pred)
                print(f" {var}_{b}: {rmse_:.4f} | {mae_:.4f} | {r2_:.4f} | {pcc_:.4f}")
                f_csv.write(f"{b},{var},{rmse_:.6f},{mae_:.6f},{r2_:.6f},{pcc_:.6f}\n")

    # ---------- salvar CSVs de previsões ----------
    # por fold
    results_fold = {"name": df["tensor_filename"]}
    for fold in range(NUM_FOLDS):
        for b in FREQS:
            results_fold[f"C50_{b}_pred_fold{fold+1}"] = preds_fold[fold][b]["C50"]
            results_fold[f"T60_{b}_pred_fold{fold+1}"] = preds_fold[fold][b]["T60"]
    pd.DataFrame(results_fold).to_csv(RESULTS_FOLD_CSV, index=False)
    print(f"\nCSV por-fold salvo em: {RESULTS_FOLD_CSV}")

    # ensemble
    results_ens = {"name": df["tensor_filename"]}
    for b in FREQS:
        results_ens[f"C50_{b}_REAL"] = df[f"C50_{b}"]
        results_ens[f"T60_{b}_REAL"] = df[f"T60_{b}"]
        results_ens[f"C50_{b}_PRED"] = ensemble_preds[b]["C50"]
        results_ens[f"T60_{b}_PRED"] = ensemble_preds[b]["T60"]
    pd.DataFrame(results_ens).to_csv(RESULTS_ENSEMBLE_CSV, index=False)
    print(f"CSV ensemble salvo em: {RESULTS_ENSEMBLE_CSV}\n")

if __name__ == "__main__":
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=FutureWarning)
        main()

"""## GRADCAM"""

from google.colab import drive
drive.mount('/content/drive')

"""Fazendo de acordo com https://github.com/jacobgil/pytorch-grad-cam/blob/master/tutorials/vision_transformers.md"""

# ===========================================================
# eval_vit_multihead_folds_attention_rollout.py
# -----------------------------------------------------------
#  • Avalia K-folds do ViT multitarefa (C50, T60 em 6 bandas)
#  • Calcula métricas por fold e ensemble
#  • Gera mapas de calor Attention-Rollout (Abnar & Zuidema 2020)
#    - agora com barra de intensidade e eixos Frequency × Time
# ===========================================================

# 0) Garante PyTorch correto -----------------------------------------------
import subprocess, sys, importlib, warnings, re, pickle, math
from pathlib import Path
def ensure_torch():
    try:
        import torch, torchvision  # noqa: F401
        return
    except Exception:
        pass
    has_cuda = subprocess.run(['nvidia-smi'], capture_output=True).returncode == 0
    wheel    = "cu118" if has_cuda else "cpu"
    subprocess.check_call(
        [sys.executable, "-m", "pip", "install", "-q",
         "torch", "torchvision", "torchaudio",
         "--index-url", f"https://download.pytorch.org/whl/{wheel}"]
    )
    importlib.invalidate_caches()
ensure_torch()

# 1) Imports ---------------------------------------------------------------
import torch, numpy as np, pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import torch.nn as nn, torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

# 2) Diretórios -------------------------------------------------------------
MODEL_DIR  = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_mod_vit_mod")
TEST_DIR   = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE")
LABELS_CSV = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
OUT_ATTN   = MODEL_DIR / "attention_maps_02"; OUT_ATTN.mkdir(exist_ok=True, parents=True)

BATCH_SIZE = 16
NUM_FOLDS  = 5
FREQS      = [str(b) for b in (125, 250, 500, 1000, 2000, 4000)]
C50_VARS   = [f"C50_{b}" for b in FREQS]
T60_VARS   = [f"T60_{b}" for b in FREQS]
COMBOS     = C50_VARS + T60_VARS
GRID_SIDE  = 14           # ViT-B/16 -> 14×14 patches
TIME_MAX   = 5.0          # 5 s  (eixo X)
FREQ_MAX   = 8000         # 8 kHz (eixo Y)

# 3) Utilitários ------------------------------------------------------------
rmse = lambda a, b: np.sqrt(mean_squared_error(a, b))
def metrics(a, b):
    a, b = np.array(a), np.array(b)
    return (
        rmse(a, b),
        mean_absolute_error(a, b),
        r2_score(a, b),
        np.corrcoef(a, b)[0, 1] if a.std() and b.std() else 0.0
    )
def load_scalers(scaler_dir):
    sc_c50, sc_t60 = {}, {}
    for var in C50_VARS + T60_VARS:
        band   = var.split("_")[1]
        scaler = pickle.load(open(scaler_dir / f"scaler_{var}.pkl", "rb"))
        (sc_c50 if var.startswith("C50") else sc_t60)[band] = scaler
    return sc_c50, sc_t60
def inverse_scale(preds, scalers):
    sc_c50, sc_t60 = scalers
    return (sc_c50.inverse_transform(preds[:, [0]]).ravel(),
            sc_t60.inverse_transform(preds[:, [1]]).ravel())

# 4) Dataset ----------------------------------------------------------------
class SpectroDataset(Dataset):
    def __init__(self, df, root): self.df, self.root = df.reset_index(drop=True), Path(root)
    def __len__(self): return len(self.df)
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        x   = torch.load(self.root / row.tensor_filename)
        if x.shape[0] == 1: x = x.repeat(3, 1, 1)
        if x.shape[-2:] != (224, 224):
            x = F.interpolate(x.unsqueeze(0), 224, mode="bilinear", align_corners=False).squeeze(0)
        return x, idx

# 5) Modelo ViT multitarefa --------------------------------------------------
class MultiHeadModel(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1); vit.heads = nn.Identity()
        self.backbone = vit; feat_dim = vit.hidden_dim
        self.heads = nn.ModuleDict({f: nn.Sequential(
            nn.Linear(feat_dim, hidden_dim), nn.GELU(), nn.Dropout(0.20), nn.Linear(hidden_dim, 2)
        ) for f in FREQS})
    def forward(self, x):
        feats = self.backbone(x)
        return {f: head(feats) for f, head in self.heads.items()}

# 6) Attention-Rollout -------------------------------------------------------
def attention_rollout(model, x_single, grid_side=GRID_SIDE):
    """
    Devolve o mapa (grid_side × grid_side) com atenção agregada
    """
    attn_list, patched = [], []
    for blk in model.backbone.encoder.layers:
        mha = next((m for m in blk.modules() if isinstance(m, nn.MultiheadAttention)), None)
        if mha is None: raise AttributeError("MultiheadAttention não encontrado")
        orig_fwd = mha.forward
        def new_fwd(q, k, v, **kw):
            kw.pop("need_weights", None); kw.pop("average_attn_weights", None)
            out, w = orig_fwd(q, k, v, need_weights=True, average_attn_weights=False, **kw)
            attn_list.append(w.detach()); return out, w
        mha.forward = new_fwd; patched.append((mha, orig_fwd))
    _ = model(x_single.unsqueeze(0))
    for mha, orig in patched: mha.forward = orig
    N = attn_list[0].size(-1); eye = torch.eye(N, device=x_single.device); R = eye.clone()
    for att in attn_list:
        att = att.squeeze(0).mean(0); att = att + eye; att = att / att.sum(dim=-1, keepdim=True); R = att @ R
    mask = R[0, 1:].reshape(grid_side, grid_side)
    mask = (mask - mask.min()) / (mask.max() - mask.min() + 1e-8)
    return mask.cpu().numpy()

# 6-b) Salvamento dos mapas --------------------------------------------------
def save_heatmap(mask: np.ndarray, title: str, out_path: Path):
    """
    Salva dois PNGs:
      • <out_path>.png         → grade 14×14 original
      • <out_path>_ft.png      → eixo Frequency × Time (0-8 kHz, 0-5 s)
    Ambos com barra de intensidade (‘Attention intensity’)
    """
    # --- 1) Grade original --------------------------------------------------
    fig, ax = plt.subplots(figsize=(3, 3))
    im = ax.imshow(mask, cmap="inferno", origin="lower")
    ax.set_title(title, fontsize=10)
    ax.axis("off")
    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    cbar.set_label("Attention intensity", rotation=270, labelpad=10)
    fig.tight_layout()
    fig.savefig(out_path, dpi=300)
    plt.close(fig)

    # --- 2) Eixo Frequency × Time ------------------------------------------
    fig2, ax2 = plt.subplots(figsize=(4, 3))
    im2 = ax2.imshow(
        mask,
        cmap="inferno",
        origin="lower",
        extent=[0, TIME_MAX, 0, FREQ_MAX],   # x: 0-5 s, y: 0-8 kHz
        aspect="auto"
    )
    ax2.set_xlabel("Time (s)")
    ax2.set_ylabel("Frequency (Hz)")
    ax2.set_title(f"{title}  (Freq × Time)", fontsize=10)

    # ticks principais em posições inteiras (0-5 s) e (0-8 kHz)
    ax2.set_xticks(np.linspace(0, TIME_MAX, 6))
    ax2.set_yticks(np.linspace(0, FREQ_MAX, 5))
    cbar2 = fig2.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)
    cbar2.set_label("Attention intensity", rotation=270, labelpad=10)
    fig2.tight_layout()
    fig2.savefig(out_path.with_name(out_path.stem + "_ft.png"), dpi=300)
    plt.close(fig2)

# 7) Pipeline principal ------------------------------------------------------
def main():
    df = pd.read_csv(LABELS_CSV)
    df["tensor_filename"] = df["name"].str.replace(r"\.wav$", "", regex=True) + ".pt"
    df = df[df.tensor_filename.isin({p.name for p in TEST_DIR.rglob('*.pt')})].reset_index(drop=True)
    loader = DataLoader(SpectroDataset(df, TEST_DIR), BATCH_SIZE, shuffle=False, num_workers=0)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    preds_fold = [{b: {"C50": [], "T60": []} for b in FREQS} for _ in range(NUM_FOLDS)]
    last_ckpt = None

    # ---------- Inferência dos folds ---------------------------------------
    for fold in range(1, NUM_FOLDS + 1):
        print(f"\n════ Avaliando FOLD {fold}/{NUM_FOLDS} ════")
        fold_dir, ckpt_dir, scaler_dir = (
            MODEL_DIR / f"fold_{fold}",
            MODEL_DIR / f"fold_{fold}/checkpoints",
            MODEL_DIR / f"fold_{fold}/scalers",
        )
        sc_c50, sc_t60 = load_scalers(scaler_dir)

        ckpt_latest = ckpt_dir / f"fold{fold}_latest.pth"
        if ckpt_latest.exists():
            ckpt_path = ckpt_latest
        else:
            m = max(
                (
                    (int(m.group(1)), p)
                    for p in ckpt_dir.glob("fold*_epoch*.pth")
                    if (m := re.search(rf"fold{fold}_epoch(\d+)\.pth$", p.name))
                ),
                key=lambda t: t[0],
            )
            ckpt_path = m[1]

        print(f"  Checkpoint: {ckpt_path.name}")
        last_ckpt = ckpt_path
        model = MultiHeadModel().to(device)
        model.load_state_dict(torch.load(ckpt_path, map_location=device))
        model.eval()

        with torch.no_grad():
            for x, _ in tqdm(loader, desc=f"Inferência Fold {fold}", leave=False):
                outs = model(x.to(device))
                for b in FREQS:
                    p_c50, p_t60 = inverse_scale(outs[b].cpu().numpy(), (sc_c50[b], sc_t60[b]))
                    preds_fold[fold - 1][b]["C50"].extend(p_c50)
                    preds_fold[fold - 1][b]["T60"].extend(p_t60)

    # ---------- Ensemble ----------------------------------------------------
    ensemble = {
        b: {
            "C50": [np.mean([preds_fold[f][b]["C50"][i] for f in range(NUM_FOLDS)]) for i in range(len(df))],
            "T60": [np.mean([preds_fold[f][b]["T60"][i] for f in range(NUM_FOLDS)]) for i in range(len(df))],
        }
        for b in FREQS
    }

    print("\n════ Métricas do ENSEMBLE (média simples) ════")
    for b in FREQS:
        for var in ("C50", "T60"):
            rm, ma, r2, pc = metrics(df[f"{var}_{b}"], ensemble[b][var])
            print(f" {var}_{b}: RMSE={rm:.4f} | MAE={ma:.4f} | R²={r2:.4f} | PCC={pc:.4f}")

    # ---------- Attention-Rollout médio ------------------------------------
    print("\nGerando mapas de atenção …")
    model_attn = MultiHeadModel().to(device)
    model_attn.load_state_dict(torch.load(last_ckpt, map_location=device))
    model_attn.eval()

    acc_mask = np.zeros((GRID_SIDE, GRID_SIDE)); n_img = 0
    with torch.no_grad():
        for x, _ in tqdm(loader, desc="Attention-Rollout", leave=False):
            for img in x.to(device):
                acc_mask += attention_rollout(model_attn, img); n_img += 1
    mean_mask = acc_mask / max(n_img, 1)

    # Salva dois PNGs por combinação (original + freq×time)
    for combo in COMBOS:
        save_heatmap(mean_mask, combo, OUT_ATTN / f"{combo}.png")

    print(f"\nMapas salvos em: {OUT_ATTN.resolve()}")

# ---------------------------------------------------------------------------
if __name__ == "__main__":
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=FutureWarning)
        main()

#!/usr/bin/env python3
# ===========================================================
# eval_vit_multihead_folds_gradcam.py
# -----------------------------------------------------------
#  • Attention-Rollout global (Freq × Time)
#  • Grad-CAM banda-específico para T60 e/ou C50
#
#  Exemplo:
#      python eval_vit_multihead_folds_gradcam.py --ckpt_fold 1 --avg
#
#  FLAGS:
#      --ckpt_fold <1-5>     (padrão 1)
#      --tgt T60 | C50 | BOTH (padrão BOTH)
#      --avg                 média Grad-CAM sobre dataset
#      --skip_eval           pula rollout (gera só Grad-CAM)
# ===========================================================

# -------------------- 0) garante torch ---------------------
import subprocess, sys, importlib
def ensure_torch():
    try:
        import torch, torchvision  # noqa: F401
        return
    except ModuleNotFoundError:
        pass
    wheel = "cu118" if subprocess.run(
        ['nvidia-smi'], capture_output=True).returncode == 0 else "cpu"
    subprocess.check_call(
        [sys.executable, "-m", "pip", "install", "-q",
         "torch", "torchvision", "torchaudio",
         "--index-url", f"https://download.pytorch.org/whl/{wheel}"]
    )
    importlib.invalidate_caches()
ensure_torch()

# -------------------- 1) imports ---------------------------
import torch, torch.nn as nn, torch.nn.functional as F
import numpy as np, pandas as pd, re, argparse, warnings
import matplotlib.pyplot as plt
from torchvision import models
from torch.utils.data import Dataset, DataLoader
from tqdm.auto import tqdm
from pathlib import Path

# -------------------- 2) caminhos / const ------------------
MODEL_DIR  = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_mod_vit_mod")
TEST_DIR   = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE")
LABELS_CSV = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
OUT_DIR    = MODEL_DIR / "maps_GRADCAM"; OUT_DIR.mkdir(exist_ok=True, parents=True)

BATCH_SIZE = 16
FREQS      = [str(b) for b in (125, 250, 500, 1000, 2000, 4000)]
GRID_SIDE  = 14
TIME_MAX   = 5.0   # s
FREQ_MAX   = 8000  # Hz

# -------------------- 3) dataset ---------------------------
class SpectroDataset(Dataset):
    def __init__(self, df, root):
        self.df, self.root = df.reset_index(drop=True), Path(root)
    def __len__(self): return len(self.df)
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        x = torch.load(self.root / row.tensor_filename)
        if x.shape[0] == 1: x = x.repeat(3,1,1)
        if x.shape[-2:] != (224,224):
            x = F.interpolate(x.unsqueeze(0), 224,
                              mode="bilinear", align_corners=False).squeeze(0)
        return x, idx

# -------------------- 4) modelo ----------------------------
class MultiHeadModel(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads = nn.Identity()
        self.backbone = vit
        feat_dim = vit.hidden_dim
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(), nn.Dropout(0.2),
                nn.Linear(hidden_dim, 2))        # [C50, T60]
            for f in FREQS })
    def forward(self, x):
        feats = self.backbone(x)
        return {b: head(feats) for b, head in self.heads.items()}

# -------------------- 5) rollout ---------------------------
def attention_rollout(model, x_single):
    attn, patched = [], []
    for blk in model.backbone.encoder.layers:
        mha = next(m for m in blk.modules()
                   if isinstance(m, nn.MultiheadAttention))
        orig = mha.forward
        def hook(q,k,v,**kw):
            kw.pop("need_weights",None); kw.pop("average_attn_weights",None)
            out, w = orig(q,k,v,need_weights=True,
                          average_attn_weights=False, **kw)
            attn.append(w.detach()); return out,w
        mha.forward = hook; patched.append((mha,orig))
    _ = model(x_single.unsqueeze(0))
    for m,orig in patched: m.forward = orig

    eye = torch.eye(attn[0].size(-1), device=x_single.device)
    R = eye.clone()
    for A in attn:
        A = A.squeeze(0).mean(0)
        A = (A + eye) / (A + eye).sum(-1, keepdim=True)
        R = A @ R
    mask = R[0,1:].reshape(GRID_SIDE,GRID_SIDE)
    return ((mask - mask.min()) /
            (mask.max() - mask.min() + 1e-8)).cpu().numpy()

# -------------------- 6) grad-cam --------------------------
def gradcam(feature, grad):
    w   = grad.mean(dim=(2,3), keepdim=True)
    cam = torch.relu((w * feature).sum(dim=1))
    cam_min = cam.amin(dim=(1,2), keepdim=True)
    cam_max = cam.amax(dim=(1,2), keepdim=True)
    return (cam - cam_min) / (cam_max - cam_min + 1e-8)

# -------------------- 7) heatmap util ----------------------
def save_heatmap(mask, title, path,
                 cmap="inferno", label="Intensity"):
    fig, ax = plt.subplots(figsize=(4,3))
    im = ax.imshow(mask, cmap=cmap, origin="lower",
                   extent=[0,TIME_MAX, 0,FREQ_MAX], aspect="auto")
    ax.set_xlabel("Time (s)"); ax.set_ylabel("Frequency (Hz)")
    ax.set_title(title, fontsize=10)
    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    cbar.set_label(label, rotation=270, labelpad=10)
    fig.tight_layout(); fig.savefig(path, dpi=300); plt.close(fig)

# -------------------- 8) grad-cam loop ---------------------
def generate_gradcams(model, loader, idx_target, avg, prefix):
    device = next(model.parameters()).device
    cams = {b: [] for b in FREQS}

    feats, grads = [], []
    def fwd(_,__,out): feats.append(out.detach())
    def bwd(_,g_in,g_out): grads.append(g_out[0].detach())
    h1 = model.backbone.conv_proj.register_forward_hook(fwd)
    h2 = model.backbone.conv_proj.register_full_backward_hook(bwd)

    for x,_ in tqdm(loader, desc=f"Grad-CAM {prefix}"):
        x = x.to(device); x.requires_grad_(True)
        outs = model(x)

        for band in FREQS:
            grads.clear()
            score = outs[band][:, idx_target].sum()
            model.zero_grad(set_to_none=True)
            score.backward(retain_graph=True)
            cams[band].append(gradcam(feats[-1], grads[-1]).cpu())

        feats.clear()                       # libera memória lote
        x.requires_grad_(False); torch.cuda.empty_cache()

    h1.remove(); h2.remove()

    for band, lst in cams.items():
        cam = torch.stack(lst)              # (num_batches, B, 14,14)
        cam = cam.mean(dim=(0,1)) if avg else cam[0,0]
        save_heatmap(cam.numpy(),
                     f"{prefix}_{band} Grad-CAM",
                     OUT_DIR/f"{prefix}_{band}_gradcam.png",
                     label="Grad-CAM intensity")

# -------------------- 9) main --------------------------------------------
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--ckpt_fold", type=int, default=1)
    ap.add_argument("--tgt", choices=["T60","C50","BOTH"], default="BOTH")
    ap.add_argument("--avg", action="store_true")
    ap.add_argument("--skip_eval", action="store_true")
    args,_ = ap.parse_known_args()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # dataframe teste
    df = pd.read_csv(LABELS_CSV)
    df["tensor_filename"] = df["name"].str.replace(r"\.wav$","",regex=True)+".pt"
    df = df[df.tensor_filename.isin({p.name for p in TEST_DIR.rglob("*.pt")})]
    loader = DataLoader(SpectroDataset(df, TEST_DIR),
                        BATCH_SIZE, shuffle=False, num_workers=0)

    # modelo + ckpt
    ckdir = MODEL_DIR/f"fold_{args.ckpt_fold}/checkpoints"
    ckpt  = ckdir/f"fold{args.ckpt_fold}_latest.pth"
    if not ckpt.exists():
        ckpt = max(ckdir.glob(f"fold{args.ckpt_fold}_epoch*.pth"),
                   key=lambda p:int(re.search(r"epoch(\d+)", p.name).group(1)))
    print("Checkpoint:", ckpt.name)
    model = MultiHeadModel().to(device)
    model.load_state_dict(torch.load(ckpt, map_location=device))
    model.eval()

    # rollout
    if not args.skip_eval:
        acc, n = np.zeros((GRID_SIDE,GRID_SIDE)), 0
        with torch.no_grad():
            for x,_ in tqdm(loader, desc="Attention-Rollout"):
                for img in x.to(device):
                    acc += attention_rollout(model, img); n += 1
        save_heatmap(acc/max(n,1),
                     "Attention-Rollout (mean)",
                     OUT_DIR/"attention_rollout_mean.png")
        print("Rollout salvo:", OUT_DIR/"attention_rollout_mean.png")

    # grad-cams
    tgt_map = {"T60":1,"C50":0} if args.tgt!="BOTH" else {"T60":1,"C50":0}
    for tag, idx in tgt_map.items():
        generate_gradcams(model, loader,
                          idx_target=idx,
                          avg=args.avg,
                          prefix=tag)
    print("\n✓ Mapas salvos em", OUT_DIR.resolve())

# -------------------- 10) run --------------------------------------------
if __name__ == "__main__":
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=FutureWarning)
        main()

"""### EXTRAINDO VETORES"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
eval_vit_multihead_folds_gradcam.py
────────────────────────────────────────────────────────────────────────────
• Métricas RMSE | MAE | R² | PCC por fold + ensemble
• Attention-Rollout global (Freq × Time)
• Grad-CAM banda-específico p/ T60 e C50
    – mapa médio (ou 1 amostra)
    – overlay CAM + espectrograma (12 png)
    – **CSV (196 valores) por amostra**            ← ADICIONADO
Ex.: python eval_vit_multihead_folds_gradcam.py --ckpt_fold 1 --avg
Flags:
    --ckpt_fold 1-5   /  --tgt T60|C50|BOTH   /  --avg   /  --skip_eval
"""
# ───────────────────────── 0 ▸ garante PyTorch ────────────────────────────
import subprocess, sys, importlib, warnings
def ensure_torch():
    try:
        import torch, torchvision  # noqa: F401
        return
    except ModuleNotFoundError:
        pass
    wheel = "cu118" if subprocess.run(['nvidia-smi'],
                                      capture_output=True).returncode == 0 else "cpu"
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q",
                           "torch", "torchvision", "torchaudio",
                           "--index-url", f"https://download.pytorch.org/whl/{wheel}"])
    importlib.invalidate_caches()
ensure_torch()

# ───────────────────────── 1 ▸ imports ────────────────────────────────────
import torch, torch.nn as nn, torch.nn.functional as F
import numpy as np, pandas as pd, pickle, re, argparse, math
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
from torchvision import models
from torch.utils.data import Dataset, DataLoader
from tqdm.auto import tqdm
from pathlib import Path

# ───────────────────────── 2 ▸ caminhos / constantes ──────────────────────
MODEL_DIR  = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_mod_vit_mod")
TEST_DIR   = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE")
LABELS_CSV = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
OUT_DIR    = MODEL_DIR / "maps_GRADCAM_TOTAL_01_VECTORS"; OUT_DIR.mkdir(exist_ok=True, parents=True)

BATCH_SIZE = 16
NUM_FOLDS  = 5
FREQS      = [str(b) for b in (125, 250, 500, 1000, 2000, 4000)]
GRID_SIDE  = 14
TIME_MAX   = 5.0    # s
FREQ_MAX   = 8000   # Hz

# ───────────────────────── 3 ▸ dataset ─────────────────────────────────────
class SpectroDataset(Dataset):
    def __init__(self, df, root):
        self.df, self.root = df.reset_index(drop=True), Path(root)
    def __len__(self): return len(self.df)
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        x = torch.load(self.root / row.tensor_filename)
        if x.shape[0] == 1:                       # ↑ garante 3 canais
            x = x.repeat(3,1,1)
        if x.shape[-2:] != (224,224):             # ↑ resize p/ ViT
            x = F.interpolate(x.unsqueeze(0), 224,
                              mode="bilinear", align_corners=False).squeeze(0)
        fname = row.tensor_filename.replace(".pt","")  # sem extensão
        return x, fname                           # ← devolve nome

# ───────────────────────── 4 ▸ modelo ─────────────────────────────────────
class MultiHeadModel(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads = nn.Identity()
        self.backbone = vit
        feat_dim = vit.hidden_dim
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(), nn.Dropout(0.2),
                nn.Linear(hidden_dim, 2))           # [C50, T60]
            for f in FREQS})
    def forward(self, x):
        feats = self.backbone(x)
        return {b: head(feats) for b, head in self.heads.items()}

# ───────────────────────── 5 ▸ rollout ────────────────────────────────────
def attention_rollout(model, x_single):
    attn, patched = [], []
    for blk in model.backbone.encoder.layers:
        mha = next(m for m in blk.modules()
                   if isinstance(m, nn.MultiheadAttention))
        orig = mha.forward
        def hook(q,k,v,**kw):
            kw.pop("need_weights",None); kw.pop("average_attn_weights",None)
            out,w = orig(q,k,v,need_weights=True,
                         average_attn_weights=False, **kw)
            attn.append(w.detach()); return out,w
        mha.forward = hook; patched.append((mha,orig))
    _ = model(x_single.unsqueeze(0))
    for m,orig in patched: m.forward = orig
    eye = torch.eye(attn[0].size(-1), device=x_single.device)
    R = eye.clone()
    for A in attn:
        A = A.squeeze(0).mean(0)
        A = (A+eye)/(A+eye).sum(-1,keepdim=True)
        R = A @ R
    M = R[0,1:].reshape(GRID_SIDE,GRID_SIDE)
    return ((M-M.min())/(M.max()-M.min()+1e-8)).cpu().numpy()

# ───────────────────────── 6 ▸ grad-cam util ──────────────────────────────
def gradcam(feature, grad):
    w = grad.mean(dim=(2,3), keepdim=True)
    cam = torch.relu((w*feature).sum(dim=1))
    cam_min, cam_max = cam.amin((1,2),True), cam.amax((1,2),True)
    return (cam-cam_min)/(cam_max-cam_min+1e-8)   # (B,14,14)

# ───────────────────────── 7 ▸ métricas & escalares ───────────────────────
rmse = lambda a,b: math.sqrt(mean_squared_error(a,b))
def metrics(a,b):
    a,b = np.asarray(a), np.asarray(b)
    return rmse(a,b), mean_absolute_error(a,b), r2_score(a,b), \
           (np.corrcoef(a,b)[0,1] if a.std() and b.std() else 0.)
def load_scalers(dir_):
    sc_c50, sc_t60 = {}, {}
    for var in [f"C50_{b}" for b in FREQS]+[f"T60_{b}" for b in FREQS]:
        band = var.split("_")[1]
        sc   = pickle.load(open(dir_/f"scaler_{var}.pkl","rb"))
        (sc_c50 if var.startswith("C50") else sc_t60)[band] = sc
    return sc_c50, sc_t60
def inv_scale(preds, scalers):
    sc_c50, sc_t60 = scalers
    return (sc_c50.inverse_transform(preds[:,[0]]).ravel(),
            sc_t60.inverse_transform(preds[:,[1]]).ravel())

# ───────────────────────── 8 ▸ heatmap util ───────────────────────────────
def save_heatmap(mask, title, path, cmap="inferno", label="Intensity",
                 overlay=None):
    fig, ax = plt.subplots(figsize=(4,3))
    if overlay is not None:
        ax.imshow(overlay, cmap="gray", origin="lower",
                  extent=[0,TIME_MAX,0,FREQ_MAX], aspect="auto")
    im = ax.imshow(mask, cmap=cmap, origin="lower",
                   extent=[0,TIME_MAX,0,FREQ_MAX], aspect="auto", alpha=0.6)
    ax.set_xlabel("Time (s)"); ax.set_ylabel("Frequency (Hz)")
    ax.set_title(title, fontsize=10)
    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    cbar.set_label(label, rotation=270, labelpad=10)
    fig.tight_layout(); fig.savefig(path, dpi=300); plt.close(fig)

# ───────────────────────── 9 ▸ grad-cam + overlay + CSV ───────────────────
def generate_gradcams(model, loader, idx_target, avg, prefix):
    """
    • Salva heatmaps & overlays como antes;
    • Agora também gera CSV "patch_vectors_{prefix}.csv" com:
        filename, patch_0 … patch_195
    """
    device = next(model.parameters()).device
    cams, overlays = {b: [] for b in FREQS}, {}
    feats, grads = [], []

    # lista que acumula [filename, 196 valores]
    rows_csv = []

    # hooks p/ capturar feature map + gradiente
    def fwd(_,__,o): feats.append(o.detach())
    def bwd(_,g_in,g_out): grads.append(g_out[0].detach())
    h1 = model.backbone.conv_proj.register_forward_hook(fwd)
    h2 = model.backbone.conv_proj.register_full_backward_hook(bwd)

    saved_overlay = {b: False for b in FREQS}

    for x, names in tqdm(loader, desc=f"Grad-CAM {prefix}"):
        x = x.to(device); x.requires_grad_(True)
        outs = model(x)

        for band in FREQS:
            grads.clear()
            score = outs[band][:, idx_target].sum()
            model.zero_grad(set_to_none=True)
            score.backward(retain_graph=True)

            cam_single = gradcam(feats[-1], grads[-1])          # (B,14,14)
            cams[band].append(cam_single.cpu())

            # ---------- vetor 196 patches por amostra ----------
            for i, fname in enumerate(names):
                rows_csv.append(
                    [fname] + cam_single[i].flatten().cpu().tolist()
                )

            # ---------- overlay (1ª amostra) ----------
            if not saved_overlay[band]:
                spec = x[0,0].detach().cpu().numpy()
                spec = (spec-spec.min())/(spec.max()-spec.min()+1e-8)
                overlays[band] = (cam_single[0].cpu().numpy(), spec)
                saved_overlay[band] = True

        feats.clear()
        x.requires_grad_(False); torch.cuda.empty_cache()

    h1.remove(); h2.remove()

    # -------- grava CSV com os vetores de patch --------
    csv_path = OUT_DIR / f"patch_vectors_{prefix}.csv"
    header = ["filename"] + [f"patch_{i}" for i in range(GRID_SIDE*GRID_SIDE)]
    pd.DataFrame(rows_csv, columns=header).to_csv(csv_path, index=False)

    # -------- salva heatmaps & overlays como antes -----
    for band,lst in cams.items():
        cam_stack = torch.stack(lst)                          # (N,B,14,14)
        cam_final = cam_stack.mean((0,1)) if avg else cam_stack[0,0]
        save_heatmap(cam_final.numpy(),
                     f"{prefix}_{band} Grad-CAM",
                     OUT_DIR/f"{prefix}_{band}_gradcam.png",
                     label="Grad-CAM intensity")
        heat,spec = overlays[band]
        save_heatmap(heat, f"{prefix}_{band} Overlay",
                     OUT_DIR/f"{prefix}_{band}_overlay.png",
                     label="Grad-CAM intensity", overlay=spec)

# ───────────────────────── 10 ▸ main ──────────────────────────────────────
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--ckpt_fold", type=int, default=1)
    ap.add_argument("--tgt", choices=["T60","C50","BOTH"], default="BOTH")
    ap.add_argument("--avg", action="store_true")
    ap.add_argument("--skip_eval", action="store_true")
    args,_ = ap.parse_known_args()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # -------- prepara DataFrame + DataLoader ----------
    df = pd.read_csv(LABELS_CSV)
    df["tensor_filename"] = df["name"].str.replace(r"\.wav$","",regex=True)+".pt"
    df = df[df.tensor_filename.isin({p.name for p in TEST_DIR.rglob("*.pt")})]
    loader = DataLoader(SpectroDataset(df, TEST_DIR),
                        BATCH_SIZE, shuffle=False, num_workers=0)

    preds_fold = [{b: {"C50": [], "T60": []} for b in FREQS}
                  for _ in range(NUM_FOLDS)]
    last_ckpt = None

    # ---------- métricas por fold ----------------------------------------
    for fold in range(1, NUM_FOLDS+1):
        ckdir = MODEL_DIR/f"fold_{fold}/checkpoints"
        ckpt  = ckdir/f"fold{fold}_latest.pth"
        if not ckpt.exists():
            ckpt = max(ckdir.glob(f"fold{fold}_epoch*.pth"),
                       key=lambda p:int(re.search(r"epoch(\d+)",p.name).group(1)))
        last_ckpt = ckpt
        model = MultiHeadModel().to(device)
        model.load_state_dict(torch.load(ckpt, map_location=device))
        model.eval()

        sc_c50, sc_t60 = load_scalers(MODEL_DIR/f"fold_{fold}/scalers")
        with torch.no_grad():
            for x,_ in loader:
                outs = model(x.to(device))
                for b in FREQS:
                    p_c50, p_t60 = inv_scale(outs[b].cpu().numpy(),
                                             (sc_c50[b], sc_t60[b]))
                    preds_fold[fold-1][b]["C50"].extend(p_c50)
                    preds_fold[fold-1][b]["T60"].extend(p_t60)

        print(f"\n════ Métricas FOLD {fold} ════")
        for b in FREQS:
            for var in ("C50","T60"):
                rm,ma,r2,pc = metrics(df[f"{var}_{b}"],
                                       preds_fold[fold-1][b][var])
                print(f" {var}_{b}: RMSE={rm:.4f} | MAE={ma:.4f} | "
                      f"R²={r2:.4f} | PCC={pc:.4f}")

    # ---------- ensemble --------------------------------------------------
    ens = {b: {"C50":[], "T60":[]} for b in FREQS}
    for b in FREQS:
        for var in ("C50","T60"):
            ens[b][var] = [np.mean([preds_fold[f][b][var][i]
                                    for f in range(NUM_FOLDS)])
                           for i in range(len(df))]
    print("\n════ Métricas ENSEMBLE (média simples) ════")
    for b in FREQS:
        for var in ("C50","T60"):
            rm,ma,r2,pc = metrics(df[f"{var}_{b}"], ens[b][var])
            print(f" {var}_{b}: RMSE={rm:.4f} | MAE={ma:.4f} | "
                  f"R²={r2:.4f} | PCC={pc:.4f}")

    # ---------- attention-rollout global ----------------------------------
    if not args.skip_eval:
        model = MultiHeadModel().to(device)
        model.load_state_dict(torch.load(last_ckpt, map_location=device))
        model.eval()
        acc,n = np.zeros((GRID_SIDE,GRID_SIDE)), 0
        with torch.no_grad():
            for x,_ in tqdm(loader, desc="Attention-Rollout"):
                for img in x.to(device):
                    acc += attention_rollout(model, img); n += 1
        save_heatmap(acc/max(n,1),
                     "Attention-Rollout (mean)",
                     OUT_DIR/"attention_rollout_mean.png",
                     label="Rollout intensity")

    # ---------- grad-cam + overlay + CSV ----------------------------------
    model = MultiHeadModel().to(device)
    model.load_state_dict(torch.load(last_ckpt, map_location=device))
    model.eval()
    tgt_map = {"T60":1,"C50":0} if args.tgt!="BOTH" else {"T60":1,"C50":0}
    for tag,idx in tgt_map.items():
        generate_gradcams(model, loader,
                          idx_target=idx,
                          avg=args.avg,
                          prefix=tag)

    print("\n✓ Resultados salvos em:", OUT_DIR.resolve())

# ───────────────────────── 11 ▸ run ───────────────────────────────────────
if __name__ == "__main__":
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=FutureWarning)
        main()

# cluster_by_band_kmeans_withplots.py
# --------------------------------------------------------------------
# Igual ao script de clustering anterior, mas:
#   • Salva PNG do mapa médio DE CADA CLUSTER
#     – resolução 224×224 px (14×14 up-sample “nearest”)
#     – barra de intensidade, eixos e título no estilo do exemplo.
# --------------------------------------------------------------------
import pandas as pd, numpy as np
from pathlib import Path
from tqdm.auto import tqdm
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# ------------- caminhos -------------
BASE = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/"
            "logmel_SR_mod_vit_mod/maps_GRADCAM_TOTAL_01_VECTORS")
FILES = { "C50": BASE / "patch_vectors_C50.csv",
          "T60": BASE / "patch_vectors_T60.csv" }
BANDS = ["125","250","500","1000","2000","4000"]
OUT   = BASE / "cluster_heatmaps_labeled"
OUT.mkdir(exist_ok=True, parents=True)

# ------------- hiper -------------
K_MIN, K_MAX = 2, 12
FIG_DPI      = 250             # controla resolução do PNG
TIME_MAX     = 5.0             # usado em extent
FREQ_MAX     = 8000
# ----------------------------------

def ensure_band(df):
    if "band" not in df.columns:
        reps = len(df) // 6
        df.insert(1, "band", BANDS * reps)
    return df

def preprocess(X):
    X = X / (X.max(1,keepdims=True)+1e-8)
    X = StandardScaler().fit_transform(X)
    return PCA(0.95).fit_transform(X)

def best_kmeans(X):
    best_s, best_lab, best_k = -1, None, None
    for k in range(K_MIN, K_MAX+1):
        lab = KMeans(k, n_init=10, random_state=42).fit_predict(X)
        s   = silhouette_score(X, lab) if k>1 else -1
        if s > best_s: best_s, best_lab, best_k = s, lab, k
    return best_k, best_s, best_lab

def save_heat(arr14, title, path):
    upscale = 16                               # 14×16 ≃ 224 px
    big = np.kron(arr14, np.ones((upscale,upscale)))
    fig, ax = plt.subplots(figsize=(4,3), dpi=FIG_DPI)
    im = ax.imshow(big, cmap="inferno", origin="lower",
                   extent=[0, TIME_MAX, 0, FREQ_MAX], aspect="auto")
    ax.set_xlabel("Time (s)");  ax.set_ylabel("Frequency (Hz)")
    ax.set_title(title, fontsize=10)
    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    cbar.set_label("Intensity", rotation=270, labelpad=8)
    fig.tight_layout()
    fig.savefig(path, dpi=FIG_DPI)
    plt.close(fig)

# ------------- main loop -------------
for tag, csv in FILES.items():
    print(f"\n=== {tag} ===")
    df_all = ensure_band(pd.read_csv(csv))

    for band in tqdm(BANDS, desc=f"{tag} | bandas"):
        sub = df_all[df_all.band==band].reset_index(drop=True)
        X   = sub.filter(like="patch_").values.astype(np.float32)
        Xp  = preprocess(X)
        k_opt, sil, labels = best_kmeans(Xp)

        # salva CSV rotulado
        out_csv = csv.with_name(f"{tag}_{band}Hz_k{k_opt}.csv")
        pd.DataFrame({"filename":sub.filename, "band":band,
                      "cluster":labels}).to_csv(out_csv,index=False)

        print(f"  {band} Hz → k={k_opt}, silhouette={sil:.3f}")

        # gera e salva o mapa médio de cada cluster
        for cid in range(k_opt):
            mask = labels == cid
            if not mask.any(): continue
            mean_map = X[mask].mean(0).reshape(14,14)
            out_dir  = OUT / tag / band
            out_dir.mkdir(parents=True, exist_ok=True)
            fname = out_dir / f"cluster_{cid}_k{k_opt}.png"
            save_heat(mean_map,
                      f"{tag} {band} Hz – cluster {cid}",
                      fname)

print("\n✓ Mapas médios + CSVs em:", OUT.resolve())









"""### ANÁLISE COMPLETA COM GRAD-CAM E TESTE"""

from google.colab import drive
drive.mount('/content/drive')

#!/usr/bin/env python3
# ===========================================================
# eval_vit_multihead_folds_gradcam.py
# -----------------------------------------------------------
#  • Métricas RMSE | MAE | R² | PCC por fold + ensemble
#  • Attention-Rollout global (Freq × Time)
#  • Grad-CAM banda-específico p/ T60 e C50
#      – mapa médio (ou 1 amostra)
#      – overlay CAM + espectrograma (12 png)
#
#  Ex.:   python eval_vit_multihead_folds_gradcam.py --ckpt_fold 1 --avg
#  Flags:
#      --ckpt_fold 1-5   /  --tgt T60|C50|BOTH   /  --avg   /  --skip_eval
# ===========================================================

# 0 ▸ garante PyTorch -------------------------------------------------------
import subprocess, sys, importlib, warnings
def ensure_torch():
    try:
        import torch, torchvision  # noqa: F401
        return
    except ModuleNotFoundError:
        pass
    wheel = "cu118" if subprocess.run(['nvidia-smi'],
                                      capture_output=True).returncode == 0 else "cpu"
    subprocess.check_call(
        [sys.executable, "-m", "pip", "install", "-q",
         "torch", "torchvision", "torchaudio",
         "--index-url", f"https://download.pytorch.org/whl/{wheel}"])
    importlib.invalidate_caches()
ensure_torch()

# 1 ▸ imports ---------------------------------------------------------------
import torch, torch.nn as nn, torch.nn.functional as F
import numpy as np, pandas as pd, pickle, re, argparse, math
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
from torchvision import models
from torch.utils.data import Dataset, DataLoader
from tqdm.auto import tqdm
from pathlib import Path

# 2 ▸ caminhos / constantes -------------------------------------------------
MODEL_DIR  = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_mod_vit_mod")
TEST_DIR   = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE")
LABELS_CSV = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
OUT_DIR    = MODEL_DIR / "maps_GRADCAM_TOTAL_01"; OUT_DIR.mkdir(exist_ok=True, parents=True)

BATCH_SIZE = 16
NUM_FOLDS  = 5
FREQS      = [str(b) for b in (125, 250, 500, 1000, 2000, 4000)]
GRID_SIDE  = 14
TIME_MAX   = 5.0     # s
FREQ_MAX   = 8000    # Hz

# 3 ▸ dataset ---------------------------------------------------------------
class SpectroDataset(Dataset):
    def __init__(self, df, root):
        self.df, self.root = df.reset_index(drop=True), Path(root)
    def __len__(self): return len(self.df)
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        x = torch.load(self.root / row.tensor_filename)
        if x.shape[0] == 1: x = x.repeat(3,1,1)
        if x.shape[-2:] != (224,224):
            x = F.interpolate(x.unsqueeze(0), 224,
                              mode="bilinear", align_corners=False).squeeze(0)
        return x, idx

# 4 ▸ modelo ----------------------------------------------------------------
class MultiHeadModel(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads = nn.Identity()
        self.backbone = vit
        feat_dim = vit.hidden_dim
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(), nn.Dropout(0.2),
                nn.Linear(hidden_dim, 2))           # [C50, T60]
            for f in FREQS})
    def forward(self, x):
        feats = self.backbone(x)
        return {b: head(feats) for b, head in self.heads.items()}

# 5 ▸ rollout ---------------------------------------------------------------
def attention_rollout(model, x_single):
    attn, patched = [], []
    for blk in model.backbone.encoder.layers:
        mha = next(m for m in blk.modules()
                   if isinstance(m, nn.MultiheadAttention))
        orig = mha.forward
        def hook(q,k,v,**kw):
            kw.pop("need_weights",None); kw.pop("average_attn_weights",None)
            out,w = orig(q,k,v,need_weights=True,
                         average_attn_weights=False, **kw)
            attn.append(w.detach()); return out,w
        mha.forward = hook; patched.append((mha,orig))
    _ = model(x_single.unsqueeze(0))
    for m,orig in patched: m.forward = orig
    eye = torch.eye(attn[0].size(-1), device=x_single.device)
    R = eye.clone()
    for A in attn:
        A = A.squeeze(0).mean(0)
        A = (A+eye)/(A+eye).sum(-1,keepdim=True)
        R = A @ R
    M = R[0,1:].reshape(GRID_SIDE,GRID_SIDE)
    return ((M-M.min())/(M.max()-M.min()+1e-8)).cpu().numpy()

# 6 ▸ grad-cam util ---------------------------------------------------------
def gradcam(feature, grad):
    w = grad.mean(dim=(2,3), keepdim=True)
    cam = torch.relu((w*feature).sum(dim=1))
    cam_min, cam_max = cam.amin((1,2),True), cam.amax((1,2),True)
    return (cam-cam_min)/(cam_max-cam_min+1e-8)

# 7 ▸ métricas & escalares --------------------------------------------------
rmse = lambda a,b: math.sqrt(mean_squared_error(a,b))
def metrics(a,b):
    a,b = np.asarray(a), np.asarray(b)
    return rmse(a,b), mean_absolute_error(a,b), r2_score(a,b), \
           (np.corrcoef(a,b)[0,1] if a.std() and b.std() else 0.)
def load_scalers(dir_):
    sc_c50, sc_t60 = {}, {}
    for var in [f"C50_{b}" for b in FREQS]+[f"T60_{b}" for b in FREQS]:
        band = var.split("_")[1]
        sc   = pickle.load(open(dir_/f"scaler_{var}.pkl","rb"))
        (sc_c50 if var.startswith("C50") else sc_t60)[band] = sc
    return sc_c50, sc_t60
def inv_scale(preds, scalers):
    sc_c50, sc_t60 = scalers
    return (sc_c50.inverse_transform(preds[:,[0]]).ravel(),
            sc_t60.inverse_transform(preds[:,[1]]).ravel())

# 8 ▸ heatmap util ----------------------------------------------------------
def save_heatmap(mask, title, path, cmap="inferno", label="Intensity",
                 overlay=None):
    fig, ax = plt.subplots(figsize=(4,3))
    if overlay is not None:
        ax.imshow(overlay, cmap="gray", origin="lower",
                  extent=[0,TIME_MAX,0,FREQ_MAX], aspect="auto")
    im = ax.imshow(mask, cmap=cmap, origin="lower",
                   extent=[0,TIME_MAX,0,FREQ_MAX], aspect="auto", alpha=0.6)
    ax.set_xlabel("Time (s)"); ax.set_ylabel("Frequency (Hz)")
    ax.set_title(title, fontsize=10)
    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    cbar.set_label(label, rotation=270, labelpad=10)
    fig.tight_layout(); fig.savefig(path, dpi=300); plt.close(fig)

# 9 ▸ grad-cam + overlay ----------------------------------------------------
def generate_gradcams(model, loader, idx_target, avg, prefix):
    device = next(model.parameters()).device
    cams, overlays = {b: [] for b in FREQS}, {}
    feats, grads = [], []
    def fwd(_,__,o): feats.append(o.detach())
    def bwd(_,g_in,g_out): grads.append(g_out[0].detach())
    h1 = model.backbone.conv_proj.register_forward_hook(fwd)
    h2 = model.backbone.conv_proj.register_full_backward_hook(bwd)
    saved_overlay = {b: False for b in FREQS}

    for x,_ in tqdm(loader, desc=f"Grad-CAM {prefix}"):
        x = x.to(device); x.requires_grad_(True)
        outs = model(x)
        for band in FREQS:
            grads.clear()
            score = outs[band][:, idx_target].sum()
            model.zero_grad(set_to_none=True)
            score.backward(retain_graph=True)
            cam_single = gradcam(feats[-1], grads[-1])
            cams[band].append(cam_single.cpu())
            if not saved_overlay[band]:
                spec = x[0,0].detach().cpu().numpy()                # ← detach
                spec = (spec-spec.min())/(spec.max()-spec.min()+1e-8)
                overlays[band] = (cam_single[0].cpu().numpy(), spec)
                saved_overlay[band] = True
        feats.clear()
        x.requires_grad_(False); torch.cuda.empty_cache()
    h1.remove(); h2.remove()

    for band,lst in cams.items():
        cam_stack = torch.stack(lst)                    # (N,B,14,14)
        cam_final = cam_stack.mean((0,1)) if avg else cam_stack[0,0]
        save_heatmap(cam_final.numpy(),
                     f"{prefix}_{band} Grad-CAM",
                     OUT_DIR/f"{prefix}_{band}_gradcam.png",
                     label="Grad-CAM intensity")
        heat,spec = overlays[band]
        save_heatmap(heat, f"{prefix}_{band} Overlay",
                     OUT_DIR/f"{prefix}_{band}_overlay.png",
                     label="Grad-CAM intensity", overlay=spec)

# 10 ▸ main ----------------------------------------------------------------
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--ckpt_fold", type=int, default=1)
    ap.add_argument("--tgt", choices=["T60","C50","BOTH"], default="BOTH")
    ap.add_argument("--avg", action="store_true")
    ap.add_argument("--skip_eval", action="store_true")
    args,_ = ap.parse_known_args()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    df = pd.read_csv(LABELS_CSV)
    df["tensor_filename"] = df["name"].str.replace(r"\.wav$","",regex=True)+".pt"
    df = df[df.tensor_filename.isin({p.name for p in TEST_DIR.rglob("*.pt")})]
    loader = DataLoader(SpectroDataset(df, TEST_DIR),
                        BATCH_SIZE, shuffle=False, num_workers=0)

    preds_fold = [{b: {"C50": [], "T60": []} for b in FREQS}
                  for _ in range(NUM_FOLDS)]
    last_ckpt = None

    # ---------- métricas por fold ----------------------------------------
    for fold in range(1, NUM_FOLDS+1):
        ckdir = MODEL_DIR/f"fold_{fold}/checkpoints"
        ckpt  = ckdir/f"fold{fold}_latest.pth"
        if not ckpt.exists():
            ckpt = max(ckdir.glob(f"fold{fold}_epoch*.pth"),
                       key=lambda p:int(re.search(r"epoch(\d+)",p.name).group(1)))
        last_ckpt = ckpt
        model = MultiHeadModel().to(device)
        model.load_state_dict(torch.load(ckpt, map_location=device))
        model.eval()

        sc_c50, sc_t60 = load_scalers(MODEL_DIR/f"fold_{fold}/scalers")
        with torch.no_grad():
            for x,_ in loader:
                outs = model(x.to(device))
                for b in FREQS:
                    p_c50, p_t60 = inv_scale(outs[b].cpu().numpy(),
                                             (sc_c50[b], sc_t60[b])) # fix
                    preds_fold[fold-1][b]["C50"].extend(p_c50)
                    preds_fold[fold-1][b]["T60"].extend(p_t60)

        print(f"\n════ Métricas FOLD {fold} ════")
        for b in FREQS:
            for var in ("C50","T60"):
                rm,ma,r2,pc = metrics(df[f"{var}_{b}"],
                                       preds_fold[fold-1][b][var])
                print(f" {var}_{b}: RMSE={rm:.4f} | MAE={ma:.4f} | "
                      f"R²={r2:.4f} | PCC={pc:.4f}")

    # ---------- ensemble --------------------------------------------------
    ens = {b: {"C50":[], "T60":[]} for b in FREQS}
    for b in FREQS:
        for var in ("C50","T60"):
            ens[b][var] = [np.mean([preds_fold[f][b][var][i]
                                    for f in range(NUM_FOLDS)])
                           for i in range(len(df))]
    print("\n════ Métricas ENSEMBLE (média simples) ════")
    for b in FREQS:
        for var in ("C50","T60"):
            rm,ma,r2,pc = metrics(df[f"{var}_{b}"], ens[b][var])
            print(f" {var}_{b}: RMSE={rm:.4f} | MAE={ma:.4f} | "
                  f"R²={r2:.4f} | PCC={pc:.4f}")

    # ---------- rollout global -------------------------------------------
    if not args.skip_eval:
        model = MultiHeadModel().to(device)
        model.load_state_dict(torch.load(last_ckpt, map_location=device))
        model.eval()
        acc,n = np.zeros((GRID_SIDE,GRID_SIDE)), 0
        with torch.no_grad():
            for x,_ in tqdm(loader, desc="Attention-Rollout"):
                for img in x.to(device):
                    acc += attention_rollout(model, img); n += 1
        save_heatmap(acc/max(n,1),
                     "Attention-Rollout (mean)",
                     OUT_DIR/"attention_rollout_mean.png",
                     label="Rollout intensity")

    # ---------- grad-cam + overlay ---------------------------------------
    model = MultiHeadModel().to(device)
    model.load_state_dict(torch.load(last_ckpt, map_location=device))
    model.eval()
    tgt_map = {"T60":1,"C50":0} if args.tgt!="BOTH" else {"T60":1,"C50":0}
    for tag,idx in tgt_map.items():
        generate_gradcams(model, loader,
                          idx_target=idx,
                          avg=args.avg,
                          prefix=tag)

    print("\n✓ Resultados salvos em:", OUT_DIR.resolve())

# 11 ▸ run -----------------------------------------------------------------
if __name__ == "__main__":
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=FutureWarning)
        main()

"""### TREINANDO O MODELO COM DESMASCARAMENTO GRADUAL A PARTIR DE ANÁLISE VIA GRAD-CAM"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_smooth_curriculum_vit_checkpoint.py
──────────────────────────────────────────────────────────────────────────────
ViT-B/16 multitarefa (6 cabeças, 125–4000 Hz) para estimar C50 e T60,
com currículo suave e gradient checkpointing manual para economizar memória,
e acumulação de gradiente para batch efetivo 32.
"""

import os, math, csv, random, warnings, gc
from pathlib import Path

import numpy as np
import pandas as pd
import librosa
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.utils.checkpoint import checkpoint
from torchvision import models
from tqdm.auto import tqdm

# ─── Hygiene & GPU setup ───────────────────────────────────────────────────
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:64"
gc.collect(); torch.cuda.empty_cache()
warnings.filterwarnings("ignore", category=FutureWarning)
torch.backends.cuda.matmul.allow_tf32 = True

# ─── Paths & Metrics CSV ───────────────────────────────────────────────────
ROOT        = Path("/content/drive/MyDrive")
TRAIN_DIR   = ROOT/"PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TREINO_VALID"
LABELS_PATH = ROOT/"Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv"
MODEL_DIR   = ROOT/"MODELOS COMPARATIVOS/logmel_SR_curriculum_checkpoint"
MODEL_DIR.mkdir(parents=True, exist_ok=True)

CSV_METRICS = MODEL_DIR/"metrics.csv"
if not CSV_METRICS.exists():
    with CSV_METRICS.open("w", newline="", encoding="utf-8") as f:
        csv.writer(f).writerow([
            "epoch","band","var",
            "rmse_t","mae_t","r2_t","pcc_t",
            "rmse_v","mae_v","r2_v","pcc_v"
        ])

# ─── Hyperparameters ───────────────────────────────────────────────────────
FREQ_BANDS   = (125,250,500,1000,2000,4000)
FREQUENCIES  = [str(b) for b in FREQ_BANDS]
C50_VARS     = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS     = [f"T60_{b}" for b in FREQ_BANDS]

BATCH_SIZE   = 4    # reduzido para GPU
ACCUM_STEPS  = 8    # efetivo 32
EPOCHS       = 100
START_DECAY  = 10
END_DECAY    = 30
PATIENCE     = 10

SEED         = 42
CLIP_NORM    = 1.0
DROPOUT_P    = 0.4

SR, N_MELS   = 22050, 128
F_MIN, F_MAX = 20, 8000

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)

# ─── Helper functions ──────────────────────────────────────────────────────
def _stats(a,b):
    return (
        math.sqrt(mean_squared_error(a,b)),
        mean_absolute_error(a,b),
        r2_score(a,b),
        np.corrcoef(a,b)[0,1]
    )

# ─── Build band masks ──────────────────────────────────────────────────────
mel_freqs = librosa.mel_frequencies(n_mels=N_MELS, fmin=F_MIN, fmax=F_MAX)
MASKS = {
    str(fc): (mel_freqs >= fc/1.4142) & (mel_freqs < fc*1.4142)
    for fc in FREQ_BANDS
}

def mask_to_224(m):
    arr = np.repeat(m.astype(np.float32)[:,None], 224, axis=1)
    t   = torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)
    up  = F.interpolate(t, size=(224,224), mode="nearest")
    return up.squeeze().bool()

MASKS_224 = {b: mask_to_224(m) for b,m in MASKS.items()}

# ─── Dataset ────────────────────────────────────────────────────────────────
class SpectroDataset(Dataset):
    def __init__(self, df, td: Path):
        self.df = df.reset_index(drop=True)
        self.td = td
    def __len__(self): return len(self.df)
    def __getitem__(self, idx):
        r = self.df.loc[idx]
        x = torch.load(self.td/r.tensor_filename)
        if x.shape[0]==1: x = x.repeat(3,1,1)
        if x.shape[-2:]!=(224,224):
            x = F.interpolate(x.unsqueeze(0), size=(224,224),
                              mode="bilinear", align_corners=False).squeeze(0)
        x_bands = {b: x.clone().masked_fill_(~MASKS_224[b],0.0)
                   for b in FREQUENCIES}
        y = torch.tensor(list(zip([r[v] for v in C50_VARS],
                                  [r[v] for v in T60_VARS])),
                         dtype=torch.float32)
        return x, x_bands, y

# ─── Model with manual checkpointing ────────────────────────────────────────
class MultiHeadViT(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads = nn.Identity()
        self.backbone = vit.to(device)
        feat_dim = vit.hidden_dim
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(DROPOUT_P),
                nn.Linear(hidden_dim, 2)
            ) for f in FREQUENCIES
        })

    def forward(self, x_full, x_bands, alpha):
        out = {}
        for f in FREQUENCIES:
            x_mix = alpha * x_bands[f] + (1 - alpha) * x_full
            feats = checkpoint(self.backbone, x_mix)
            out[f] = self.heads[f](feats)
        return out

# ─── Load data & preprocess ────────────────────────────────────────────────
print("Lendo labels …")
df = pd.read_csv(LABELS_PATH)
df["tensor_filename"] = df.name.str.replace(r"\.wav$","",regex=True)+".pt"
existing = {p.name for p in TRAIN_DIR.rglob("*.pt")}
df = df[df.tensor_filename.isin(existing)].reset_index(drop=True)
df.replace([np.inf,-np.inf], np.nan, inplace=True)
df.dropna(subset=C50_VARS+T60_VARS, inplace=True)

train_df, val_df = train_test_split(
    df, test_size=0.2, shuffle=True, random_state=SEED
)
sc_c50, sc_t60 = {}, {}
for var in C50_VARS+T60_VARS:
    sc = StandardScaler().fit(train_df[[var]])
    train_df[var] = sc.transform(train_df[[var]])
    val_df[var]   = sc.transform(val_df[[var]])
    band = var.split("_")[1]
    (sc_c50 if var.startswith("C50") else sc_t60)[band] = sc

train_loader = DataLoader(
    SpectroDataset(train_df, TRAIN_DIR),
    batch_size=BATCH_SIZE, shuffle=True,
    num_workers=4, pin_memory=True
)
val_loader = DataLoader(
    SpectroDataset(val_df, TRAIN_DIR),
    batch_size=BATCH_SIZE, shuffle=False,
    num_workers=4, pin_memory=True
)

# ─── Training setup ────────────────────────────────────────────────────────
gc.collect(); torch.cuda.empty_cache()

model     = MultiHeadViT().to(device)
criterion = nn.MSELoss()

param_groups = [
    {"params": model.backbone.parameters(), "lr": 1e-6,  "weight_decay": 5e-4}
] + [
    {"params": model.heads[f].parameters(),    "lr": 1e-4,  "weight_decay": 5e-3}
    for f in FREQUENCIES
]
optimizer = optim.AdamW(param_groups, betas=(0.9,0.999))
scheduler = optim.lr_scheduler.OneCycleLR(
    optimizer,
    max_lr=[1e-5] + [1e-4]*6,
    pct_start=0.1, div_factor=10, final_div_factor=100,
    total_steps=len(train_loader)*EPOCHS
)

# ─── Tentar retomar de último checkpoint se existir ──────────────────────────
start_epoch = 1
ckpt_files = sorted(
    MODEL_DIR.glob("epoch*.pth"),
    key=lambda p: int(p.stem.replace("epoch",""))
)
if ckpt_files:
    last_ckpt   = ckpt_files[-1]
    start_epoch = int(last_ckpt.stem.replace("epoch","")) + 1
    model.load_state_dict(torch.load(last_ckpt))
    optimizer.load_state_dict(torch.load(MODEL_DIR/"optim_latest.pth"))
    print(f"Retomando do checkpoint {last_ckpt.name}, começando na época {start_epoch}")

best_r2    = -float("inf")
no_improve = 0
loss_w     = np.ones(len(FREQUENCIES)*2, dtype=np.float32)

@torch.no_grad()
def compute_metrics(pred, true):
    out = {}
    for f in FREQUENCIES:
        p = torch.vstack(pred[f]).cpu().numpy()
        t = torch.vstack(true[f]).cpu().numpy()
        pc = sc_c50[f].inverse_transform(p[:,[0]]).ravel()
        tc = sc_c50[f].inverse_transform(t[:,[0]]).ravel()
        pt = sc_t60[f].inverse_transform(p[:,[1]]).ravel()
        tt = sc_t60[f].inverse_transform(t[:,[1]]).ravel()
        out[f] = {"C50": _stats(tc,pc), "T60": _stats(tt,pt)}
    return out

# ─── Training loop ─────────────────────────────────────────────────────────
for epoch in range(start_epoch, EPOCHS+1):
    # currículo suave (α)
    if epoch <= START_DECAY:
        alpha = 1.0
    elif epoch <= END_DECAY:
        alpha = 1.0 - (epoch - START_DECAY)/(END_DECAY - START_DECAY)
    else:
        alpha = 0.0

    # ---- Train ----
    model.train(); optimizer.zero_grad()
    train_loss = 0.0
    preds_t    = {f:[] for f in FREQUENCIES}
    trues_t    = {f:[] for f in FREQUENCIES}

    for step, (x_full, x_bands, y) in enumerate(
            tqdm(train_loader, desc=f"[Train] E{epoch}", leave=False), 1
    ):
        x_full = x_full.to(device)
        x_bands= {k:v.to(device) for k,v in x_bands.items()}
        y      = y.to(device)

        outs   = model(x_full, x_bands, alpha)
        losses = []
        for i,f in enumerate(FREQUENCIES):
            losses.append(criterion(outs[f], y[:,i,:]))
            losses.append(criterion(outs[f], y[:,i,:]))
        lw    = torch.tensor(loss_w, device=device)
        loss  = (torch.stack(losses)*lw).mean()/ACCUM_STEPS
        loss.backward()

        if step % ACCUM_STEPS == 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)
            optimizer.step(); scheduler.step(); optimizer.zero_grad()

        train_loss += loss.item() * ACCUM_STEPS * x_full.size(0)
        for i,f in enumerate(FREQUENCIES):
            preds_t[f].append(outs[f].detach().cpu())
            trues_t[f].append(y[:,i,:].cpu())

    train_loss /= len(train_loader.dataset)

    # ---- Validate ----
    model.eval()
    val_loss = 0.0
    preds_v, trues_v = ({f:[] for f in FREQUENCIES},
                        {f:[] for f in FREQUENCIES})

    with torch.no_grad():
        for x_full, x_bands, y in tqdm(val_loader, desc=f"[Val] E{epoch}", leave=False):
            x_full = x_full.to(device)
            x_bands= {k:v.to(device) for k,v in x_bands.items()}
            y      = y.to(device)

            outs     = model(x_full, x_bands, 0.0)
            batch_l  = sum(criterion(outs[f], y[:,i,:])
                           for i,f in enumerate(FREQUENCIES))
            val_loss += batch_l.item() * x_full.size(0)

            for i,f in enumerate(FREQUENCIES):
                preds_v[f].append(outs[f].cpu())
                trues_v[f].append(y[:,i,:].cpu())

    val_loss /= len(val_loader.dataset)

    # metrics & dynamic weights
    train_m = compute_metrics(preds_t, trues_t)
    val_m   = compute_metrics(preds_v, trues_v)
    avg_r2  = np.mean([val_m[b][v][2] for b in FREQUENCIES for v in ("C50","T60")])

    rmses   = np.array([val_m[b][v][0] for b in FREQUENCIES for v in ("C50","T60")])
    inv     = 1/(rmses + 1e-3)
    loss_w  = (inv / inv.sum()).astype(np.float32)

    # checkpoints & early stop
    torch.save(model.state_dict(), MODEL_DIR/f"epoch{epoch}.pth")
    torch.save(optimizer.state_dict(), MODEL_DIR/"optim_latest.pth")
    if avg_r2 > best_r2:
        best_r2, no_improve = avg_r2, 0
        torch.save(model.state_dict(), MODEL_DIR/"best.pth")
    else:
        no_improve += 1
        if no_improve >= PATIENCE:
            print(f"\nEarly stopping at epoch {epoch}")
            break

    # print & CSV
    print(f"\nEpoch {epoch}/{EPOCHS} | α={alpha:.2f} | L_tr={train_loss:.4f} | L_v={val_loss:.4f} | R²̄_val={avg_r2:.3f}")
    hdr = "Band | RMSE_t | MAE_t | R2_t | PCC_t | RMSE_v | MAE_v | R2_v | PCC_v"
    for var in ("C50","T60"):
        print(f"\n── {var} ──\n{hdr}\n" + "-"*len(hdr))
        for b in FREQUENCIES:
            rt,mt,r2t,pcct = train_m[b][var]
            rv,mv,r2v,pccv = val_m[b][var]
            print(f"{b:>4} | {rt:6.3f}|{mt:6.3f}|{r2t:5.2f}|{pcct:5.2f}|{rv:6.3f}|{mv:6.3f}|{r2v:5.2f}|{pccv:5.2f}")

    with CSV_METRICS.open("a", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        for b in FREQUENCIES:
            for var in ("C50","T60"):
                rt,mt,r2t,pcct = train_m[b][var]
                rv,mv,r2v,pccv = val_m[b][var]
                w.writerow([
                    epoch, b, var,
                    f"{rt:.6f}", f"{mt:.6f}", f"{r2t:.6f}", f"{pcct:.6f}",
                    f"{rv:.6f}", f"{mv:.6f}", f"{r2v:.6f}", f"{pccv:.6f}"
                ])

print("\nTreinamento concluído!")

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_smooth_curriculum_vit_checkpoint.py
──────────────────────────────────────────────────────────────────────────────
ViT-B/16 multitarefa (6 cabeças, 125–4000 Hz) para estimar C50 e T60,
com currículo suave e gradient checkpointing manual para economizar memória,
e acumulação de gradiente para batch efetivo 32.
"""

import os
import math
import csv
import random
import warnings
import gc
import pickle
from pathlib import Path

import numpy as np
import pandas as pd
import librosa
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.utils.checkpoint import checkpoint
from torchvision import models
from tqdm.auto import tqdm

# ─── Hygiene & GPU setup ───────────────────────────────────────────────────
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:64"
gc.collect(); torch.cuda.empty_cache()
warnings.filterwarnings("ignore", category=FutureWarning)
torch.backends.cuda.matmul.allow_tf32 = True

# ─── Paths & Metrics CSV ───────────────────────────────────────────────────
ROOT        = Path("/content/drive/MyDrive")
TRAIN_DIR   = ROOT/"PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TREINO_VALID"
LABELS_PATH = ROOT/"Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv"
MODEL_DIR   = ROOT/"MODELOS COMPARATIVOS/logmel_SR_curriculum_checkpoint"
MODEL_DIR.mkdir(parents=True, exist_ok=True)

CSV_METRICS = MODEL_DIR/"metrics.csv"
if not CSV_METRICS.exists():
    with CSV_METRICS.open("w", newline="", encoding="utf-8") as f:
        csv.writer(f).writerow([
            "epoch","band","var",
            "rmse_t","mae_t","r2_t","pcc_t",
            "rmse_v","mae_v","r2_v","pcc_v"
        ])

# ─── Hyperparameters ───────────────────────────────────────────────────────
FREQ_BANDS   = (125,250,500,1000,2000,4000)
FREQUENCIES  = [str(b) for b in FREQ_BANDS]
C50_VARS     = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS     = [f"T60_{b}" for b in FREQ_BANDS]

BATCH_SIZE   = 4    # reduzido para GPU
ACCUM_STEPS  = 8    # efetivo 32
EPOCHS       = 100
START_DECAY  = 10
END_DECAY    = 30
PATIENCE     = 10

SEED         = 42
CLIP_NORM    = 1.0
DROPOUT_P    = 0.4

SR, N_MELS   = 22050, 128
F_MIN, F_MAX = 20, 8000

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)

# ─── Helper functions ──────────────────────────────────────────────────────
def _stats(a,b):
    return (
        math.sqrt(mean_squared_error(a,b)),
        mean_absolute_error(a,b),
        r2_score(a,b),
        np.corrcoef(a,b)[0,1]
    )

# ─── Build band masks ──────────────────────────────────────────────────────
mel_freqs = librosa.mel_frequencies(n_mels=N_MELS, fmin=F_MIN, fmax=F_MAX)
MASKS = {
    str(fc): (mel_freqs >= fc/1.4142) & (mel_freqs < fc*1.4142)
    for fc in FREQ_BANDS
}

def mask_to_224(m):
    arr = np.repeat(m.astype(np.float32)[:,None], 224, axis=1)
    t   = torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)
    up  = F.interpolate(t, size=(224,224), mode="nearest")
    return up.squeeze().bool()

MASKS_224 = {b: mask_to_224(m) for b,m in MASKS.items()}

# ─── Dataset ────────────────────────────────────────────────────────────────
class SpectroDataset(Dataset):
    def __init__(self, df, td: Path):
        self.df = df.reset_index(drop=True)
        self.td = td

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        r = self.df.loc[idx]
        x = torch.load(self.td/r.tensor_filename)
        if x.shape[0]==1:
            x = x.repeat(3,1,1)
        if x.shape[-2:]!=(224,224):
            x = F.interpolate(
                x.unsqueeze(0), size=(224,224),
                mode="bilinear", align_corners=False
            ).squeeze(0)
        x_bands = {
            b: x.clone().masked_fill_(~MASKS_224[b],0.0)
            for b in FREQUENCIES
        }
        y = torch.tensor(
            list(zip([r[v] for v in C50_VARS],
                     [r[v] for v in T60_VARS])),
            dtype=torch.float32
        )
        return x, x_bands, y

# ─── Model with manual checkpointing ────────────────────────────────────────
class MultiHeadViT(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads = nn.Identity()
        self.backbone = vit.to(device)
        feat_dim = vit.hidden_dim
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(DROPOUT_P),
                nn.Linear(hidden_dim, 2)
            ) for f in FREQUENCIES
        })

    def forward(self, x_full, x_bands, alpha):
        out = {}
        for f in FREQUENCIES:
            x_mix = alpha * x_bands[f] + (1 - alpha) * x_full
            feats = checkpoint(self.backbone, x_mix)
            out[f] = self.heads[f](feats)
        return out

# ─── Load data & preprocess ────────────────────────────────────────────────
print("Lendo labels …")
df = pd.read_csv(LABELS_PATH)
df["tensor_filename"] = df.name.str.replace(r"\.wav$","",regex=True)+".pt"
existing = {p.name for p in TRAIN_DIR.rglob("*.pt")}
df = df[df.tensor_filename.isin(existing)].reset_index(drop=True)
df.replace([np.inf,-np.inf], np.nan, inplace=True)
df.dropna(subset=C50_VARS+T60_VARS, inplace=True)

train_df, val_df = train_test_split(
    df, test_size=0.2, shuffle=True, random_state=SEED
)

# ─── Fit scalers e transforma ──────────────────────────────────────────────
sc_c50, sc_t60 = {}, {}
for var in C50_VARS + T60_VARS:
    sc = StandardScaler().fit(train_df[[var]])
    train_df[var] = sc.transform(train_df[[var]])
    val_df[var]   = sc.transform(val_df[[var]])
    band = var.split("_")[1]
    if var.startswith("C50"):
        sc_c50[band] = sc
    else:
        sc_t60[band] = sc

# ─── Salvar scalers em disco ────────────────────────────────────────────────
print("Salvando scalers…")
for band, scaler in sc_c50.items():
    path = MODEL_DIR / f"scaler_C50_{band}.pkl"
    with open(path, "wb") as f:
        pickle.dump(scaler, f)
    print(f" - {path.name}")
for band, scaler in sc_t60.items():
    path = MODEL_DIR / f"scaler_T60_{band}.pkl"
    with open(path, "wb") as f:
        pickle.dump(scaler, f)
    print(f" - {path.name}")

# ─── DataLoaders ───────────────────────────────────────────────────────────
train_loader = DataLoader(
    SpectroDataset(train_df, TRAIN_DIR),
    batch_size=BATCH_SIZE, shuffle=True,
    num_workers=4, pin_memory=True
)
val_loader = DataLoader(
    SpectroDataset(val_df, TRAIN_DIR),
    batch_size=BATCH_SIZE, shuffle=False,
    num_workers=4, pin_memory=True
)

# ─── Training setup ────────────────────────────────────────────────────────
gc.collect(); torch.cuda.empty_cache()

model     = MultiHeadViT().to(device)
criterion = nn.MSELoss()

param_groups = (
    [{"params": model.backbone.parameters(), "lr": 1e-6,  "weight_decay": 5e-4}]
    + [{"params": model.heads[f].parameters(), "lr": 1e-4,  "weight_decay": 5e-3}
       for f in FREQUENCIES]
)
optimizer = optim.AdamW(param_groups, betas=(0.9,0.999))
scheduler = optim.lr_scheduler.OneCycleLR(
    optimizer,
    max_lr=[1e-5] + [1e-4]*6,
    pct_start=0.1, div_factor=10, final_div_factor=100,
    total_steps=len(train_loader)*EPOCHS
)

# ─── Resume checkpoint if exists ────────────────────────────────────────────
start_epoch = 1
ckpt_files = sorted(
    MODEL_DIR.glob("epoch*.pth"),
    key=lambda p: int(p.stem.replace("epoch",""))
)
if ckpt_files:
    last_ckpt   = ckpt_files[-1]
    start_epoch = int(last_ckpt.stem.replace("epoch","")) + 1
    model.load_state_dict(torch.load(last_ckpt))
    optimizer.load_state_dict(torch.load(MODEL_DIR/"optim_latest.pth"))
    print(f"Retomando de checkpoint {last_ckpt.name}, época {start_epoch}")

best_r2    = -float("inf")
no_improve = 0
loss_w     = np.ones(len(FREQUENCIES)*2, dtype=np.float32)

@torch.no_grad()
def compute_metrics(pred, true):
    out = {}
    for f in FREQUENCIES:
        p = torch.vstack(pred[f]).cpu().numpy()
        t = torch.vstack(true[f]).cpu().numpy()
        pc = sc_c50[f].inverse_transform(p[:,[0]]).ravel()
        tc = sc_c50[f].inverse_transform(t[:,[0]]).ravel()
        pt = sc_t60[f].inverse_transform(p[:,[1]]).ravel()
        tt = sc_t60[f].inverse_transform(t[:,[1]]).ravel()
        out[f] = {"C50": _stats(tc,pc), "T60": _stats(tt,pt)}
    return out

# ─── Training loop ─────────────────────────────────────────────────────────
for epoch in range(start_epoch, EPOCHS+1):
    # Currículo suave α
    if epoch <= START_DECAY:
        alpha = 1.0
    elif epoch <= END_DECAY:
        alpha = 1.0 - (epoch - START_DECAY)/(END_DECAY - START_DECAY)
    else:
        alpha = 0.0

    # ---- Train ----
    model.train(); optimizer.zero_grad()
    train_loss = 0.0
    preds_t    = {f:[] for f in FREQUENCIES}
    trues_t    = {f:[] for f in FREQUENCIES}

    for step, (x_full, x_bands, y) in enumerate(
            tqdm(train_loader, desc=f"[Train] E{epoch}", leave=False), 1
    ):
        x_full = x_full.to(device)
        x_bands= {k:v.to(device) for k,v in x_bands.items()}
        y      = y.to(device)

        outs   = model(x_full, x_bands, alpha)
        losses = []
        for i,f in enumerate(FREQUENCIES):
            losses.append(criterion(outs[f], y[:,i,:]))
            losses.append(criterion(outs[f], y[:,i,:]))
        lw    = torch.tensor(loss_w, device=device)
        loss  = (torch.stack(losses)*lw).mean()/ACCUM_STEPS
        loss.backward()

        if step % ACCUM_STEPS == 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)
            optimizer.step(); scheduler.step(); optimizer.zero_grad()

        train_loss += loss.item() * ACCUM_STEPS * x_full.size(0)
        for i,f in enumerate(FREQUENCIES):
            preds_t[f].append(outs[f].detach().cpu())
            trues_t[f].append(y[:,i,:].cpu())

    train_loss /= len(train_loader.dataset)

    # ---- Validate ----
    model.eval()
    val_loss = 0.0
    preds_v, trues_v = ({f:[] for f in FREQUENCIES},
                        {f:[] for f in FREQUENCIES})

    with torch.no_grad():
        for x_full, x_bands, y in tqdm(val_loader, desc=f"[Val] E{epoch}", leave=False):
            x_full = x_full.to(device)
            x_bands= {k:v.to(device) for k,v in x_bands.items()}
            y      = y.to(device)

            outs    = model(x_full, x_bands, 0.0)
            batch_l = sum(criterion(outs[f], y[:,i,:])
                          for i,f in enumerate(FREQUENCIES))
            val_loss += batch_l.item() * x_full.size(0)

            for i,f in enumerate(FREQUENCIES):
                preds_v[f].append(outs[f].cpu())
                trues_v[f].append(y[:,i,:].cpu())

    val_loss /= len(val_loader.dataset)

    # metrics & dynamic weights
    train_m = compute_metrics(preds_t, trues_t)
    val_m   = compute_metrics(preds_v, trues_v)
    avg_r2  = np.mean([val_m[b][v][2] for b in FREQUENCIES for v in ("C50","T60")])

    rmses   = np.array([val_m[b][v][0] for b in FREQUENCIES for v in ("C50","T60")])
    inv     = 1/(rmses + 1e-3)
    loss_w  = (inv / inv.sum()).astype(np.float32)

    # checkpoints & early stop
    torch.save(model.state_dict(), MODEL_DIR/f"epoch{epoch}.pth")
    torch.save(optimizer.state_dict(), MODEL_DIR/"optim_latest.pth")
    if avg_r2 > best_r2:
        best_r2, no_improve = avg_r2, 0
        torch.save(model.state_dict(), MODEL_DIR/"best.pth")
    else:
        no_improve += 1
        if no_improve >= PATIENCE:
            print(f"\nEarly stopping at epoch {epoch}")
            break

    # print & CSV
    print(f"\nEpoch {epoch}/{EPOCHS} | α={alpha:.2f} | L_tr={train_loss:.4f} | L_v={val_loss:.4f} | R²̄_val={avg_r2:.3f}")
    hdr = "Band | RMSE_t | MAE_t | R2_t | PCC_t | RMSE_v | MAE_v | R2_v | PCC_v"
    for var in ("C50","T60"):
        print(f"\n── {var} ──\n{hdr}\n" + "-"*len(hdr))
        for b in FREQUENCIES:
            rt,mt,r2t,pcct = train_m[b][var]
            rv,mv,r2v,pccv = val_m[b][var]
            print(f"{b:>4} | {rt:6.3f}|{mt:6.3f}|{r2t:5.2f}|{pcct:5.2f}|{rv:6.3f}|{mv:6.3f}|{r2v:5.2f}|{pccv:5.2f}")

    with CSV_METRICS.open("a", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        for b in FREQUENCIES:
            for var in ("C50","T60"):
                rt,mt,r2t,pcct = train_m[b][var]
                rv,mv,r2v,pccv = val_m[b][var]
                w.writerow([
                    epoch, b, var,
                    f"{rt:.6f}", f"{mt:.6f}", f"{r2t:.6f}", f"{pcct:.6f}",
                    f"{rv:.6f}", f"{mv:.6f}", f"{r2v:.6f}", f"{pccv:.6f}"
                ])

print("\nTreinamento concluído!")

"""### ANALISE GRAD CAM PARA VERIFICAR SE HOUVE DIFERENÇAS"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
eval_smooth_curriculum_gradcam.py
──────────────────────────────────────────────────────────────────────────────
Avaliação do MultiHeadViT treinado com currículo suave e checkpointing:
 • Métricas RMSE | MAE | R² | PCC no conjunto de teste
 • Attention-Rollout global (Freq × Time)
 • Grad-CAM banda-específico p/ T60 e C50 (média ou 1 amostra + overlay)
"""

import subprocess
import sys
import importlib
import warnings
from pathlib import Path
import math
import pickle
import argparse

# ─── 0 ▸ garante PyTorch ────────────────────────────────────────────────────
def ensure_torch():
    try:
        import torch, torchvision, torchaudio  # noqa: F401
        return
    except ModuleNotFoundError:
        wheel = "cu118" if subprocess.run(['nvidia-smi'], capture_output=True).returncode == 0 else "cpu"
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", "-q",
            "torch", "torchvision", "torchaudio",
            "--index-url", f"https://download.pytorch.org/whl/{wheel}"
        ])
        importlib.invalidate_caches()
ensure_torch()

# ─── 1 ▸ imports ─────────────────────────────────────────────────────────────
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
from torchvision import models
from torch.utils.data import Dataset, DataLoader
from torch.utils.checkpoint import checkpoint
from tqdm.auto import tqdm
import librosa

# ─── 2 ▸ caminhos & constantes ──────────────────────────────────────────────
ROOT       = Path("/content/drive/MyDrive")
TEST_DIR   = ROOT/"PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE"
LABELS_CSV = ROOT/"Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv"
MODEL_DIR  = ROOT/"MODELOS COMPARATIVOS/logmel_SR_curriculum_checkpoint"
BEST_CKPT  = MODEL_DIR/"best.pth"
OUT_DIR    = MODEL_DIR/"eval_maps_gradcam"
OUT_DIR.mkdir(exist_ok=True, parents=True)

BATCH_SIZE = 16
FREQ_BANDS = (125, 250, 500, 1000, 2000, 4000)
FREQS      = [str(b) for b in FREQ_BANDS]
GRID_SIDE  = 14
TIME_MAX   = 5.0    # segundos
FREQ_MAX   = 8000   # Hz

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ─── 3 ▸ máscaras de banda ───────────────────────────────────────────────────
mel_freqs = librosa.mel_frequencies(n_mels=128, fmin=20, fmax=8000)
MASKS = {
    str(fc): (mel_freqs >= fc/1.4142) & (mel_freqs < fc*1.4142)
    for fc in FREQ_BANDS
}
def mask_to_224(m):
    arr = np.repeat(m.astype(np.float32)[:, None], 224, axis=1)
    t   = torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)
    up  = F.interpolate(t, size=(224, 224), mode="nearest")
    return up.squeeze().bool()
MASKS_224 = {b: mask_to_224(m) for b, m in MASKS.items()}

# ─── 4 ▸ Dataset de teste ───────────────────────────────────────────────────
class SpectroDataset(Dataset):
    def __init__(self, df, td: Path):
        self.df = df.reset_index(drop=True)
        self.td = td

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        r = self.df.loc[idx]
        x = torch.load(self.td / r.tensor_filename)
        if x.shape[0] == 1:
            x = x.repeat(3, 1, 1)
        if x.shape[-2:] != (224, 224):
            x = F.interpolate(
                x.unsqueeze(0), size=(224, 224),
                mode="bilinear", align_corners=False
            ).squeeze(0)
        x_bands = {
            b: x.clone().masked_fill_(~MASKS_224[b], 0.0)
            for b in FREQS
        }
        y = torch.tensor([
            [r[f"C50_{b}"], r[f"T60_{b}"]] for b in FREQS
        ], dtype=torch.float32)
        return x, x_bands, y

# ─── 5 ▸ Modelo multitarefa ─────────────────────────────────────────────────
class MultiHeadViT(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads = nn.Identity()
        self.backbone = vit.to(device)
        feat_dim      = vit.hidden_dim
        self.heads = nn.ModuleDict({
            f: nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(0.4),
                nn.Linear(hidden_dim, 2)
            ) for f in FREQS
        })

    def forward(self, x_full, x_bands, alpha=0.0):
        out = {}
        for f in FREQS:
            x_mix = alpha * x_bands[f] + (1 - alpha) * x_full
            # passa use_reentrant=False para evitar warning
            feats = checkpoint(self.backbone, x_mix, use_reentrant=False)
            out[f] = self.heads[f](feats)
        return out

# ─── 6 ▸ métricas ───────────────────────────────────────────────────────────
def rmse(a, b):
    return math.sqrt(mean_squared_error(a, b))

def metrics(a, b):
    a, b = np.asarray(a), np.asarray(b)
    corr = np.corrcoef(a, b)[0, 1] if a.std() and b.std() else 0.0
    return (
        rmse(a, b),
        mean_absolute_error(a, b),
        r2_score(a, b),
        corr
    )

# ─── 7 ▸ utilitário heatmap ─────────────────────────────────────────────────
def save_heatmap(mask, title, path, cmap="inferno",
                 label="Intensity", overlay=None):
    fig, ax = plt.subplots(figsize=(4, 3))
    if overlay is not None:
        ax.imshow(
            overlay, cmap="gray", origin="lower",
            extent=[0, TIME_MAX, 0, FREQ_MAX], aspect="auto"
        )
    im = ax.imshow(
        mask, cmap=cmap, origin="lower",
        extent=[0, TIME_MAX, 0, FREQ_MAX], aspect="auto", alpha=0.6
    )
    ax.set_xlabel("Time (s)")
    ax.set_ylabel("Frequency (Hz)")
    ax.set_title(title, fontsize=10)
    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    cbar.set_label(label, rotation=270, labelpad=10)
    fig.tight_layout()
    fig.savefig(path, dpi=300)
    plt.close(fig)

# ─── 8 ▸ Attention-Rollout ──────────────────────────────────────────────────
def attention_rollout(model, x_single):
    attn, patched = [], []
    for blk in model.backbone.encoder.layers:
        mha = next(
            m for m in blk.modules()
            if isinstance(m, nn.MultiheadAttention)
        )
        orig = mha.forward
        def hook(q, k, v, **kw):
            kw.pop("need_weights", None)
            kw.pop("average_attn_weights", None)
            out, w = orig(q, k, v, need_weights=True,
                         average_attn_weights=False, **kw)
            attn.append(w.detach())
            return out, w
        mha.forward = hook
        patched.append((mha, orig))

    _ = model(
        x_single.unsqueeze(0),
        {f: x_single for f in FREQS},
        alpha=0.0
    )

    for m, orig in patched:
        m.forward = orig

    eye = torch.eye(attn[0].size(-1), device=x_single.device)
    R   = eye.clone()
    for A in attn:
        A = A.squeeze(0).mean(0)
        A = (A + eye) / (A + eye).sum(-1, keepdim=True)
        R = A @ R
    M = R[0, 1:].reshape(GRID_SIDE, GRID_SIDE)
    return ((M - M.min()) / (M.max() - M.min() + 1e-8)).cpu().numpy()

# ─── 9 ▸ Grad-CAM ───────────────────────────────────────────────────────────
def gradcam(feature, grad):
    w       = grad.mean(dim=(2, 3), keepdim=True)
    cam     = torch.relu((w * feature).sum(dim=1))
    cam_min = cam.amin((1, 2), True)
    cam_max = cam.amax((1, 2), True)
    return (cam - cam_min) / (cam_max - cam_min + 1e-8)

# ─── 10 ▸ gera Grad-CAMs ───────────────────────────────────────────────────
def generate_gradcams(model, loader, idx_target, avg, prefix):
    device = next(model.parameters()).device
    cams, overlays = {b: [] for b in FREQS}, {}
    feats, grads = [], []
    h1 = model.backbone.conv_proj.register_forward_hook(
        lambda _, __, o: feats.append(o.detach())
    )
    h2 = model.backbone.conv_proj.register_full_backward_hook(
        lambda _, g_in, g_out: grads.append(g_out[0].detach())
    )
    saved_ov = {b: False for b in FREQS}

    for x_full, x_bands, y in tqdm(loader, desc=f"Grad-CAM {prefix}"):
        x_full = x_full.to(device)
        x_bands = {b: xb.to(device) for b, xb in x_bands.items()}
        x_full.requires_grad_(True)

        outs   = model(x_full, x_bands, alpha=0.0)
        for band in FREQS:
            grads.clear()
            score = outs[band][:, idx_target].sum()
            model.zero_grad(set_to_none=True)
            score.backward(retain_graph=True)
            cam_single = gradcam(feats[-1], grads[-1])
            cams[band].append(cam_single.cpu())
            if not saved_ov[band]:
                spec = x_full[0, 0].detach().cpu().numpy()
                spec = (spec - spec.min()) / (spec.max() - spec.min() + 1e-8)
                overlays[band] = (cam_single[0].cpu().numpy(), spec)
                saved_ov[band] = True

        feats.clear()
        x_full.requires_grad_(False)
        torch.cuda.empty_cache()

    h1.remove()
    h2.remove()

    for band, lst in cams.items():
        stack     = torch.stack(lst)
        cam_final = stack.mean((0, 1)) if avg else stack[0, 0]
        save_heatmap(
            cam_final.numpy(),
            f"{prefix}_{band} Grad-CAM",
            OUT_DIR / f"{prefix}_{band}_gradcam.png",
            label="Grad-CAM intensity"
        )
        heat, spec = overlays[band]
        save_heatmap(
            heat,
            f"{prefix}_{band} Overlay",
            OUT_DIR / f"{prefix}_{band}_overlay.png",
            label="Grad-CAM intensity",
            overlay=spec
        )

# ─── 11 ▸ main ──────────────────────────────────────────────────────────────
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument(
        "--avg", action="store_true",
        help="usar média dos mapas Grad-CAM"
    )
    args, _ = ap.parse_known_args()

    df = pd.read_csv(LABELS_CSV)
    df["tensor_filename"] = df.name.str.replace(r"\.wav$", "", regex=True) + ".pt"
    existing = {p.name for p in TEST_DIR.rglob("*.pt")}
    df = df[df.tensor_filename.isin(existing)].reset_index(drop=True)

    loader = DataLoader(
        SpectroDataset(df, TEST_DIR),
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )

    model = MultiHeadViT().to(device)
    model.load_state_dict(torch.load(BEST_CKPT, map_location=device))
    model.eval()

    sc_c50 = {
        b: pickle.load(open(MODEL_DIR / f"scaler_C50_{b}.pkl", "rb"))
        for b in FREQS
    }
    sc_t60 = {
        b: pickle.load(open(MODEL_DIR / f"scaler_T60_{b}.pkl", "rb"))
        for b in FREQS
    }

    preds = {b: {"C50": [], "T60": []} for b in FREQS}
    trues = {b: {"C50": [], "T60": []} for b in FREQS}

    for x_full, x_bands, y in tqdm(loader, desc="Inferência e Métricas"):
        x_full = x_full.to(device)
        x_bands = {b: xb.to(device) for b, xb in x_bands.items()}

        outs   = model(x_full, x_bands, alpha=0.0)
        y_np = y.cpu().numpy()

        for i, b in enumerate(FREQS):
            p = outs[b].detach().cpu().numpy()
            pc = sc_c50[b].inverse_transform(p[:, [0]]).ravel()
            tc = sc_t60[b].inverse_transform(p[:, [1]]).ravel()

            gc = y_np[:, i, 0]
            gt = y_np[:, i, 1]

            preds[b]["C50"].extend(pc)
            preds[b]["T60"].extend(tc)
            trues[b]["C50"].extend(gc)
            trues[b]["T60"].extend(gt)

    print("\n════ Métricas TESTE ════")
    for b in FREQS:
        for var in ("C50", "T60"):
            a = trues[b][var]
            y = preds[b][var]
            rm, ma, r2, pc = metrics(a, y)
            print(f" {var}_{b}: RMSE={rm:.4f} | MAE={ma:.4f} | R²={r2:.4f} | PCC={pc:.4f}")

    acc, n = np.zeros((GRID_SIDE, GRID_SIDE)), 0
    for x_full, x_bands, _ in tqdm(loader, desc="Attention-Rollout"):
        x_full = x_full.to(device)
        x_bands = {b: xb.to(device) for b, xb in x_bands.items()}
        for img in x_full:
            acc += attention_rollout(model, img)
            n += 1

    save_heatmap(
        acc / max(n, 1),
        "Attention-Rollout (mean)",
        OUT_DIR / "attention_rollout_mean.png",
        label="Rollout intensity"
    )

    for tag, idx in [("C50", 0), ("T60", 1)]:
        generate_gradcams(model, loader, idx_target=idx, avg=args.avg, prefix=tag)

    print(f"\n✓ Resultados em: {OUT_DIR.resolve()}")

if __name__ == "__main__":
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=FutureWarning)
        main()

"""MELHORANDO CODIGO ACIMA"""

!pip install captum==0.7.0

from google.colab import drive
drive.mount('/content/drive')

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_smooth_curriculum_vit_checkpoint_OPT.py
──────────────────────────────────────────────────────────────────────────────
ViT-B/16 multitask (6 heads, 125–4000 Hz) to estimate C50 and T60
using inverse smooth curriculum, gradient checkpointing,
gradient accumulation, and OneCycleLR scheduler.
"""

import os
import math
import csv
import random
import warnings
import gc
import pickle
from pathlib import Path

import numpy as np
import pandas as pd
import librosa
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.utils.checkpoint import checkpoint
from torchvision import models
from tqdm.auto import tqdm

# ─── Hygiene & GPU setup ───────────────────────────────────────────────────
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:64"
gc.collect(); torch.cuda.empty_cache()
warnings.filterwarnings("ignore", category=FutureWarning)
torch.backends.cuda.matmul.allow_tf32 = True

# ─── Paths & Metrics CSV ───────────────────────────────────────────────────
ROOT        = Path("/content/drive/MyDrive")
TRAIN_DIR   = ROOT / "PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TREINO_VALID"
LABELS_PATH = ROOT / "Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv"
MODEL_DIR   = ROOT / "MODELOS COMPARATIVOS/logmel_SR_curriculum_checkpoint_OPT"
MODEL_DIR.mkdir(parents=True, exist_ok=True)

CSV_METRICS = MODEL_DIR / "metrics.csv"
if not CSV_METRICS.exists():
    with CSV_METRICS.open("w", newline="", encoding="utf-8") as f:
        csv.writer(f).writerow([
            "epoch","band","var",
            "rmse_t","mae_t","r2_t","pcc_t",
            "rmse_v","mae_v","r2_v","pcc_v"
        ])

# ─── Hyperparameters ───────────────────────────────────────────────────────
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQUENCIES = [str(b) for b in FREQ_BANDS]
C50_VARS    = [f"C50_{b}" for b in FREQ_BANDS]
T60_VARS    = [f"T60_{b}" for b in FREQ_BANDS]

BATCH_SIZE  = 4     # per GPU
ACCUM_STEPS = 8     # effective batch 32
EPOCHS      = 100

PATIENCE    = 10


START_DECAY = 10
END_DECAY   = 30

def get_alpha(epoch, start=START_DECAY, end=END_DECAY):
    if epoch <= start:
        return 1.0
    if epoch <= end:
        return 1.0 - (epoch - start) / (end - start)
    return 0.0


SEED        = 42
CLIP_NORM   = 1.0
DROPOUT_P   = 0.4

SR, N_MELS  = 22050, 128
F_MIN, F_MAX= 20, 8000

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)

# ─── Helper functions ──────────────────────────────────────────────────────
def _stats(a, b):
    return (
        math.sqrt(mean_squared_error(a, b)),
        mean_absolute_error(a, b),
        r2_score(a, b),
        np.corrcoef(a, b)[0,1]
    )

# ─── Build band masks ──────────────────────────────────────────────────────
mel_freqs = librosa.mel_frequencies(n_mels=N_MELS, fmin=F_MIN, fmax=F_MAX)
MASKS = {
    str(fc): (mel_freqs >= fc / math.sqrt(2)) & (mel_freqs < fc * math.sqrt(2))
    for fc in FREQ_BANDS
}
def mask_to_224(mask):
    arr = np.repeat(mask.astype(np.float32)[:, None], 224, axis=1)
    t = torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)
    return F.interpolate(t, size=(224,224), mode="nearest").squeeze().bool()
MASKS_224 = {b: mask_to_224(m) for b, m in MASKS.items()}

# ─── Dataset ───────────────────────────────────────────────────────────────
class SpectroDataset(Dataset):
    def __init__(self, df, td):
        self.df = df.reset_index(drop=True)
        self.td = td
    def __len__(self): return len(self.df)
    def __getitem__(self, idx):
        row = self.df.loc[idx]
        x = torch.load(self.td/row.tensor_filename)
        if x.shape[0]==1: x=x.repeat(3,1,1)
        if x.shape[-2:]!=(224,224):
            x=F.interpolate(x.unsqueeze(0), size=(224,224), mode="bilinear", align_corners=False).squeeze(0)
        x_bands={b: x.clone().masked_fill(~MASKS_224[b],0.0) for b in FREQUENCIES}
        y = torch.tensor([ [row[v] for v in C50_VARS], [row[v] for v in T60_VARS] ], dtype=torch.float32).transpose(0,1)
        return x, x_bands, y

# ─── Model definition ──────────────────────────────────────────────────────
class MultiHeadViT(nn.Module):
    def __init__(self, hidden_dim=128):
        super().__init__()
        vit=models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads=nn.Identity()
        self.backbone=vit.to(device)
        feat_dim=vit.hidden_dim
        self.heads=nn.ModuleDict({ f: nn.Sequential(nn.Linear(feat_dim,hidden_dim),nn.GELU(),nn.Dropout(DROPOUT_P),nn.Linear(hidden_dim,2)) for f in FREQUENCIES })
    def forward(self,x_full,x_bands,alpha):
        out={}
        for i,f in enumerate(FREQUENCIES):
            x_mix=alpha*x_bands[f]+(1-alpha)*x_full
            feats=checkpoint(self.backbone,x_mix,use_reentrant=False)
            out[f]=self.heads[f](feats)
        return out

# ─── Load & preprocess labels ──────────────────────────────────────────────
df=pd.read_csv(LABELS_PATH)
df["tensor_filename"]=df.name.str.replace(r"\.wav$","",regex=True)+".pt"
existing={p.name for p in TRAIN_DIR.rglob("*.pt")}
df=df[df.tensor_filename.isin(existing)].reset_index(drop=True)
df.replace([np.inf,-np.inf],np.nan,inplace=True)
df.dropna(subset=C50_VARS+T60_VARS,inplace=True)
train_df,val_df=train_test_split(df,test_size=0.2,shuffle=True,random_state=SEED)

# ─── Scale targets ─────────────────────────────────────────────────────────
sc_c50,sc_t60={},{}
for var in C50_VARS+T60_VARS:
    sc=StandardScaler().fit(train_df[[var]])
    train_df[var]=sc.transform(train_df[[var]])
    val_df[var]=sc.transform(val_df[[var]])
    band=var.split("_")[1]
    (sc_c50 if var.startswith("C50") else sc_t60)[band]=sc
for band,sc in sc_c50.items(): pickle.dump(sc,open(MODEL_DIR/f"scaler_C50_{band}.pkl","wb"))
for band,sc in sc_t60.items(): pickle.dump(sc,open(MODEL_DIR/f"scaler_T60_{band}.pkl","wb"))

# ─── Dataloaders ───────────────────────────────────────────────────────────
train_loader=DataLoader(SpectroDataset(train_df,TRAIN_DIR),batch_size=BATCH_SIZE,shuffle=True,num_workers=4,pin_memory=True)
val_loader  =DataLoader(SpectroDataset(val_df,TRAIN_DIR),batch_size=BATCH_SIZE,shuffle=False,num_workers=4,pin_memory=True)

# ─── Setup training ─────────────────────────────────────────────────────────
model=MultiHeadViT().to(device)
criterion=nn.MSELoss()
param_groups=[{"params":model.backbone.parameters(),"lr":5e-6,"weight_decay":5e-4}]+[{"params":model.heads[f].parameters(),"lr":1e-4,"weight_decay":5e-3} for f in FREQUENCIES]
optimizer=optim.AdamW(param_groups,betas=(0.9,0.999))
scheduler=optim.lr_scheduler.OneCycleLR(optimizer,max_lr=[5e-5]+[1e-4]*len(FREQUENCIES),pct_start=0.3,div_factor=10,final_div_factor=100,total_steps=len(train_loader)*EPOCHS)

# resume if checkpoint
start_epoch=1
ckpts=sorted(MODEL_DIR.glob("epoch*.pth"),key=lambda p:int(p.stem.replace("epoch","")))
if ckpts:
    last=ckpts[-1]
    start_epoch=int(last.stem.replace("epoch",""))+1
    model.load_state_dict(torch.load(last))
    optimizer.load_state_dict(torch.load(MODEL_DIR/"optim_latest.pth"))
    print(f"Resuming from {last.name}, epoch {start_epoch}")

best_r2,no_improve=-1e9,0
loss_w=np.ones(len(FREQUENCIES)*2)

# ─── Training loop ─────────────────────────────────────────────────────────
for epoch in range(start_epoch,EPOCHS+1):
    alpha=get_alpha(epoch)
    # train
    model.train();optimizer.zero_grad();train_loss=0
    preds_t,trues_t={f:[] for f in FREQUENCIES},{f:[] for f in FREQUENCIES}
    for step,(x_full,x_bands,y) in enumerate(tqdm(train_loader,desc=f"Train E{epoch}"),1):
        x_full=x_full.to(device);x_bands={k:v.to(device) for k,v in x_bands.items()};y=y.to(device)
        outs=model(x_full,x_bands,alpha)
        losses=[]
        for i,f in enumerate(FREQUENCIES):
            losses.append(criterion(outs[f],y[:,i,:]))
            losses.append(criterion(outs[f],y[:,i,:]))
        loss=(torch.stack(losses)*torch.tensor(loss_w,device=device)).mean()/ACCUM_STEPS
        loss.backward()
        if step%ACCUM_STEPS==0:
            torch.nn.utils.clip_grad_norm_(model.parameters(),CLIP_NORM)
            optimizer.step();scheduler.step();optimizer.zero_grad()
        train_loss+=loss.item()*ACCUM_STEPS*x_full.size(0)
        for i,f in enumerate(FREQUENCIES):
            preds_t[f].append(outs[f].detach().cpu());trues_t[f].append(y[:,i,:].cpu())
    train_loss/=len(train_loader.dataset)
    # val
    model.eval();val_loss=0
    preds_v,trues_v={f:[] for f in FREQUENCIES},{f:[] for f in FREQUENCIES}
    with torch.no_grad():
        for x_full,x_bands,y in tqdm(val_loader,desc=f"Val E{epoch}"):
            x_full=x_full.to(device);x_bands={k:v.to(device) for k,v in x_bands.items()};y=y.to(device)
            outs=model(x_full,x_bands,0)
            for i,f in enumerate(FREQUENCIES):
                preds_v[f].append(outs[f].cpu());trues_v[f].append(y[:,i,:].cpu())
            val_loss+=sum(criterion(outs[f],y[:,i,:]).item() for i,f in enumerate(FREQUENCIES))*x_full.size(0)
    val_loss/=len(val_loader.dataset)
    # metrics
    train_m,val_m={},{}
    for f in FREQUENCIES:
        p_t=torch.cat(preds_t[f]).numpy();t_t=torch.cat(trues_t[f]).numpy()
        p_v=torch.cat(preds_v[f]).numpy();t_v=torch.cat(trues_v[f]).numpy()
        train_m[f]={'C50':_stats(t_t[:,0],p_t[:,0]),'T60':_stats(t_t[:,1],p_t[:,1])}
        val_m[f]  ={'C50':_stats(t_v[:,0],p_v[:,0]),'T60':_stats(t_v[:,1],p_v[:,1])}
    avg_r2=np.mean([val_m[b][v][2] for b in FREQUENCIES for v in ("C50","T60")])
    torch.save(model.state_dict(),MODEL_DIR/f"epoch{epoch}.pth")
    torch.save(optimizer.state_dict(),MODEL_DIR/"optim_latest.pth")
    if avg_r2>best_r2:
        best_r2,no_improve=avg_r2,0
        torch.save(model.state_dict(),MODEL_DIR/"best.pth")
    else:
        no_improve+=1
        if no_improve>=PATIENCE:
            print(f"Early stopping at epoch {epoch}")
            break
    print(f"Epoch {epoch}/{EPOCHS} | α={alpha:.2f} | L_tr={train_loss:.4f} | L_v={val_loss:.4f} | R²̄_val={avg_r2:.3f}")
    hdr="Band | RMSE_t | MAE_t | R2_t | PCC_t | RMSE_v | MAE_v | R2_v | PCC_v"
    for var in ("C50","T60"):
        print(f"── {var} ──\n{hdr}\n"+"-"*len(hdr))
        for b in FREQUENCIES:
            rt,ma,r2,pc=train_m[b][var];rv,ma2,r22,pc2=val_m[b][var]
            print(f"{b:>4} |{rt:6.3f}|{ma:6.3f}|{r2:5.2f}|{pc:5.2f}|{rv:6.3f}|{ma2:6.3f}|{r22:5.2f}|{pc2:5.2f}")
    with CSV_METRICS.open("a",newline="",encoding="utf-8") as f:
        w=csv.writer(f)
        for b in FREQUENCIES:
            for var in ("C50","T60"):
                rt,ma,r2,pc=train_m[b][var];rv,ma2,r22,pc2=val_m[b][var]
                w.writerow([epoch,b,var,f"{rt:.6f}",f"{ma:.6f}",f"{r2:.6f}",f"{pc:.6f}",f"{rv:.6f}",f"{ma2:.6f}",f"{r22:.6f}",f"{pc2:.6f}"])
print("\nTreinamento concluído!")

"""TESTE

COM GRADCAM
"""

import torch, gc

# delete variáveis grandes que você não precisa mais
try:
    del model
    del loader_inf
    del loader
    del dataset
    del df
    del preds
    del outs
except NameError:
    pass

# força coleta de lixo do Python
gc.collect()

# libera caches da GPU
torch.cuda.empty_cache()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
generate_gradcam_from_training.py
Gera Grad-CAM para C50 (idx 0) e T60 (idx 1) usando o mesmo
MultiHeadViT que foi treinado em train_smooth_curriculum_vit_checkpoint_OPT.py.
"""

import os, math, argparse, warnings
from pathlib import Path
import numpy as np, pandas as pd, librosa
import torch, torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import models
from tqdm.auto import tqdm
import matplotlib.pyplot as plt

# ─── Paths ────────────────────────────────────────────────────────────────
ROOT       = Path("/content/drive/MyDrive")
MODEL_DIR  = ROOT / "MODELOS COMPARATIVOS/logmel_SR_curriculum_checkpoint_OPT"
TEST_DIR   = ROOT / "PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE"
LABELS_CSV = ROOT / "Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv"
OUT_DIR    = MODEL_DIR / "gradcam_from_training"
OUT_DIR.mkdir(parents=True, exist_ok=True)

# ─── Bands & masks (idem treino) ──────────────────────────────────────────
FREQ_BANDS = (125, 250, 500, 1000, 2000, 4000)
FREQS      = [str(b) for b in FREQ_BANDS]
SR, N_MELS, F_MIN, F_MAX = 22050, 128, 20, 8000
mel_freqs = librosa.mel_frequencies(n_mels=N_MELS, fmin=F_MIN, fmax=F_MAX)
def mask_to_224(mask):
    arr = np.repeat(mask.astype(np.float32)[:,None], 224, axis=1)
    t   = torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)
    return F.interpolate(t, size=(224,224), mode="nearest").squeeze().bool()
MASKS_224 = {str(b): mask_to_224((mel_freqs>=b/math.sqrt(2))&(mel_freqs<b*math.sqrt(2)))
             for b in FREQ_BANDS}

# ─── Dataset ──────────────────────────────────────────────────────────────
class SpectroDataset(torch.utils.data.Dataset):
    def __init__(self, df, root):
        self.df, self.root = df.reset_index(drop=True), Path(root)
    def __len__(self): return len(self.df)
    def __getitem__(self, idx):
        row = self.df.loc[idx]
        x   = torch.load(self.root/row.tensor_filename)          # (3,H,W) or (1,H,W)
        if x.shape[0]==1: x = x.repeat(3,1,1)
        if x.shape[-2:]!=(224,224):
            x = F.interpolate(x.unsqueeze(0), size=(224,224),
                              mode="bilinear", align_corners=False).squeeze(0)
        x_bands = {b: x.clone().masked_fill(~MASKS_224[b], 0.) for b in FREQS}
        return x, x_bands                # y não é necessário para Grad-CAM

# ─── Modelo (mesmo do treino) ─────────────────────────────────────────────
class MultiHeadViT(torch.nn.Module):
    def __init__(self, hidden_dim=128, dropout=0.4):
        super().__init__()
        vit = models.vit_b_16(weights=None)       # mesma arquitetura
        vit.heads = torch.nn.Identity()           # remove head original
        self.backbone = vit
        feat_dim = vit.hidden_dim
        self.heads = torch.nn.ModuleDict({
            b: torch.nn.Sequential(
                torch.nn.Linear(feat_dim, hidden_dim),
                torch.nn.GELU(),
                torch.nn.Dropout(dropout),
                torch.nn.Linear(hidden_dim, 2)
            ) for b in FREQS
        })
    def forward(self, x_full, x_bands, alpha=0.0):
        out = {}
        for b in FREQS:
            x_mix = alpha * x_bands[b] + (1-alpha) * x_full   # (B,3,224,224)
            feats = self.backbone(x_mix)                      # (B,768)
            out[b] = self.heads[b](feats)                    # (B,2)
        return out

# ─── Grad-CAM util ────────────────────────────────────────────────────────
def gradcam(feature, grad):
    w   = grad.mean(dim=(2,3), keepdim=True)
    cam = torch.relu((w*feature).sum(1, keepdim=True))
    mi, ma = cam.amin((2,3), True), cam.amax((2,3), True)
    return (cam-mi)/(ma-mi+1e-8)

# ─── Save heatmap ─────────────────────────────────────────────────────────
def save_heatmap(mask,title,path,overlay=None,label="Intensity"):
    TIME_MAX, FREQ_MAX = 5.0, 8000
    fig,ax = plt.subplots(figsize=(4,3))
    if overlay is not None:
        ax.imshow(overlay,cmap="gray",origin="lower",
                  extent=[0,TIME_MAX,0,FREQ_MAX],aspect="auto")
    im = ax.imshow(mask,cmap="inferno",origin="lower",
                   extent=[0,TIME_MAX,0,FREQ_MAX],aspect="auto",alpha=0.6)
    ax.set_xlabel("Time (s)"); ax.set_ylabel("Frequency (Hz)")
    ax.set_title(title,fontsize=9)
    cbar = fig.colorbar(im,ax=ax,fraction=0.046,pad=0.04)
    cbar.set_label(label,rotation=270,labelpad=8)
    fig.tight_layout(); fig.savefig(path,dpi=300); plt.close(fig)

# ─── Gerar Grad-CAM ───────────────────────────────────────────────────────
def generate_gradcams(model, loader, idx_target, avg, tag):
    device = next(model.parameters()).device
    cams, overlays = {b: [] for b in FREQS}, {}
    feats, grads   = [], []

    # hooks na conv_proj do ViT torchvision
    h_f = model.backbone.conv_proj.register_forward_hook(lambda m,i,o: feats.append(o.detach()))
    h_b = model.backbone.conv_proj.register_full_backward_hook(lambda m,gi,go: grads.append(go[0].detach()))
    saved = {b: False for b in FREQS}

    for x_full, x_bands in tqdm(loader, desc=f"Grad-CAM {tag}"):
        x_full = x_full.to(device); x_full.requires_grad_(True)
        outs = model(x_full, {b:v.to(device) for b,v in x_bands.items()}, alpha=0.0)

        for b in FREQS:
            grads.clear()
            score = outs[b][:, idx_target].sum()
            model.zero_grad(set_to_none=True)
            score.backward(retain_graph=True)

            cam_batch = gradcam(feats[-1], grads[-1]).cpu()   # (B,1,14,14)
            cams[b].append(cam_batch)

            if not saved[b]:
                spec = x_full[0,0].detach().cpu().numpy()
                spec = (spec-spec.min())/(spec.max()-spec.min()+1e-8)
                overlays[b] = (cam_batch[0,0].numpy(), spec)
                saved[b] = True

        feats.clear(); x_full.requires_grad_(False); torch.cuda.empty_cache()

    h_f.remove(); h_b.remove()

    for b,lst in cams.items():
        cam_stack = torch.cat(lst,0).squeeze(1)          # (N,14,14)
        cam_final = cam_stack.mean(0) if avg else cam_stack[0]
        save_heatmap(cam_final.numpy(),f"{tag}_{b} Grad-CAM",
                     OUT_DIR/f"{tag}_{b}_gradcam.png")
        heat,spec = overlays[b]
        save_heatmap(heat,f"{tag}_{b} Overlay",
                     OUT_DIR/f"{tag}_{b}_overlay.png",overlay=spec)

# ─── Main ─────────────────────────────────────────────────────────────────
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--ckpt", default="best.pth")
    ap.add_argument("--avg",  action="store_true")
    ap.add_argument("--bs_cam", type=int, default=2)
    ap.add_argument("--num_workers", type=int, default=0)
    args, _ = ap.parse_known_args()   # ignora o -f do Jupyter

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    df = pd.read_csv(LABELS_CSV)
    df["tensor_filename"] = df.name.str.replace(r"\.wav$","",regex=True)+".pt"
    valid = {p.name for p in TEST_DIR.rglob("*.pt")}
    df = df[df.tensor_filename.isin(valid)].reset_index(drop=True)

    loader = DataLoader(
        SpectroDataset(df, TEST_DIR),
        batch_size=args.bs_cam,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=True
    )

    model = MultiHeadViT().to(device)
    model.load_state_dict(torch.load(MODEL_DIR/args.ckpt, map_location=device))
    model.eval()

    generate_gradcams(model, loader, idx_target=0, avg=args.avg, tag="C50")
    generate_gradcams(model, loader, idx_target=1, avg=args.avg, tag="T60")

    print("\n✓ Grad-CAMs salvos em:", OUT_DIR.resolve())

if __name__=="__main__":
    with warnings.catch_warnings():
        warnings.simplefilter("ignore",category=FutureWarning)
        main()

"""### EXTRAINDO .CSV DAS INTENSIDADES"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
generate_gradcam_patch_vectors.py
────────────────────────────────────────────────────────────────────────────
• Gera Grad-CAM + overlay para C50 (idx 0) e T60 (idx 1).
• Para cada amostra, salva um vetor de 196 intensidades (14×14 patches) em CSV:
    filename, patch_0, patch_1, …, patch_195
Ex.: room_999_FULL_src4_rec4_mic1,0.82,0.74,…,0.23
"""

# ───────────────────────── Imports ────────────────────────────────────────
import os, math, csv, argparse, warnings
from pathlib import Path
import numpy as np, pandas as pd, librosa
import torch, torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import models
from tqdm.auto import tqdm
import matplotlib.pyplot as plt

# ──────────────────────── Paths & Constantes ──────────────────────────────
ROOT       = Path("/content/drive/MyDrive")
MODEL_DIR  = ROOT / "MODELOS COMPARATIVOS/logmel_SR_curriculum_checkpoint_OPT"
TEST_DIR   = ROOT / "PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE"
LABELS_CSV = ROOT / "Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv"
OUT_DIR    = MODEL_DIR / "gradcam_patch_vectors"
OUT_DIR.mkdir(parents=True, exist_ok=True)

FREQ_BANDS = (125, 250, 500, 1000, 2000, 4000)
FREQS      = [str(b) for b in FREQ_BANDS]

SR, N_MELS, F_MIN, F_MAX = 22050, 128, 20, 8000

# ──────────────────────── Band Masks (14×14) ──────────────────────────────
mel_freqs = librosa.mel_frequencies(n_mels=N_MELS, fmin=F_MIN, fmax=F_MAX)
def _mask_to_224(mask):
    arr = np.repeat(mask.astype(np.float32)[:, None], 224, axis=1)
    t   = torch.from_numpy(arr)[None, None]
    return F.interpolate(t, size=(224,224), mode="nearest").squeeze().bool()
MASKS_224 = { str(b): _mask_to_224((mel_freqs>=b/math.sqrt(2)) &
                                   (mel_freqs<b*math.sqrt(2)))
              for b in FREQ_BANDS }

# ───────────────────────── Dataset ────────────────────────────────────────
class SpectroDataset(torch.utils.data.Dataset):
    def __init__(self, df, root):
        self.df, self.root = df.reset_index(drop=True), Path(root)
    def __len__(self): return len(self.df)
    def __getitem__(self, idx):
        row = self.df.loc[idx]
        fname = row.tensor_filename             # .pt filename
        x = torch.load(self.root / fname)       # (C,H,W)
        if x.shape[0] == 1:
            x = x.repeat(3,1,1)                 # make 3-ch
        if x.shape[-2:] != (224,224):
            x = F.interpolate(
                x.unsqueeze(0), size=(224,224),
                mode="bilinear", align_corners=False
            ).squeeze(0)
        x_bands = { b: x.clone().masked_fill(~MASKS_224[b], 0.)
                    for b in FREQS }
        return x, x_bands, fname.replace(".pt","")  # strip .pt for CSV

# ───────────────────────── Modelo ─────────────────────────────────────────
class MultiHeadViT(torch.nn.Module):
    def __init__(self, hidden_dim=128, dropout=0.4):
        super().__init__()
        vit = models.vit_b_16(weights=None)   # mesma arquitetura do treino
        vit.heads = torch.nn.Identity()
        self.backbone = vit
        feat_dim = vit.hidden_dim
        self.heads = torch.nn.ModuleDict({
            b: torch.nn.Sequential(
                torch.nn.Linear(feat_dim, hidden_dim),
                torch.nn.GELU(),
                torch.nn.Dropout(dropout),
                torch.nn.Linear(hidden_dim, 2)
            ) for b in FREQS
        })
    def forward(self, x_full, x_bands, alpha=0.0):
        out={}
        for b in FREQS:
            mix = alpha*x_bands[b] + (1-alpha)*x_full
            feats = self.backbone(mix)        # (B,768)
            out[b] = self.heads[b](feats)     # (B,2)
        return out

# ───────────────────── Grad-CAM util ──────────────────────────────────────
def gradcam(feature, grad):
    w   = grad.mean(dim=(2,3), keepdim=True)
    cam = torch.relu((w*feature).sum(1, keepdim=True))
    mi, ma = cam.amin((2,3), True), cam.amax((2,3), True)
    return (cam - mi) / (ma - mi + 1e-8)

# ───────────────────── Save Heatmap util ──────────────────────────────────
def save_heatmap(mask, title, path, overlay=None, label="Intensity"):
    TIME_MAX, FREQ_MAX = 5.0, 8000
    fig, ax = plt.subplots(figsize=(4,3))
    if overlay is not None:
        ax.imshow(overlay, cmap="gray", origin="lower",
                  extent=[0,TIME_MAX,0,FREQ_MAX], aspect="auto")
    im = ax.imshow(mask, cmap="inferno", origin="lower",
                   extent=[0,TIME_MAX,0,FREQ_MAX], aspect="auto", alpha=0.6)
    ax.set_xlabel("Time (s)"); ax.set_ylabel("Frequency (Hz)")
    ax.set_title(title, fontsize=9)
    cbar = fig.colorbar(im, ax=ax, fraction=0.05, pad=0.04)
    cbar.set_label(label, rotation=270, labelpad=8)
    fig.tight_layout(); fig.savefig(path, dpi=300); plt.close(fig)

# ────────────────── Grad-CAM + CSV Patch Vector ───────────────────────────
def generate_gradcams(model, loader, idx_target, avg, tag):
    device = next(model.parameters()).device
    cams, overlays = {b: [] for b in FREQS}, {}
    feats, grads   = [], []
    rows_csv       = []                           # ← armazenar vetores p/ CSV

    # hooks
    h_f = model.backbone.conv_proj.register_forward_hook(
        lambda m,i,o: feats.append(o.detach()))
    h_b = model.backbone.conv_proj.register_full_backward_hook(
        lambda m,gi,go: grads.append(go[0].detach()))
    saved_overlay = {b: False for b in FREQS}

    for x_full, x_bands, names in tqdm(loader, desc=f"Grad-CAM {tag}"):
        x_full = x_full.to(device); x_full.requires_grad_(True)
        outs = model(x_full, {b:v.to(device) for b,v in x_bands.items()}, alpha=0.0)

        for b in FREQS:
            grads.clear()
            score = outs[b][:, idx_target].sum()
            model.zero_grad(set_to_none=True)
            score.backward(retain_graph=True)

            cam_batch = gradcam(feats[-1], grads[-1]).cpu()   # (B,1,14,14)
            cams[b].append(cam_batch)

            # --- salva vetor de patches (196) por sample ---
            for i, fname in enumerate(names):
                rows_csv.append(
                    [fname] + cam_batch[i,0].flatten().tolist()
                )
            # ------------------------------------------------

            if not saved_overlay[b]:
                spec = x_full[0,0].detach().cpu().numpy()
                spec = (spec - spec.min())/(spec.max()-spec.min()+1e-8)
                overlays[b] = (cam_batch[0,0].numpy(), spec)
                saved_overlay[b] = True

        feats.clear(); x_full.requires_grad_(False); torch.cuda.empty_cache()

    h_f.remove(); h_b.remove()

    # --------- grava CSV --------------
    csv_path = OUT_DIR / f"patch_vectors_{tag}.csv"
    header = ["filename"] + [f"patch_{i}" for i in range(196)]
    with open(csv_path, "w", newline="") as f:
        writer = csv.writer(f); writer.writerow(header); writer.writerows(rows_csv)
    # ----------------------------------

    # --------- salva heatmaps ----------
    for b, lst in cams.items():
        cam_stack = torch.cat(lst,0).squeeze(1)       # (N,14,14)
        cam_final = cam_stack.mean(0) if avg else cam_stack[0]
        save_heatmap(cam_final.numpy(), f"{tag}_{b} Grad-CAM",
                     OUT_DIR/f"{tag}_{b}_gradcam.png")
        heat, spec = overlays[b]
        save_heatmap(heat, f"{tag}_{b} Overlay",
                     OUT_DIR/f"{tag}_{b}_overlay.png", overlay=spec)
    # ----------------------------------

# ───────────────────────────── main ───────────────────────────────────────
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--ckpt", default="best.pth")
    ap.add_argument("--avg",  action="store_true")
    ap.add_argument("--bs_cam", type=int, default=2)
    ap.add_argument("--num_workers", type=int, default=0)
    args, _ = ap.parse_known_args()   # ignora -f do Jupyter

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    df = pd.read_csv(LABELS_CSV)
    df["tensor_filename"] = df.name.str.replace(r"\.wav$", "", regex=True)+".pt"
    valid = {p.name for p in TEST_DIR.rglob("*.pt")}
    df = df[df.tensor_filename.isin(valid)].reset_index(drop=True)

    loader = DataLoader(
        SpectroDataset(df, TEST_DIR),
        batch_size=args.bs_cam,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=True
    )

    model = MultiHeadViT().to(device)
    model.load_state_dict(torch.load(MODEL_DIR/args.ckpt, map_location=device))
    model.eval()

    generate_gradcams(model, loader, idx_target=0, avg=args.avg, tag="C50")
    generate_gradcams(model, loader, idx_target=1, avg=args.avg, tag="T60")

    print("\n✓ Grad-CAM e CSVs salvos em:", OUT_DIR.resolve())

if __name__ == "__main__":
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=FutureWarning)
        main()

# cluster_by_band_kmeans_withplots.py
# --------------------------------------------------------------------
# Igual ao script de clustering anterior, mas:
#   • Salva PNG do mapa médio DE CADA CLUSTER
#     – resolução 224×224 px (14×14 up-sample “nearest”)
#     – barra de intensidade, eixos e título no estilo do exemplo.
# --------------------------------------------------------------------
import pandas as pd, numpy as np
from pathlib import Path
from tqdm.auto import tqdm
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# ------------- caminhos -------------
BASE = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/"
            "logmel_SR_curriculum_checkpoint_OPT/gradcam_patch_vectors")
FILES = { "C50": BASE / "patch_vectors_C50.csv",
          "T60": BASE / "patch_vectors_T60.csv" }
BANDS = ["125","250","500","1000","2000","4000"]
OUT   = BASE / "cluster_heatmaps_labeled"
OUT.mkdir(exist_ok=True, parents=True)

# ------------- hiper -------------
K_MIN, K_MAX = 2, 12
FIG_DPI      = 250             # controla resolução do PNG
TIME_MAX     = 5.0             # usado em extent
FREQ_MAX     = 8000
# ----------------------------------

def ensure_band(df):
    if "band" not in df.columns:
        reps = len(df) // 6
        df.insert(1, "band", BANDS * reps)
    return df

def preprocess(X):
    X = X / (X.max(1,keepdims=True)+1e-8)
    X = StandardScaler().fit_transform(X)
    return PCA(0.95).fit_transform(X)

def best_kmeans(X):
    best_s, best_lab, best_k = -1, None, None
    for k in range(K_MIN, K_MAX+1):
        lab = KMeans(k, n_init=10, random_state=42).fit_predict(X)
        s   = silhouette_score(X, lab) if k>1 else -1
        if s > best_s: best_s, best_lab, best_k = s, lab, k
    return best_k, best_s, best_lab

def save_heat(arr14, title, path):
    upscale = 16                               # 14×16 ≃ 224 px
    big = np.kron(arr14, np.ones((upscale,upscale)))
    fig, ax = plt.subplots(figsize=(4,3), dpi=FIG_DPI)
    im = ax.imshow(big, cmap="inferno", origin="lower",
                   extent=[0, TIME_MAX, 0, FREQ_MAX], aspect="auto")
    ax.set_xlabel("Time (s)");  ax.set_ylabel("Frequency (Hz)")
    ax.set_title(title, fontsize=10)
    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    cbar.set_label("Intensity", rotation=270, labelpad=8)
    fig.tight_layout()
    fig.savefig(path, dpi=FIG_DPI)
    plt.close(fig)

# ------------- main loop -------------
for tag, csv in FILES.items():
    print(f"\n=== {tag} ===")
    df_all = ensure_band(pd.read_csv(csv))

    for band in tqdm(BANDS, desc=f"{tag} | bandas"):
        sub = df_all[df_all.band==band].reset_index(drop=True)
        X   = sub.filter(like="patch_").values.astype(np.float32)
        Xp  = preprocess(X)
        k_opt, sil, labels = best_kmeans(Xp)

        # salva CSV rotulado
        out_csv = csv.with_name(f"{tag}_{band}Hz_k{k_opt}.csv")
        pd.DataFrame({"filename":sub.filename, "band":band,
                      "cluster":labels}).to_csv(out_csv,index=False)

        print(f"  {band} Hz → k={k_opt}, silhouette={sil:.3f}")

        # gera e salva o mapa médio de cada cluster
        for cid in range(k_opt):
            mask = labels == cid
            if not mask.any(): continue
            mean_map = X[mask].mean(0).reshape(14,14)
            out_dir  = OUT / tag / band
            out_dir.mkdir(parents=True, exist_ok=True)
            fname = out_dir / f"cluster_{cid}_k{k_opt}.png"
            save_heat(mean_map,
                      f"{tag} {band} Hz – cluster {cid}",
                      fname)

print("\n✓ Mapas médios + CSVs em:", OUT.resolve())

import pandas as pd

csv_path = '/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv'
df_params = pd.read_csv(csv_path)

print(df_params.shape)   # (linhas, colunas)
df_params.head()         # mostra as primeiras linhas

df_params.info()

#!/usr/bin/env python3
# analyse_cluster_physics.py
# ───────────────────────────────────────────────────────────────────
# Mostra estatísticas físicas das salas para cada cluster de um
# arquivo <TAG>_<BAND>Hz_k<K>.csv (gerado no passo de K-means).
#
# • Imprime:
#     – nº de linhas por cluster
#     – exemplos de filenames
#     – salas distintas e dimensões
#     – contagem de receivers / sources / noises
# • Gera um CSV por cluster contendo todos os filenames desse grupo
#   na mesma pasta do arquivo de entrada.
# ───────────────────────────────────────────────────────────────────
import re
import pandas as pd
from pathlib import Path
from tqdm.auto import tqdm

# ======================== CONFIGURE AQUI ==========================
TAG  = "C50"      # "C50" ou "T60"
BAND = "125"      # "125" "250" "500" "1000" "2000" "4000"
K    = 2          # k usado no nome do arquivo (_k2.csv, _k3.csv, ...)
# ================================================================ #

# ---- caminhos principais ----
BASE = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/"
            "logmel_SR_curriculum_checkpoint_OPT/gradcam_patch_vectors")
CLUSTER_CSV = BASE / f"{TAG}_{BAND}Hz_k{K}.csv"

PARQUET_DIR = Path("/content/drive/MyDrive/Dissertação - Mestrado/config_salas")
rooms_df     = pd.read_parquet(PARQUET_DIR / "rooms.parquet")
receivers_df = pd.read_parquet(PARQUET_DIR / "receivers.parquet")
sources_df   = pd.read_parquet(PARQUET_DIR / "sources.parquet")
noises_df    = pd.read_parquet(PARQUET_DIR / "noises.parquet")

# ---- carrega CSV de clusters ----
df_clu = pd.read_csv(CLUSTER_CSV)
if "cluster" not in df_clu.columns:
    raise ValueError("CSV não contém coluna 'cluster'.")

# extrai room_key (ex.: room_0) do filename
df_clu["room_key"] = df_clu["filename"].str.extract(r"^(room_\d+)", expand=False)

print(f"\nArquivo: {CLUSTER_CSV.name}\nTotal de linhas: {len(df_clu)}")

# ---- varre clusters ----
for cid, grp in df_clu.groupby("cluster"):
    if cid == -1:          # outliers (caso DBSCAN)
        continue

    n_rows = len(grp)
    sample_names = ", ".join(grp["filename"].head(5))

    room_keys = grp["room_key"].unique()
    rooms_sub = rooms_df[rooms_df["room_key"].isin(room_keys)]

    dims = rooms_sub["dimensions"].tolist()[:3]
    dims_txt = f"{dims} ..." if len(rooms_sub) > 3 else f"{dims}"

    n_recv = len(receivers_df[receivers_df["room_key"].isin(room_keys)])
    n_src  = len(sources_df[sources_df["room_key"].isin(room_keys)])
    n_noi  = len(noises_df[noises_df["room_key"].isin(room_keys)])

    print(f"\n══ Cluster {cid} ══")
    print(f" • linhas           : {n_rows}")
    print(f" • exemplos         : {sample_names}")
    print(f" • salas distintas  : {len(room_keys)}")
    print(f" • dimensões (m)    : {dims_txt}")
    print(f" • receivers linhas : {n_recv}")
    print(f" • sources   linhas : {n_src}")
    print(f" • noises    linhas : {n_noi}")

    # ---- salva CSV do cluster ----
    out_csv = CLUSTER_CSV.with_name(f"{TAG}_{BAND}Hz_cluster{cid}.csv")
    grp[["filename", "room_key"]].to_csv(out_csv, index=False)
    print(f"   ↳ CSV salvo: {out_csv.name}")

#!/usr/bin/env python3
# analyse_cluster_physics_with_params.py
# ───────────────────────────────────────────────────────────────────
# Para cada cluster em <TAG>_<BAND>Hz_k<K>.csv, imprime estatísticas físicas
# das salas e parâmetros acústicos vindos de merged_params.csv, e salva CSV
# detalhado por cluster.
# ───────────────────────────────────────────────────────────────────
import re
import pandas as pd
from pathlib import Path
from tqdm.auto import tqdm

# ======================== CONFIGURE AQUI ==========================
TAG        = "T60"      # "C50" ou "T60"
BAND       = "125"      # "125","250","500","1000","2000","4000"
K          = 2          # valor de k no nome do arquivo (_k2.csv)
# caminhos
BASE       = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/"
                  "logmel_SR_curriculum_checkpoint_OPT/gradcam_patch_vectors")
PARAMS_CSV = Path("/content/drive/MyDrive/Dissertação - Mestrado/"
                  "NOVA_ALT_3/PARÂMETROS/merged_params.csv")
PARQ_DIR   = Path("/content/drive/MyDrive/Dissertação - Mestrado/config_salas")
# ==================================================================

# --- carregar Parquets ---
rooms_df     = pd.read_parquet(PARQ_DIR / "rooms.parquet")
receivers_df = pd.read_parquet(PARQ_DIR / "receivers.parquet")
sources_df   = pd.read_parquet(PARQ_DIR / "sources.parquet")
noises_df    = pd.read_parquet(PARQ_DIR / "noises.parquet")

# --- carregar parâmetros acústicos ---
df_params = pd.read_csv(PARAMS_CSV)
# extrai filename sem extensão
df_params["filename"] = df_params["name"].str.replace(r"\.wav$", "", regex=True)

# colunas de interesse em merged_params
param_cols = [
    "abs_media_125","abs_media_250","abs_media_500","abs_media_1000",
    "abs_media_2000","abs_media_4000",
    "T60_125","C50_125","T60_250","C50_250","T60_500","C50_500",
    "T60_1000","C50_1000","T60_2000","C50_2000","T60_4000","C50_4000",
    "Surface Area (m²)","Volume (m³)"
]

# --- carregar CSV de clusters ---
cluster_csv = BASE / f"{TAG}_{BAND}Hz_k{K}.csv"
df_clu = pd.read_csv(cluster_csv)
df_clu["room_key"] = df_clu["filename"].str.extract(r"^(room_\d+)", expand=False)
print(f"\nArquivo: {cluster_csv.name} | total linhas = {len(df_clu)}")

# --- varre cada cluster ---
for cid, grp in df_clu.groupby("cluster"):
    if cid == -1:
        continue
    n_rows = len(grp)
    sample5 = ", ".join(grp["filename"].head(5))
    room_keys = grp["room_key"].unique()
    rooms_sub = rooms_df[rooms_df["room_key"].isin(room_keys)]
    dims = rooms_sub["dimensions"].tolist()[:3]
    dims_txt = f"{dims} ..." if len(rooms_sub)>3 else f"{dims}"

    # estatísticas acústicas médias por cluster
    df_pm = grp.merge(df_params[["filename"]+param_cols],
                      on="filename", how="left")
    mean_params = df_pm[param_cols].mean()

    # contagens de registros nos Parquets
    n_recv = len(receivers_df[receivers_df["room_key"].isin(room_keys)])
    n_src  = len(sources_df  [sources_df["room_key"].isin(room_keys)])
    n_noi  = len(noises_df   [noises_df["room_key"].isin(room_keys)])

    # imprime resumo
    print(f"\n══ Cluster {cid} ══")
    print(f" • linhas           : {n_rows}")
    print(f" • exemplos         : {sample5}")
    print(f" • salas distintas  : {len(room_keys)}")
    print(f" • dimensões (m)    : {dims_txt}")
    print(f" • receivers linhas : {n_recv}")
    print(f" • sources   linhas : {n_src}")
    print(f" • noises    linhas : {n_noi}")
    print("\n • Parâmetros acústicos médios:")
    for col in param_cols:
        print(f"    – {col:<15}: {mean_params[col]:.3f}")

    # salva CSV detalhado do cluster
    out_csv = cluster_csv.with_name(f"{TAG}_{BAND}Hz_cluster{cid}_full.csv")
    df_pm.to_csv(out_csv, index=False)
    print(f"   ↳ CSV salvo: {out_csv.name}")

"""# PROXIMO PASSO: FAZER A MESMA TECNICA DE AGRUPAMENTO PARA O GRADCAM SEM CURRICULUM LEARNING (EM CIMA). COMPARAR PAR A PAR.

## TREINANDO LOG-MEL - 1R

## TREINANDO LOG-MEL - 5R

# MODELO 4 - 2 HEADS (T60, C50)

## TREINANDO LOG-MEL - SR
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_twohead_param_kfold_vit.py
──────────────────────────────────────────────────────────────────────────────
• Treina (e retoma, se existir) um ViT-B/16 multitarefa com **duas** cabeças:
      – Cabeça “C50”: devolve 6 valores (125-4000 Hz)
      – Cabeça “T60”: devolve 6 valores (125-4000 Hz)
• Validação K-Fold e retomada automática de checkpoints
• Checkpoints (por fold-época/“best”/“*_latest”) + otimizador
• Scalers StandardScaler gravados por parâmetro-banda
• CSV global append-only com RMSE, MAE, R², PCC (treino/validação)
• Early-stopping removido — sempre percorre todas as épocas
"""

# ───────────────────────── Imports ──────────────────────────
import os, re, random, pickle, math, warnings
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

warnings.filterwarnings("ignore", category=FutureWarning)
torch.backends.cuda.matmul.allow_tf32 = True   # GPUs Ampere+

# ─────────────────── Caminhos principais ────────────────────
TRAIN_DIR   = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TREINO_VALID")
LABELS_PATH = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR   = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_MODELO_4")
MODEL_DIR.mkdir(parents=True, exist_ok=True)

CSV_METRICS = MODEL_DIR / "all_metrics.csv"
if not CSV_METRICS.exists():
    CSV_METRICS.write_text(
        "fold,epoch,param,band,rmse_t,mae_t,r2_t,pcc_t,rmse_v,mae_v,r2_v,pcc_v\n",
        encoding="utf-8"
    )

# ────────────────── Hiperparâmetros ──────────────────
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQUENCIES = [str(b) for b in FREQ_BANDS]
PARAMS      = ("C50", "T60")

BATCH_SIZE  = 16
EPOCHS      = 100
NUM_FOLDS   = 5
SEED        = 42
CLIP_NORM   = 1.0
DROPOUT_P   = 0.2

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ───────────────────── Dataset ──────────────────────
class SpectroDataset(Dataset):
    """
    Devolve:
        x : Tensor [3, 224, 224]
        y : Tensor [2, 6]  (dim 0 = [C50, T60]; dim 1 = bandas)
    """
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir

    def __len__(self) -> int:
        return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])        # [C, H, W]
        if x.shape[0] == 1:                                              # força 3 canais
            x = x.repeat(3, 1, 1)
        if x.shape[-2:] != (224, 224):                                   # resize
            x = F.interpolate(x.unsqueeze(0), 224,
                              mode="bilinear", align_corners=False).squeeze(0)
        y_c50 = [row[f"C50_{b}"] for b in FREQ_BANDS]
        y_t60 = [row[f"T60_{b}"] for b in FREQ_BANDS]
        y = torch.tensor([y_c50, y_t60], dtype=torch.float32)            # [2, 6]
        return x, y

# ─────────────── Modelo ViT com 2 cabeças ───────────────
class TwoHeadViT(nn.Module):
    """
    • Uma única backbone ViT-B/16
    • Duas cabeças independentes (C50 e T60), cada uma ⇒ 6 saídas
    """
    def __init__(self, hidden_dim: int = 128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads = nn.Identity()
        self.backbone = vit
        feat_dim = vit.hidden_dim                                      # 768
        self.heads = nn.ModuleDict({
            "C50": nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(DROPOUT_P),
                nn.Linear(hidden_dim, len(FREQ_BANDS))
            ),
            "T60": nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(DROPOUT_P),
                nn.Linear(hidden_dim, len(FREQ_BANDS))
            )
        })

    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        feats = self.backbone(x)           # CLS token  [B, 768]
        return {p: head(feats) for p, head in self.heads.items()}  # cada [B, 6]

# ─────────────── Utilidades de métrica ───────────────
def _stats(a: np.ndarray, b: np.ndarray):
    return (math.sqrt(mean_squared_error(a, b)),
            mean_absolute_error(a, b),
            r2_score(a, b),
            np.corrcoef(a, b)[0, 1])

def compute_metrics(pred, true, sc_c50, sc_t60):
    """
    pred/true: Dict[param] -> List[tensor [B, 6]]
    Retorna: dict[param][band] = tuple métricas
    """
    out = {p: {} for p in PARAMS}
    for j, band in enumerate(FREQUENCIES):
        p_c50 = torch.cat(pred["C50"])[:, j:j+1].cpu().numpy()
        t_c50 = torch.cat(true["C50"])[:, j:j+1].cpu().numpy()
        p_t60 = torch.cat(pred["T60"])[:, j:j+1].cpu().numpy()
        t_t60 = torch.cat(true["T60"])[:, j:j+1].cpu().numpy()

        p_c50 = sc_c50[band].inverse_transform(p_c50).ravel()
        t_c50 = sc_c50[band].inverse_transform(t_c50).ravel()
        p_t60 = sc_t60[band].inverse_transform(p_t60).ravel()
        t_t60 = sc_t60[band].inverse_transform(t_t60).ravel()

        out["C50"][band] = _stats(t_c50, p_c50)
        out["T60"][band] = _stats(t_t60, p_t60)
    return out

def find_last_epoch(ckpt_dir: Path, fold: int) -> Tuple[int, Path, Path]:
    pattern = re.compile(rf"fold{fold}_epoch(\d+)\.pth$")
    epochs = [(int(m.group(1)), p) for p in ckpt_dir.glob(f"fold{fold}_epoch*.pth")
              if (m := pattern.search(p.name))]
    if not epochs:
        return 0, None, None
    last_epoch, ckpt_path = max(epochs, key=lambda x: x[0])
    opt_path = ckpt_dir / f"fold{fold}_optim_latest.pth"
    return last_epoch, ckpt_path, opt_path if opt_path.exists() else None

# ──────────── Carrega labels e filtros ────────────
print("Lendo labels …")
df = pd.read_csv(LABELS_PATH)
df["tensor_filename"] = df["name"].str.replace(r"\.wav$", "", regex=True) + ".pt"
existing = {p.name for p in TRAIN_DIR.rglob("*.pt")}
df = df[df["tensor_filename"].isin(existing)].reset_index(drop=True)
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(subset=[f"{p}_{b}" for p in PARAMS for b in FREQ_BANDS], inplace=True)

kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)

# ─────────────────────── Loop K-Fold ───────────────────────
for fold, (tr_idx, v_idx) in enumerate(kf.split(df), 1):
    print(f"\n══════════ FOLD {fold}/{NUM_FOLDS} ══════════")
    fold_dir   = MODEL_DIR / f"fold_{fold}"
    ckpt_dir   = fold_dir / "checkpoints"
    scaler_dir = fold_dir / "scalers"
    ckpt_dir.mkdir(parents=True, exist_ok=True)
    scaler_dir.mkdir(parents=True, exist_ok=True)

    train_df, val_df = df.iloc[tr_idx].copy(), df.iloc[v_idx].copy()

    # ── StandardScalers (uma por parâmetro-banda) ──
    scalers_c50, scalers_t60 = {}, {}
    for band in FREQUENCIES:
        sc_c = StandardScaler().fit(train_df[[f"C50_{band}"]])
        sc_t = StandardScaler().fit(train_df[[f"T60_{band}"]])
        (scaler_dir / f"scaler_C50_{band}.pkl").write_bytes(pickle.dumps(sc_c))
        (scaler_dir / f"scaler_T60_{band}.pkl").write_bytes(pickle.dumps(sc_t))
        train_df[f"C50_{band}"] = sc_c.transform(train_df[[f"C50_{band}"]])
        val_df[f"C50_{band}"]   = sc_c.transform(val_df[[f"C50_{band}"]])
        train_df[f"T60_{band}"] = sc_t.transform(train_df[[f"T60_{band}"]])
        val_df[f"T60_{band}"]   = sc_t.transform(val_df[[f"T60_{band}"]])
        scalers_c50[band] = sc_c
        scalers_t60[band] = sc_t

    train_loader = DataLoader(
        SpectroDataset(train_df, TRAIN_DIR),
        batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True
    )
    val_loader = DataLoader(
        SpectroDataset(val_df, TRAIN_DIR),
        batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True
    )

    model = TwoHeadViT().to(device)
    criterion = nn.MSELoss()

    param_groups = (
        [{"params": model.backbone.parameters(), "lr": 3e-6, "weight_decay": 1e-4}] +
        [{"params": model.heads["C50"].parameters(), "lr": 3e-4, "weight_decay": 1e-2},
         {"params": model.heads["T60"].parameters(), "lr": 3e-4, "weight_decay": 1e-2}]
    )
    optimizer = optim.AdamW(param_groups, betas=(0.9, 0.999))

    # ─── Retomada ───
    start_epoch = 1
    last_epoch, ckpt_path, opt_path = find_last_epoch(ckpt_dir, fold)
    if ckpt_path is not None:
        model.load_state_dict(torch.load(ckpt_path, map_location=device))
        if opt_path is not None:
            optimizer.load_state_dict(torch.load(opt_path, map_location=device))
            for state in optimizer.state.values():       # corrige device
                for k, v in state.items():
                    if torch.is_tensor(v):
                        state[k] = v.to(device)
        start_epoch = last_epoch + 1
        print(f">>> Retomando da época {last_epoch} (checkpoint: {ckpt_path.name})")
    else:
        print(">>> Nenhum checkpoint — iniciando do zero")

    total_steps = len(train_loader) * EPOCHS
    scheduler = optim.lr_scheduler.OneCycleLR(
        optimizer,
        max_lr=[1e-4] + [5e-4]*2,                        # backbone + 2 heads
        pct_start=3/EPOCHS,
        div_factor=25, final_div_factor=1e3,
        total_steps=total_steps,
        last_epoch=(start_epoch - 2)
    )

    best_r2 = -float("inf")

    # ─────────── EPOCH LOOP ───────────
    for epoch in range(start_epoch, EPOCHS + 1):
        # ---------- treino ----------
        model.train()
        pred_t = {p: [] for p in PARAMS}
        true_t = {p: [] for p in PARAMS}
        loss_sum = 0.0

        for x, y in tqdm(train_loader, desc=f"[F{fold}] Train {epoch}", leave=False):
            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)  # y [B,2,6]
            optimizer.zero_grad()
            outs = model(x)                                      # dict param->[B,6]
            loss = (criterion(outs["C50"], y[:, 0, :]) +
                    criterion(outs["T60"], y[:, 1, :]))
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)
            optimizer.step()
            scheduler.step()

            loss_sum += loss.item() * x.size(0)
            for p in PARAMS:
                pred_t[p].append(outs[p].detach().cpu())
                true_t[p].append(y[:, 0 if p == "C50" else 1, :].cpu())

        train_loss = loss_sum / len(train_loader.dataset)

        # ---------- validação ----------
        model.eval()
        pred_v = {p: [] for p in PARAMS}
        true_v = {p: [] for p in PARAMS}
        val_loss_sum = 0.0
        with torch.no_grad():
            for x, y in tqdm(val_loader, desc=f"[F{fold}] Val {epoch}", leave=False):
                x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)
                outs = model(x)
                val_loss_sum += (criterion(outs["C50"], y[:, 0, :]).item()
                                 + criterion(outs["T60"], y[:, 1, :]).item()) * x.size(0)
                for p in PARAMS:
                    pred_v[p].append(outs[p].cpu())
                    true_v[p].append(y[:, 0 if p == "C50" else 1, :].cpu())

        val_loss = val_loss_sum / len(val_loader.dataset)

        # ---------- métricas ----------
        train_m = compute_metrics(pred_t, true_t, scalers_c50, scalers_t60)
        val_m   = compute_metrics(pred_v, true_v, scalers_c50, scalers_t60)
        val_r2_mean = np.mean([val_m[p][b][2] for p in PARAMS for b in FREQUENCIES])

        # ---------- checkpoints ----------
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_epoch{epoch}.pth")
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_latest.pth")
        torch.save(optimizer.state_dict(), ckpt_dir / f"fold{fold}_optim_latest.pth")
        if val_r2_mean > best_r2:
            best_r2 = val_r2_mean
            torch.save(model.state_dict(), fold_dir / "best.pth")

        # ---------- log ----------
        print(f"\n[Fold {fold}] Epoch {epoch}/{EPOCHS} — Train L={train_loss:.4f} | Val L={val_loss:.4f}")
        hdr = "Band | RMSE_t | MAE_t | R2_t  | PCC_t | RMSE_v | MAE_v | R2_v  | PCC_v"
        for p in PARAMS:
            print(f"─── {p} ───")
            print(hdr)
            print("-" * len(hdr))
            for b in FREQUENCIES:
                rt, mt, r2t, pcct = train_m[p][b]
                rv, mv, r2v, pccv = val_m[p][b]
                print(f"{b:>4} | {rt:6.3f} | {mt:6.3f} | "
                      f"{r2t:6.3f} | {pcct:6.3f} | "
                      f"{rv:6.3f} | {mv:6.3f} | "
                      f"{r2v:6.3f} | {pccv:6.3f}")
        print("=" * 90)

        # ---------- grava CSV ----------
        with CSV_METRICS.open("a", encoding="utf-8") as f_csv:
            for p in PARAMS:
                for b in FREQUENCIES:
                    rt, mt, r2t, pcct = train_m[p][b]
                    rv, mv, r2v, pccv = val_m[p][b]
                    f_csv.write(f"{fold},{epoch},{p},{b},"
                                f"{rt:.6f},{mt:.6f},{r2t:.6f},{pcct:.6f},"
                                f"{rv:.6f},{mv:.6f},{r2v:.6f},{pccv:.6f}\n")

print("\nTreinamento K-Fold concluído!")

"""TESTE"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
eval_twohead_param_vit_folds.py
──────────────────────────────────────────────────────────────────────────────
Avalia o ViT-B/16 multitarefa com DUAS cabeças (C50 e T60) treinado via
K-Fold. Para cada fold são carregados:
    • checkpoint mais recente (“*_latest”) ― ou o último epoch salvo
    • StandardScalers por parâmetro-banda (salvos na fase de treino)

A rotina:
1. Carrega o conjunto de TESTE (tensores *.pt + labels CSV)
2. Executa inferência para cada fold
3. Calcula métricas por banda (RMSE, MAE, R², PCC)
4. Gera CSVs
      ├─ metrics_folds.csv    (métricas por fold)
      ├─ metrics_ensemble.csv (métricas do ensemble - média simples)
      ├─ preds_folds.csv      (predições de cada fold)
      └─ preds_ensemble.csv   (predições do ensemble)
"""

# ───────────────────────── Imports ──────────────────────────
import warnings, pickle, re
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

# ─────────────────── Configurações ────────────────────
MODEL_DIR  = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_SR_MODELO_4")
TEST_DIR   = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/SR_mod/log_mel_PASTA_UNICA_TESTE")
LABELS_CSV = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")

FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQS       = [str(b) for b in FREQ_BANDS]
PARAMS      = ("C50", "T60")

BATCH_SIZE  = 16
NUM_FOLDS   = 5

# Arquivos de saída
METRICS_FOLD_CSV     = MODEL_DIR / "metrics_folds.csv"
METRICS_ENSEMBLE_CSV = MODEL_DIR / "metrics_ensemble.csv"
RESULTS_FOLD_CSV     = MODEL_DIR / "preds_folds.csv"
RESULTS_ENSEMBLE_CSV = MODEL_DIR / "preds_ensemble.csv"

# ─────────────────── Funções utilitárias ───────────────────
rmse = lambda a, b: np.sqrt(mean_squared_error(a, b))


def metrics(a: np.ndarray, b: np.ndarray) -> Tuple[float, float, float, float]:
    """RMSE, MAE, R² e PCC."""
    a = np.asarray(a)
    b = np.asarray(b)
    return (
        rmse(a, b),
        mean_absolute_error(a, b),
        r2_score(a, b),
        np.corrcoef(a, b)[0, 1] if (a.std() and b.std()) else 0.0,
    )


def load_scalers(scaler_dir: Path):
    """Carrega scalers salvos na fase de treino."""
    sc_c50, sc_t60 = {}, {}
    for band in FREQS:
        sc_c50[band] = pickle.load(open(scaler_dir / f"scaler_C50_{band}.pkl", "rb"))
        sc_t60[band] = pickle.load(open(scaler_dir / f"scaler_T60_{band}.pkl", "rb"))
    return sc_c50, sc_t60


def inverse_scale(preds: np.ndarray, scalers: Dict[str, Dict[str, object]]):
    """
    Converte predições padronizadas → valores reais.
    preds: dict param→np.ndarray shape (N, 6)
    """
    out = {p: {} for p in PARAMS}
    sc_c50, sc_t60 = scalers
    for j, b in enumerate(FREQS):
        out["C50"][b] = sc_c50[b].inverse_transform(preds["C50"][:, j:j + 1]).ravel()
        out["T60"][b] = sc_t60[b].inverse_transform(preds["T60"][:, j:j + 1]).ravel()
    return out


# ───────────────────── Dataset de espectrogramas ─────────────────────
class SpectroDataset(Dataset):
    def __init__(self, df: pd.DataFrame, root: Path):
        self.df = df.reset_index(drop=True)
        self.root = Path(root)

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.iloc[idx]
        x = torch.load(self.root / row.tensor_filename)
        if x.shape[0] == 1:
            x = x.repeat(3, 1, 1)
        if x.shape[-2:] != (224, 224):
            x = F.interpolate(
                x.unsqueeze(0), 224, mode="bilinear", align_corners=False
            ).squeeze(0)
        return x, idx


# ───────────────────── Modelo Two-Head ViT ─────────────────────
class TwoHeadViT(nn.Module):
    def __init__(self, hidden_dim: int = 128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads = nn.Identity()
        self.backbone = vit
        feat_dim = vit.hidden_dim  # 768
        self.heads = nn.ModuleDict(
            {
                "C50": nn.Sequential(
                    nn.Linear(feat_dim, hidden_dim),
                    nn.GELU(),
                    nn.Dropout(0.2),
                    nn.Linear(hidden_dim, len(FREQS)),
                ),
                "T60": nn.Sequential(
                    nn.Linear(feat_dim, hidden_dim),
                    nn.GELU(),
                    nn.Dropout(0.2),
                    nn.Linear(hidden_dim, len(FREQS)),
                ),
            }
        )

    def forward(self, x: torch.Tensor):
        feats = self.backbone(x)  # [B, 768]
        return {p: head(feats) for p, head in self.heads.items()}


# ───────────────────────────── Main ─────────────────────────────
def main():
    # 1) DataFrame
    df = pd.read_csv(LABELS_CSV)
    df["tensor_filename"] = (
        df["name"].str.replace(r"\.wav$", "", regex=True) + ".pt"
    )
    keep = {p.name for p in TEST_DIR.rglob("*.pt")}
    df = df[df.tensor_filename.isin(keep)].reset_index(drop=True)

    # 2) DataLoader único para todo o conjunto de teste
    loader = DataLoader(
        SpectroDataset(df, TEST_DIR),
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=2,
        pin_memory=True,
    )
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 3) Estruturas de predições
    preds_fold: List[Dict[str, Dict[str, List[float]]]] = [
        {b: {"C50": [], "T60": []} for b in FREQS} for _ in range(NUM_FOLDS)
    ]

    # ────────────── Loop pelos folds ──────────────
    for fold in range(1, NUM_FOLDS + 1):
        print(f"\n════ Avaliando FOLD {fold}/{NUM_FOLDS} ════")
        fold_dir = MODEL_DIR / f"fold_{fold}"
        ckpt_dir = fold_dir / "checkpoints"
        scaler_dir = fold_dir / "scalers"

        # 3.1) Carrega scalers
        scalers = load_scalers(scaler_dir)

        # 3.2) Carrega modelo
        model = TwoHeadViT().to(device)
        ckpt_path = ckpt_dir / f"fold{fold}_latest.pth"
        if not ckpt_path.exists():
            # busca último epoch se *_latest não existir
            all_ckpt = list(ckpt_dir.glob(f"fold{fold}_epoch*.pth"))
            if not all_ckpt:
                raise FileNotFoundError(f"Nenhum checkpoint em {ckpt_dir}")
            ckpt_path = max(
                all_ckpt, key=lambda p: int(re.search(r"epoch(\d+)", p.stem).group(1))
            )
        model.load_state_dict(torch.load(ckpt_path, map_location=device))
        model.eval()
        print(f"  Checkpoint carregado: {ckpt_path.name}")

        # 3.3) Inferência
        with torch.no_grad():
            for x, idxs in tqdm(loader, desc=f"Inferência Fold {fold}", leave=False):
                x = x.to(device, non_blocking=True)
                outs = model(x)  # dict param→[B,6]
                outs_cpu = {p: outs[p].cpu().numpy() for p in PARAMS}
                # converte para valores reais
                inv = inverse_scale(outs_cpu, scalers)
                for j, global_idx in enumerate(idxs):
                    for b in FREQS:
                        preds_fold[fold - 1][b]["C50"].append(inv["C50"][b][j])
                        preds_fold[fold - 1][b]["T60"].append(inv["T60"][b][j])

        # 3.4) Métricas por fold
        with open(METRICS_FOLD_CSV, "a") as f_csv:
            print("→ Métricas por banda (RMSE | MAE | R² | PCC):")
            for b in FREQS:
                for p in PARAMS:
                    y_true = df[f"{p}_{b}"].values
                    y_pred = preds_fold[fold - 1][b][p]
                    rmse_, mae_, r2_, pcc_ = metrics(y_true, y_pred)
                    print(
                        f" {p}_{b}: {rmse_:7.4f} | {mae_:7.4f} | {r2_:7.4f} | {pcc_:7.4f}"
                    )
                    f_csv.write(
                        f"{fold},{b},{p},{rmse_:.6f},{mae_:.6f},{r2_:.6f},{pcc_:.6f}\n"
                    )

    # ────────────── Ensemble (média simples) ──────────────
    print("\n════ Métricas do ENSEMBLE (média simples) ════")
    ensemble_preds = {b: {p: [] for p in PARAMS} for b in FREQS}
    for i in range(len(df)):
        for b in FREQS:
            for p in PARAMS:
                ensemble_preds[b][p].append(
                    np.mean([preds_fold[f][b][p][i] for f in range(NUM_FOLDS)])
                )

    with open(METRICS_ENSEMBLE_CSV, "a") as f_csv:
        for b in FREQS:
            for p in PARAMS:
                y_true = df[f"{p}_{b}"].values
                y_pred = ensemble_preds[b][p]
                rmse_, mae_, r2_, pcc_ = metrics(y_true, y_pred)
                print(
                    f" {p}_{b}: {rmse_:7.4f} | {mae_:7.4f} | {r2_:7.4f} | {pcc_:7.4f}"
                )
                f_csv.write(
                    f"{b},{p},{rmse_:.6f},{mae_:.6f},{r2_:.6f},{pcc_:.6f}\n"
                )

    # ────────────── CSVs de predições ──────────────
    # (a) por fold
    results_fold = {"name": df["tensor_filename"]}
    for f in range(NUM_FOLDS):
        for b in FREQS:
            for p in PARAMS:
                results_fold[f"{p}_{b}_pred_fold{f+1}"] = preds_fold[f][b][p]
    pd.DataFrame(results_fold).to_csv(RESULTS_FOLD_CSV, index=False)
    print(f"\nCSV por-fold salvo em: {RESULTS_FOLD_CSV}")

    # (b) ensemble
    results_ens = {"name": df["tensor_filename"]}
    for b in FREQS:
        for p in PARAMS:
            results_ens[f"{p}_{b}_REAL"] = df[f"{p}_{b}"]
            results_ens[f"{p}_{b}_PRED"] = ensemble_preds[b][p]
    pd.DataFrame(results_ens).to_csv(RESULTS_ENSEMBLE_CSV, index=False)
    print(f"CSV ensemble salvo em: {RESULTS_ENSEMBLE_CSV}\n")


# ────────────────────────── Execução ──────────────────────────
if __name__ == "__main__":
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=FutureWarning)
        main()

"""## TREINANDO LOG-MEL - 1R"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_twohead_param_kfold_vit.py
──────────────────────────────────────────────────────────────────────────────
• Treina (e retoma, se existir) um ViT-B/16 multitarefa com **duas** cabeças:
      – Cabeça “C50”: devolve 6 valores (125-4000 Hz)
      – Cabeça “T60”: devolve 6 valores (125-4000 Hz)
• Validação K-Fold e retomada automática de checkpoints
• Checkpoints (por fold-época/“best”/“*_latest”) + otimizador
• Scalers StandardScaler gravados por parâmetro-banda
• CSV global append-only com RMSE, MAE, R², PCC (treino/validação)
• Early-stopping removido — sempre percorre todas as épocas
"""

# ───────────────────────── Imports ──────────────────────────
import os, re, random, pickle, math, warnings
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm.auto import tqdm

warnings.filterwarnings("ignore", category=FutureWarning)
torch.backends.cuda.matmul.allow_tf32 = True   # GPUs Ampere+

# ─────────────────── Caminhos principais ────────────────────
TRAIN_DIR   = Path("/content/drive/MyDrive/PREPROCESSING/TENSORES_DATASET/1R/log_mel_MOD_PASTA_UNICA_TREINO_VALID")
LABELS_PATH = Path("/content/drive/MyDrive/Dissertação - Mestrado/NOVA_ALT_3/PARÂMETROS/merged_params.csv")
MODEL_DIR   = Path("/content/drive/MyDrive/MODELOS COMPARATIVOS/logmel_1R_MODELO_4")
MODEL_DIR.mkdir(parents=True, exist_ok=True)

CSV_METRICS = MODEL_DIR / "all_metrics.csv"
if not CSV_METRICS.exists():
    CSV_METRICS.write_text(
        "fold,epoch,param,band,rmse_t,mae_t,r2_t,pcc_t,rmse_v,mae_v,r2_v,pcc_v\n",
        encoding="utf-8"
    )

# ────────────────── Hiperparâmetros ──────────────────
FREQ_BANDS  = (125, 250, 500, 1000, 2000, 4000)
FREQUENCIES = [str(b) for b in FREQ_BANDS]
PARAMS      = ("C50", "T60")

BATCH_SIZE  = 32
EPOCHS      = 100
NUM_FOLDS   = 5
SEED        = 42
CLIP_NORM   = 1.0
DROPOUT_P   = 0.2

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ───────────────────── Dataset ──────────────────────
class SpectroDataset(Dataset):
    """
    Devolve:
        x : Tensor [3, 224, 224]
        y : Tensor [2, 6]  (dim 0 = [C50, T60]; dim 1 = bandas)
    """
    def __init__(self, df: pd.DataFrame, tensors_dir: Path):
        self.df = df.reset_index(drop=True)
        self.tensors_dir = tensors_dir

    def __len__(self) -> int:
        return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.loc[idx]
        x = torch.load(self.tensors_dir / row["tensor_filename"])        # [C, H, W]
        if x.shape[0] == 1:                                              # força 3 canais
            x = x.repeat(3, 1, 1)
        if x.shape[-2:] != (224, 224):                                   # resize
            x = F.interpolate(x.unsqueeze(0), 224,
                              mode="bilinear", align_corners=False).squeeze(0)
        y_c50 = [row[f"C50_{b}"] for b in FREQ_BANDS]
        y_t60 = [row[f"T60_{b}"] for b in FREQ_BANDS]
        y = torch.tensor([y_c50, y_t60], dtype=torch.float32)            # [2, 6]
        return x, y

# ─────────────── Modelo ViT com 2 cabeças ───────────────
class TwoHeadViT(nn.Module):
    """
    • Uma única backbone ViT-B/16
    • Duas cabeças independentes (C50 e T60), cada uma ⇒ 6 saídas
    """
    def __init__(self, hidden_dim: int = 128):
        super().__init__()
        vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
        vit.heads = nn.Identity()
        self.backbone = vit
        feat_dim = vit.hidden_dim                                      # 768
        self.heads = nn.ModuleDict({
            "C50": nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(DROPOUT_P),
                nn.Linear(hidden_dim, len(FREQ_BANDS))
            ),
            "T60": nn.Sequential(
                nn.Linear(feat_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(DROPOUT_P),
                nn.Linear(hidden_dim, len(FREQ_BANDS))
            )
        })

    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        feats = self.backbone(x)           # CLS token  [B, 768]
        return {p: head(feats) for p, head in self.heads.items()}  # cada [B, 6]

# ─────────────── Utilidades de métrica ───────────────
def _stats(a: np.ndarray, b: np.ndarray):
    return (math.sqrt(mean_squared_error(a, b)),
            mean_absolute_error(a, b),
            r2_score(a, b),
            np.corrcoef(a, b)[0, 1])

def compute_metrics(pred, true, sc_c50, sc_t60):
    """
    pred/true: Dict[param] -> List[tensor [B, 6]]
    Retorna: dict[param][band] = tuple métricas
    """
    out = {p: {} for p in PARAMS}
    for j, band in enumerate(FREQUENCIES):
        p_c50 = torch.cat(pred["C50"])[:, j:j+1].cpu().numpy()
        t_c50 = torch.cat(true["C50"])[:, j:j+1].cpu().numpy()
        p_t60 = torch.cat(pred["T60"])[:, j:j+1].cpu().numpy()
        t_t60 = torch.cat(true["T60"])[:, j:j+1].cpu().numpy()

        p_c50 = sc_c50[band].inverse_transform(p_c50).ravel()
        t_c50 = sc_c50[band].inverse_transform(t_c50).ravel()
        p_t60 = sc_t60[band].inverse_transform(p_t60).ravel()
        t_t60 = sc_t60[band].inverse_transform(t_t60).ravel()

        out["C50"][band] = _stats(t_c50, p_c50)
        out["T60"][band] = _stats(t_t60, p_t60)
    return out

def find_last_epoch(ckpt_dir: Path, fold: int) -> Tuple[int, Path, Path]:
    pattern = re.compile(rf"fold{fold}_epoch(\d+)\.pth$")
    epochs = [(int(m.group(1)), p) for p in ckpt_dir.glob(f"fold{fold}_epoch*.pth")
              if (m := pattern.search(p.name))]
    if not epochs:
        return 0, None, None
    last_epoch, ckpt_path = max(epochs, key=lambda x: x[0])
    opt_path = ckpt_dir / f"fold{fold}_optim_latest.pth"
    return last_epoch, ckpt_path, opt_path if opt_path.exists() else None

# ──────────── Carrega labels e filtros ────────────
print("Lendo labels …")
df = pd.read_csv(LABELS_PATH)
df["tensor_filename"] = df["name"].str.replace(r"\.wav$", "", regex=True) + ".pt"
existing = {p.name for p in TRAIN_DIR.rglob("*.pt")}
df = df[df["tensor_filename"].isin(existing)].reset_index(drop=True)
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(subset=[f"{p}_{b}" for p in PARAMS for b in FREQ_BANDS], inplace=True)

kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)

# ─────────────────────── Loop K-Fold ───────────────────────
for fold, (tr_idx, v_idx) in enumerate(kf.split(df), 1):
    print(f"\n══════════ FOLD {fold}/{NUM_FOLDS} ══════════")
    fold_dir   = MODEL_DIR / f"fold_{fold}"
    ckpt_dir   = fold_dir / "checkpoints"
    scaler_dir = fold_dir / "scalers"
    ckpt_dir.mkdir(parents=True, exist_ok=True)
    scaler_dir.mkdir(parents=True, exist_ok=True)

    train_df, val_df = df.iloc[tr_idx].copy(), df.iloc[v_idx].copy()

    # ── StandardScalers (uma por parâmetro-banda) ──
    scalers_c50, scalers_t60 = {}, {}
    for band in FREQUENCIES:
        sc_c = StandardScaler().fit(train_df[[f"C50_{band}"]])
        sc_t = StandardScaler().fit(train_df[[f"T60_{band}"]])
        (scaler_dir / f"scaler_C50_{band}.pkl").write_bytes(pickle.dumps(sc_c))
        (scaler_dir / f"scaler_T60_{band}.pkl").write_bytes(pickle.dumps(sc_t))
        train_df[f"C50_{band}"] = sc_c.transform(train_df[[f"C50_{band}"]])
        val_df[f"C50_{band}"]   = sc_c.transform(val_df[[f"C50_{band}"]])
        train_df[f"T60_{band}"] = sc_t.transform(train_df[[f"T60_{band}"]])
        val_df[f"T60_{band}"]   = sc_t.transform(val_df[[f"T60_{band}"]])
        scalers_c50[band] = sc_c
        scalers_t60[band] = sc_t

    train_loader = DataLoader(
        SpectroDataset(train_df, TRAIN_DIR),
        batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True
    )
    val_loader = DataLoader(
        SpectroDataset(val_df, TRAIN_DIR),
        batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True
    )

    model = TwoHeadViT().to(device)
    criterion = nn.MSELoss()

    param_groups = (
        [{"params": model.backbone.parameters(), "lr": 3e-6, "weight_decay": 1e-4}] +
        [{"params": model.heads["C50"].parameters(), "lr": 3e-4, "weight_decay": 1e-2},
         {"params": model.heads["T60"].parameters(), "lr": 3e-4, "weight_decay": 1e-2}]
    )
    optimizer = optim.AdamW(param_groups, betas=(0.9, 0.999))

    # ─── Retomada ───
    start_epoch = 1
    last_epoch, ckpt_path, opt_path = find_last_epoch(ckpt_dir, fold)
    if ckpt_path is not None:
        model.load_state_dict(torch.load(ckpt_path, map_location=device))
        if opt_path is not None:
            optimizer.load_state_dict(torch.load(opt_path, map_location=device))
            for state in optimizer.state.values():       # corrige device
                for k, v in state.items():
                    if torch.is_tensor(v):
                        state[k] = v.to(device)
        start_epoch = last_epoch + 1
        print(f">>> Retomando da época {last_epoch} (checkpoint: {ckpt_path.name})")
    else:
        print(">>> Nenhum checkpoint — iniciando do zero")

    total_steps = len(train_loader) * EPOCHS
    scheduler = optim.lr_scheduler.OneCycleLR(
        optimizer,
        max_lr=[1e-4] + [5e-4]*2,                        # backbone + 2 heads
        pct_start=3/EPOCHS,
        div_factor=25, final_div_factor=1e3,
        total_steps=total_steps,
        last_epoch=(start_epoch - 2)
    )

    best_r2 = -float("inf")

    # ─────────── EPOCH LOOP ───────────
    for epoch in range(start_epoch, EPOCHS + 1):
        # ---------- treino ----------
        model.train()
        pred_t = {p: [] for p in PARAMS}
        true_t = {p: [] for p in PARAMS}
        loss_sum = 0.0

        for x, y in tqdm(train_loader, desc=f"[F{fold}] Train {epoch}", leave=False):
            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)  # y [B,2,6]
            optimizer.zero_grad()
            outs = model(x)                                      # dict param->[B,6]
            loss = (criterion(outs["C50"], y[:, 0, :]) +
                    criterion(outs["T60"], y[:, 1, :]))
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)
            optimizer.step()
            scheduler.step()

            loss_sum += loss.item() * x.size(0)
            for p in PARAMS:
                pred_t[p].append(outs[p].detach().cpu())
                true_t[p].append(y[:, 0 if p == "C50" else 1, :].cpu())

        train_loss = loss_sum / len(train_loader.dataset)

        # ---------- validação ----------
        model.eval()
        pred_v = {p: [] for p in PARAMS}
        true_v = {p: [] for p in PARAMS}
        val_loss_sum = 0.0
        with torch.no_grad():
            for x, y in tqdm(val_loader, desc=f"[F{fold}] Val {epoch}", leave=False):
                x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)
                outs = model(x)
                val_loss_sum += (criterion(outs["C50"], y[:, 0, :]).item()
                                 + criterion(outs["T60"], y[:, 1, :]).item()) * x.size(0)
                for p in PARAMS:
                    pred_v[p].append(outs[p].cpu())
                    true_v[p].append(y[:, 0 if p == "C50" else 1, :].cpu())

        val_loss = val_loss_sum / len(val_loader.dataset)

        # ---------- métricas ----------
        train_m = compute_metrics(pred_t, true_t, scalers_c50, scalers_t60)
        val_m   = compute_metrics(pred_v, true_v, scalers_c50, scalers_t60)
        val_r2_mean = np.mean([val_m[p][b][2] for p in PARAMS for b in FREQUENCIES])

        # ---------- checkpoints ----------
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_epoch{epoch}.pth")
        torch.save(model.state_dict(), ckpt_dir / f"fold{fold}_latest.pth")
        torch.save(optimizer.state_dict(), ckpt_dir / f"fold{fold}_optim_latest.pth")
        if val_r2_mean > best_r2:
            best_r2 = val_r2_mean
            torch.save(model.state_dict(), fold_dir / "best.pth")

        # ---------- log ----------
        print(f"\n[Fold {fold}] Epoch {epoch}/{EPOCHS} — Train L={train_loss:.4f} | Val L={val_loss:.4f}")
        hdr = "Band | RMSE_t | MAE_t | R2_t  | PCC_t | RMSE_v | MAE_v | R2_v  | PCC_v"
        for p in PARAMS:
            print(f"─── {p} ───")
            print(hdr)
            print("-" * len(hdr))
            for b in FREQUENCIES:
                rt, mt, r2t, pcct = train_m[p][b]
                rv, mv, r2v, pccv = val_m[p][b]
                print(f"{b:>4} | {rt:6.3f} | {mt:6.3f} | "
                      f"{r2t:6.3f} | {pcct:6.3f} | "
                      f"{rv:6.3f} | {mv:6.3f} | "
                      f"{r2v:6.3f} | {pccv:6.3f}")
        print("=" * 90)

        # ---------- grava CSV ----------
        with CSV_METRICS.open("a", encoding="utf-8") as f_csv:
            for p in PARAMS:
                for b in FREQUENCIES:
                    rt, mt, r2t, pcct = train_m[p][b]
                    rv, mv, r2v, pccv = val_m[p][b]
                    f_csv.write(f"{fold},{epoch},{p},{b},"
                                f"{rt:.6f},{mt:.6f},{r2t:.6f},{pcct:.6f},"
                                f"{rv:.6f},{mv:.6f},{r2v:.6f},{pccv:.6f}\n")

print("\nTreinamento K-Fold concluído!")

"""https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/

## TREINANDO LOG-MEL - 5R
"""
